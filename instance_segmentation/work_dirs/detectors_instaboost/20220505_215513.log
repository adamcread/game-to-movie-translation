2022-05-05 21:55:13,615 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.11 (default, Jul  3 2021, 17:53:42) [GCC 7.5.0]
CUDA available: True
GPU 0: NVIDIA TITAN RTX
CUDA_HOME: /apps/cuda/cuda-11.0-cudnn8.0
NVCC: 
GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
PyTorch: 1.7.0+cu110
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80
  - CuDNN 8.0.4
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.8.1+cu110
OpenCV: 4.5.5
MMCV: 1.4.8
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.0
MMDetection: 2.23.0+a3f7f65
------------------------------------------------------------

2022-05-05 21:55:14,015 - mmdet - INFO - Distributed training: False
2022-05-05 21:55:14,429 - mmdet - INFO - Config:
dataset_type = 'COCODataset'
data_root = 'data/coco/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='LoadAnnotations', with_bbox=True, with_mask=True, with_seg=True),
    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='SegRescale', scale_factor=0.125),
    dict(type='DefaultFormatBundle'),
    dict(
        type='Collect',
        keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type='CocoDataset',
        ann_file='../coco/annotations/train_filtered.json',
        img_prefix='../coco/images/train/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='LoadAnnotations',
                with_bbox=True,
                with_mask=True,
                with_seg=True),
            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='SegRescale', scale_factor=0.125),
            dict(type='DefaultFormatBundle'),
            dict(
                type='Collect',
                keys=[
                    'img', 'gt_bboxes', 'gt_labels', 'gt_masks',
                    'gt_semantic_seg'
                ])
        ],
        seg_prefix='../coco/segmentations/train/',
        classes=('person', )),
    val=dict(
        type='CocoDataset',
        ann_file='../coco/annotations/val_filtered.json',
        img_prefix='../coco/images/val/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip', flip_ratio=0.5),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ],
        seg_prefix='../coco/segmentations/val/',
        classes=('person', )),
    test=dict(
        type='CocoDataset',
        ann_file='data/coco/annotations/instances_val2017.json',
        img_prefix='data/coco/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip', flip_ratio=0.5),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(metric=['bbox', 'segm'])
optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=2000,
    warmup_ratio=0.001,
    step=[8, 11])
runner = dict(type='EpochBasedRunner', max_epochs=6)
checkpoint_config = dict(interval=1)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = './checkpoints/detectors_htc_r101_20e_coco_20210419_203638-348d533b.pth'
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
model = dict(
    type='HybridTaskCascade',
    backbone=dict(
        type='DetectoRS_ResNet',
        depth=101,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type='BN', requires_grad=True),
        norm_eval=True,
        style='pytorch',
        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet101'),
        conv_cfg=dict(type='ConvAWS'),
        sac=dict(type='SAC', use_deform=True),
        stage_with_sac=(False, True, True, True),
        output_img=True),
    neck=dict(
        type='RFP',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        num_outs=5,
        rfp_steps=2,
        aspp_out_channels=64,
        aspp_dilations=(1, 3, 6, 1),
        rfp_backbone=dict(
            rfp_inplanes=256,
            type='DetectoRS_ResNet',
            depth=101,
            num_stages=4,
            out_indices=(0, 1, 2, 3),
            frozen_stages=1,
            norm_cfg=dict(type='BN', requires_grad=True),
            norm_eval=True,
            conv_cfg=dict(type='ConvAWS'),
            sac=dict(type='SAC', use_deform=True),
            stage_with_sac=(False, True, True, True),
            pretrained='torchvision://resnet101',
            style='pytorch')),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[8],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(
            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),
    roi_head=dict(
        type='HybridTaskCascadeRoIHead',
        interleaved=True,
        mask_info_flow=True,
        num_stages=3,
        stage_loss_weights=[1, 0.5, 0.25],
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=[
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=1,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.1, 0.1, 0.2, 0.2]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,
                               loss_weight=1.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=1,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.05, 0.05, 0.1, 0.1]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,
                               loss_weight=1.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=1,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.033, 0.033, 0.067, 0.067]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))
        ],
        mask_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        mask_head=[
            dict(
                type='HTCMaskHead',
                with_conv_res=False,
                num_convs=4,
                in_channels=256,
                conv_out_channels=256,
                num_classes=1,
                loss_mask=dict(
                    type='CrossEntropyLoss', use_mask=True, loss_weight=1.0)),
            dict(
                type='HTCMaskHead',
                num_convs=4,
                in_channels=256,
                conv_out_channels=256,
                num_classes=1,
                loss_mask=dict(
                    type='CrossEntropyLoss', use_mask=True, loss_weight=1.0)),
            dict(
                type='HTCMaskHead',
                num_convs=4,
                in_channels=256,
                conv_out_channels=256,
                num_classes=1,
                loss_mask=dict(
                    type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))
        ],
        semantic_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[8]),
        semantic_head=dict(
            type='FusedSemanticHead',
            num_ins=5,
            fusion_level=1,
            num_convs=4,
            in_channels=256,
            conv_out_channels=256,
            num_classes=183,
            loss_seg=dict(
                type='CrossEntropyLoss', ignore_index=255, loss_weight=0.2))),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=0,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=2000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=[
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.5,
                    neg_iou_thr=0.5,
                    min_pos_iou=0.5,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                mask_size=28,
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.6,
                    neg_iou_thr=0.6,
                    min_pos_iou=0.6,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                mask_size=28,
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.7,
                    neg_iou_thr=0.7,
                    min_pos_iou=0.7,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                mask_size=28,
                pos_weight=-1,
                debug=False)
        ]),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            score_thr=0.001,
            nms=dict(type='nms', iou_threshold=0.5),
            max_per_img=100,
            mask_thr_binary=0.5)))
classes = ('person', )
work_dir = './work_dirs/detectors_instaboost'
auto_resume = False
gpu_ids = [0]

2022-05-05 21:55:14,429 - mmdet - INFO - Set random seed to 1892244158, deterministic: False
2022-05-05 21:55:16,870 - mmdet - INFO - load checkpoint from torchvision path: torchvision://resnet101
2022-05-05 21:55:17,576 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias

2022-05-05 21:55:17,645 - mmdet - INFO - load checkpoint from torchvision path: torchvision://resnet101
2022-05-05 21:55:18,060 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.0.rfp_conv.weight, layer2.0.rfp_conv.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.0.rfp_conv.weight, layer3.0.rfp_conv.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.0.rfp_conv.weight, layer4.0.rfp_conv.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias

2022-05-05 21:55:18,106 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}
2022-05-05 21:55:18,115 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2022-05-05 21:55:18,196 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2022-05-05 21:55:18,278 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2022-05-05 21:55:18,366 - mmdet - INFO - initialize FusedSemanticHead with init_cfg {'type': 'Kaiming', 'override': {'name': 'conv_logits'}}
Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.0.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.0.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.0.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.0.bn2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.0.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.0.bn3.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.1.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.1.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.1.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.1.bn2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.1.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.1.bn3.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.2.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.2.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.2.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.2.bn2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.2.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer1.2.bn3.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.0.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.0.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.0.conv2.weight_diff - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.0.conv2.switch.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.0.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.0.conv2.pre_context.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.0.conv2.pre_context.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.0.conv2.post_context.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.0.conv2.post_context.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.0.conv2.offset_s.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.0.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.0.conv2.offset_l.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.0.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.0.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.0.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.0.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.0.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.1.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.1.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.1.conv2.weight_diff - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.1.conv2.switch.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.1.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.1.conv2.pre_context.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.1.conv2.pre_context.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.1.conv2.post_context.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.1.conv2.post_context.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.1.conv2.offset_s.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.1.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.1.conv2.offset_l.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.1.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.1.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.1.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.1.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.1.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.2.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.2.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.2.conv2.weight_diff - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.2.conv2.switch.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.2.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.2.conv2.pre_context.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.2.conv2.pre_context.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.2.conv2.post_context.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.2.conv2.post_context.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.2.conv2.offset_s.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.2.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.2.conv2.offset_l.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.2.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.2.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.2.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.2.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.2.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.3.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.3.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.3.conv2.weight_diff - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.3.conv2.switch.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.3.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.3.conv2.pre_context.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.3.conv2.pre_context.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.3.conv2.post_context.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.3.conv2.post_context.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.3.conv2.offset_s.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.3.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.3.conv2.offset_l.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.3.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer2.3.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.3.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.3.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer2.3.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.0.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.0.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.0.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.0.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.0.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.0.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.0.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.0.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.0.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.0.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.0.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.0.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.0.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.0.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.0.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.0.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.0.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.1.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.1.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.1.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.1.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.1.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.1.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.1.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.1.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.1.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.1.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.1.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.1.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.1.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.1.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.1.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.1.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.1.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.2.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.2.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.2.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.2.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.2.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.2.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.2.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.2.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.2.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.2.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.2.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.2.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.2.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.2.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.2.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.2.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.2.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.3.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.3.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.3.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.3.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.3.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.3.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.3.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.3.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.3.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.3.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.3.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.3.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.3.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.3.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.3.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.3.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.3.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.4.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.4.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.4.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.4.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.4.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.4.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.4.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.4.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.4.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.4.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.4.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.4.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.4.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.4.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.4.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.4.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.4.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.5.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.5.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.5.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.5.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.5.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.5.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.5.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.5.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.5.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.5.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.5.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.5.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.5.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.5.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.5.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.5.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.5.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.6.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.6.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.6.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.6.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.6.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.6.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.6.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.6.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.6.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.6.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.6.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.6.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.6.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.6.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.6.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.6.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.6.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.6.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.6.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.6.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.7.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.7.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.7.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.7.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.7.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.7.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.7.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.7.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.7.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.7.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.7.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.7.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.7.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.7.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.7.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.7.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.7.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.7.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.7.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.7.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.8.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.8.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.8.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.8.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.8.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.8.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.8.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.8.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.8.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.8.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.8.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.8.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.8.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.8.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.8.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.8.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.8.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.8.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.8.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.8.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.9.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.9.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.9.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.9.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.9.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.9.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.9.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.9.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.9.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.9.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.9.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.9.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.9.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.9.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.9.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.9.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.9.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.9.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.9.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.9.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.10.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.10.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.10.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.10.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.10.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.10.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.10.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.10.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.10.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.10.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.10.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.10.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.10.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.10.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.10.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.10.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.10.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.10.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.10.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.10.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.11.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.11.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.11.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.11.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.11.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.11.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.11.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.11.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.11.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.11.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.11.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.11.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.11.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.11.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.11.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.11.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.11.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.11.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.11.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.11.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.12.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.12.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.12.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.12.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.12.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.12.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.12.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.12.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.12.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.12.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.12.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.12.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.12.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.12.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.12.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.12.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.12.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.12.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.12.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.12.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.13.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.13.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.13.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.13.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.13.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.13.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.13.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.13.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.13.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.13.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.13.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.13.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.13.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.13.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.13.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.13.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.13.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.13.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.13.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.13.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.14.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.14.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.14.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.14.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.14.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.14.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.14.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.14.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.14.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.14.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.14.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.14.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.14.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.14.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.14.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.14.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.14.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.14.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.14.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.14.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.15.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.15.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.15.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.15.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.15.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.15.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.15.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.15.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.15.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.15.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.15.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.15.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.15.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.15.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.15.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.15.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.15.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.15.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.15.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.15.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.16.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.16.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.16.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.16.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.16.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.16.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.16.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.16.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.16.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.16.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.16.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.16.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.16.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.16.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.16.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.16.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.16.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.16.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.16.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.16.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.17.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.17.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.17.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.17.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.17.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.17.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.17.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.17.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.17.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.17.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.17.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.17.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.17.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.17.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.17.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.17.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.17.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.17.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.17.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.17.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.18.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.18.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.18.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.18.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.18.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.18.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.18.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.18.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.18.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.18.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.18.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.18.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.18.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.18.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.18.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.18.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.18.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.18.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.18.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.18.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.19.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.19.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.19.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.19.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.19.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.19.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.19.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.19.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.19.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.19.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.19.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.19.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.19.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.19.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.19.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.19.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.19.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.19.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.19.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.19.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.20.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.20.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.20.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.20.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.20.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.20.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.20.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.20.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.20.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.20.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.20.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.20.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.20.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.20.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.20.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.20.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.20.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.20.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.20.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.20.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.21.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.21.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.21.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.21.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.21.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.21.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.21.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.21.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.21.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.21.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.21.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.21.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.21.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.21.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.21.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.21.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.21.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.21.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.21.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.21.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.22.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.22.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.22.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.22.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.22.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.22.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.22.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.22.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.22.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.22.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.22.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.22.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.22.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.22.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.22.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer3.22.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.22.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.22.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.22.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer3.22.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.0.bn1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.0.bn1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.0.conv2.weight_diff - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.0.conv2.switch.weight - torch.Size([1, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.0.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.0.conv2.pre_context.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.0.conv2.pre_context.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.0.conv2.post_context.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.0.conv2.post_context.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.0.conv2.offset_s.weight - torch.Size([18, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.0.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.0.conv2.offset_l.weight - torch.Size([18, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.0.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.0.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.0.bn2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.0.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.0.bn3.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.1.bn1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.1.bn1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.1.conv2.weight_diff - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.1.conv2.switch.weight - torch.Size([1, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.1.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.1.conv2.pre_context.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.1.conv2.pre_context.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.1.conv2.post_context.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.1.conv2.post_context.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.1.conv2.offset_s.weight - torch.Size([18, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.1.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.1.conv2.offset_l.weight - torch.Size([18, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.1.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.1.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.1.bn2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.1.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.1.bn3.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.2.bn1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.2.bn1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.2.conv2.weight_diff - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.2.conv2.switch.weight - torch.Size([1, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.2.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.2.conv2.pre_context.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.2.conv2.pre_context.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.2.conv2.post_context.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.2.conv2.post_context.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.2.conv2.offset_s.weight - torch.Size([18, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.2.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.2.conv2.offset_l.weight - torch.Size([18, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.2.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

backbone.layer4.2.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.2.bn2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.2.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

backbone.layer4.2.bn3.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in DetectoRS_ResNet  

neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.lateral_convs.1.conv.weight - torch.Size([256, 512, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.lateral_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.lateral_convs.3.conv.weight - torch.Size([256, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.lateral_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.conv1.weight - torch.Size([64, 3, 7, 7]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.bn2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.bn3.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.downsample.1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.0.downsample.1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.1.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.1.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.1.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.1.bn2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.1.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.1.bn3.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.2.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.2.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.2.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.2.bn2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.2.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer1.2.bn3.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.conv2.weight_diff - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.0.conv2.switch.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.0.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.0.conv2.pre_context.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.0.conv2.pre_context.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.0.conv2.post_context.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.0.conv2.post_context.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.0.conv2.offset_s.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.0.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.0.conv2.offset_l.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.0.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.0.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.downsample.1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.downsample.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.0.rfp_conv.weight - torch.Size([512, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.0.rfp_conv.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.1.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.1.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.1.conv2.weight_diff - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.1.conv2.switch.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.1.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.1.conv2.pre_context.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.1.conv2.pre_context.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.1.conv2.post_context.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.1.conv2.post_context.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.1.conv2.offset_s.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.1.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.1.conv2.offset_l.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.1.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.1.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.1.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.1.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.1.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.2.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.2.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.2.conv2.weight_diff - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.2.conv2.switch.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.2.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.2.conv2.pre_context.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.2.conv2.pre_context.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.2.conv2.post_context.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.2.conv2.post_context.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.2.conv2.offset_s.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.2.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.2.conv2.offset_l.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.2.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.2.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.2.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.2.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.2.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.3.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.3.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.3.conv2.weight_diff - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.3.conv2.switch.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.3.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.3.conv2.pre_context.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.3.conv2.pre_context.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.3.conv2.post_context.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.3.conv2.post_context.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.3.conv2.offset_s.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.3.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.3.conv2.offset_l.weight - torch.Size([18, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.3.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer2.3.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.3.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.3.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer2.3.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.0.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.0.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.0.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.0.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.0.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.0.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.0.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.0.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.0.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.0.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.0.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.downsample.1.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.downsample.1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.0.rfp_conv.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.0.rfp_conv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.1.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.1.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.1.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.1.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.1.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.1.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.1.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.1.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.1.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.1.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.1.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.1.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.1.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.1.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.1.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.1.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.1.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.2.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.2.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.2.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.2.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.2.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.2.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.2.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.2.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.2.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.2.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.2.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.2.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.2.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.2.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.2.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.2.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.2.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.3.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.3.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.3.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.3.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.3.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.3.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.3.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.3.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.3.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.3.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.3.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.3.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.3.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.3.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.3.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.3.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.3.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.4.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.4.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.4.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.4.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.4.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.4.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.4.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.4.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.4.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.4.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.4.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.4.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.4.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.4.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.4.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.4.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.4.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.5.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.5.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.5.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.5.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.5.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.5.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.5.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.5.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.5.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.5.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.5.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.5.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.5.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.5.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.5.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.5.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.5.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.6.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.6.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.6.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.6.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.6.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.6.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.6.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.6.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.6.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.6.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.6.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.6.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.6.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.6.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.6.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.6.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.6.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.6.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.6.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.6.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.7.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.7.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.7.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.7.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.7.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.7.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.7.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.7.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.7.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.7.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.7.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.7.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.7.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.7.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.7.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.7.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.7.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.7.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.7.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.7.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.8.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.8.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.8.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.8.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.8.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.8.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.8.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.8.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.8.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.8.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.8.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.8.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.8.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.8.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.8.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.8.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.8.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.8.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.8.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.8.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.9.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.9.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.9.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.9.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.9.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.9.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.9.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.9.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.9.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.9.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.9.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.9.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.9.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.9.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.9.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.9.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.9.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.9.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.9.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.9.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.10.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.10.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.10.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.10.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.10.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.10.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.10.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.10.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.10.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.10.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.10.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.10.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.10.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.10.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.10.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.10.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.10.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.10.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.10.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.10.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.11.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.11.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.11.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.11.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.11.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.11.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.11.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.11.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.11.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.11.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.11.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.11.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.11.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.11.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.11.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.11.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.11.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.11.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.11.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.11.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.12.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.12.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.12.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.12.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.12.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.12.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.12.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.12.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.12.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.12.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.12.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.12.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.12.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.12.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.12.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.12.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.12.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.12.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.12.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.12.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.13.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.13.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.13.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.13.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.13.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.13.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.13.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.13.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.13.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.13.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.13.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.13.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.13.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.13.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.13.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.13.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.13.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.13.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.13.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.13.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.14.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.14.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.14.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.14.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.14.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.14.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.14.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.14.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.14.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.14.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.14.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.14.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.14.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.14.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.14.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.14.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.14.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.14.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.14.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.14.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.15.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.15.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.15.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.15.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.15.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.15.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.15.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.15.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.15.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.15.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.15.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.15.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.15.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.15.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.15.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.15.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.15.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.15.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.15.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.15.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.16.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.16.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.16.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.16.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.16.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.16.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.16.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.16.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.16.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.16.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.16.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.16.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.16.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.16.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.16.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.16.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.16.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.16.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.16.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.16.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.17.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.17.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.17.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.17.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.17.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.17.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.17.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.17.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.17.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.17.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.17.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.17.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.17.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.17.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.17.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.17.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.17.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.17.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.17.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.17.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.18.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.18.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.18.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.18.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.18.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.18.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.18.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.18.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.18.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.18.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.18.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.18.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.18.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.18.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.18.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.18.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.18.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.18.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.18.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.18.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.19.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.19.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.19.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.19.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.19.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.19.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.19.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.19.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.19.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.19.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.19.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.19.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.19.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.19.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.19.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.19.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.19.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.19.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.19.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.19.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.20.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.20.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.20.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.20.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.20.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.20.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.20.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.20.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.20.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.20.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.20.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.20.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.20.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.20.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.20.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.20.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.20.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.20.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.20.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.20.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.21.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.21.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.21.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.21.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.21.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.21.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.21.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.21.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.21.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.21.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.21.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.21.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.21.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.21.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.21.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.21.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.21.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.21.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.21.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.21.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.22.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.22.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.22.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.22.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.22.conv2.weight_diff - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.22.conv2.switch.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.22.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.22.conv2.pre_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.22.conv2.pre_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.22.conv2.post_context.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.22.conv2.post_context.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.22.conv2.offset_s.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.22.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.22.conv2.offset_l.weight - torch.Size([18, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.22.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer3.22.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.22.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.22.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.22.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer3.22.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.bn1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.bn1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.conv2.weight_diff - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.0.conv2.switch.weight - torch.Size([1, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.0.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.0.conv2.pre_context.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.0.conv2.pre_context.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.0.conv2.post_context.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.0.conv2.post_context.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.0.conv2.offset_s.weight - torch.Size([18, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.0.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.0.conv2.offset_l.weight - torch.Size([18, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.0.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.0.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.bn2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.bn3.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.downsample.1.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.downsample.1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.0.rfp_conv.weight - torch.Size([2048, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.0.rfp_conv.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.1.bn1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.1.bn1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.1.conv2.weight_diff - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.1.conv2.switch.weight - torch.Size([1, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.1.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.1.conv2.pre_context.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.1.conv2.pre_context.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.1.conv2.post_context.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.1.conv2.post_context.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.1.conv2.offset_s.weight - torch.Size([18, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.1.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.1.conv2.offset_l.weight - torch.Size([18, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.1.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.1.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.1.bn2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.1.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.1.bn3.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.2.bn1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.2.bn1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.2.conv2.weight_diff - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.2.conv2.switch.weight - torch.Size([1, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.2.conv2.switch.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.2.conv2.pre_context.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.2.conv2.pre_context.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.2.conv2.post_context.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.2.conv2.post_context.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.2.conv2.offset_s.weight - torch.Size([18, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.2.conv2.offset_s.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.2.conv2.offset_l.weight - torch.Size([18, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.2.conv2.offset_l.bias - torch.Size([18]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_modules.0.layer4.2.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.2.bn2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.2.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_modules.0.layer4.2.bn3.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_aspp.aspp.0.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_aspp.aspp.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_aspp.aspp.1.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_aspp.aspp.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_aspp.aspp.2.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_aspp.aspp.2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_aspp.aspp.3.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_aspp.aspp.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

neck.rfp_weight.weight - torch.Size([1, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RFP  

neck.rfp_weight.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in RFP  

rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_conv.bias - torch.Size([256]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.bias - torch.Size([3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.bias - torch.Size([12]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_cls.weight - torch.Size([2, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_cls.bias - torch.Size([2]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_reg.weight - torch.Size([4, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.0.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.0.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.0.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.0.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.0.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.fc_cls.weight - torch.Size([2, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.1.fc_cls.bias - torch.Size([2]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.1.fc_reg.weight - torch.Size([4, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.1.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.1.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.fc_cls.weight - torch.Size([2, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.2.fc_cls.bias - torch.Size([2]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.2.fc_reg.weight - torch.Size([4, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.2.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.2.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.mask_head.0.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.0.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.0.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.0.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.0.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.0.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.0.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.0.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.0.upsample.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.0.upsample.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.0.conv_logits.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.0.conv_logits.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.1.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.1.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.1.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.1.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.1.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.1.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.1.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.1.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.1.upsample.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.1.upsample.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.1.conv_logits.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.1.conv_logits.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.1.conv_res.conv.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.1.conv_res.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.2.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.2.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.2.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.2.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.2.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.2.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.2.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.2.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.2.upsample.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.2.upsample.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.2.conv_logits.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.2.conv_logits.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.2.conv_res.conv.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.mask_head.2.conv_res.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.semantic_head.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.semantic_head.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.semantic_head.lateral_convs.1.conv.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.semantic_head.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.semantic_head.lateral_convs.2.conv.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.semantic_head.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.semantic_head.lateral_convs.3.conv.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.semantic_head.lateral_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.semantic_head.lateral_convs.4.conv.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.semantic_head.lateral_convs.4.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.semantic_head.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.semantic_head.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.semantic_head.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.semantic_head.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.semantic_head.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.semantic_head.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.semantic_head.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.semantic_head.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.semantic_head.conv_embedding.conv.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.semantic_head.conv_embedding.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of HybridTaskCascade  

roi_head.semantic_head.conv_logits.weight - torch.Size([183, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

roi_head.semantic_head.conv_logits.bias - torch.Size([183]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
2022-05-05 21:55:39,075 - mmdet - INFO - load checkpoint from local path: ./checkpoints/detectors_htc_r101_20e_coco_20210419_203638-348d533b.pth
2022-05-05 21:55:42,071 - mmdet - WARNING - The model and loaded state dict do not match exactly

size mismatch for roi_head.bbox_head.0.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([2, 1024]).
size mismatch for roi_head.bbox_head.0.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for roi_head.bbox_head.1.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([2, 1024]).
size mismatch for roi_head.bbox_head.1.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for roi_head.bbox_head.2.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([2, 1024]).
size mismatch for roi_head.bbox_head.2.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for roi_head.mask_head.0.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 256, 1, 1]).
size mismatch for roi_head.mask_head.0.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).
size mismatch for roi_head.mask_head.1.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 256, 1, 1]).
size mismatch for roi_head.mask_head.1.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).
size mismatch for roi_head.mask_head.2.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 256, 1, 1]).
size mismatch for roi_head.mask_head.2.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).
2022-05-05 21:55:42,091 - mmdet - INFO - Start running, host: fsfr78@gpu8, work_dir: /home2/fsfr78/comp_vis/instance_segmentation/work_dirs/detectors_instaboost
2022-05-05 21:55:42,091 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2022-05-05 21:55:42,091 - mmdet - INFO - workflow: [('train', 1)], max: 6 epochs
2022-05-05 21:55:42,091 - mmdet - INFO - Checkpoints will be saved to /home2/fsfr78/comp_vis/instance_segmentation/work_dirs/detectors_instaboost by HardDiskBackend.
2022-05-05 21:57:14,920 - mmdet - INFO - Epoch [1][50/32058]	lr: 5.095e-04, eta: 4 days, 3:02:04, time: 1.854, data_time: 0.081, memory: 18026, loss_rpn_cls: 0.0149, loss_rpn_bbox: 0.0063, loss_semantic_seg: 0.1380, s0.loss_cls: 0.2827, s0.acc: 89.1719, s0.loss_bbox: 0.0365, s0.loss_mask: 0.5580, s1.loss_cls: 0.1493, s1.acc: 88.7790, s1.loss_bbox: 0.0503, s1.loss_mask: 0.2486, s2.loss_cls: 0.0829, s2.acc: 87.0874, s2.loss_bbox: 0.0367, s2.loss_mask: 0.1024, loss: 1.7065, grad_norm: 7.5151
2022-05-05 21:58:45,307 - mmdet - INFO - Epoch [1][100/32058]	lr: 1.009e-03, eta: 4 days, 1:46:22, time: 1.808, data_time: 0.021, memory: 19223, loss_rpn_cls: 0.0151, loss_rpn_bbox: 0.0060, loss_semantic_seg: 0.1430, s0.loss_cls: 0.0857, s0.acc: 97.3438, s0.loss_bbox: 0.0358, s0.loss_mask: 0.2237, s1.loss_cls: 0.0452, s1.acc: 97.2698, s1.loss_bbox: 0.0453, s1.loss_mask: 0.1012, s2.loss_cls: 0.0320, s2.acc: 94.6939, s2.loss_bbox: 0.0347, s2.loss_mask: 0.0513, loss: 0.8190, grad_norm: 5.0697
2022-05-05 22:00:17,923 - mmdet - INFO - Epoch [1][150/32058]	lr: 1.509e-03, eta: 4 days, 2:07:44, time: 1.852, data_time: 0.024, memory: 19223, loss_rpn_cls: 0.0127, loss_rpn_bbox: 0.0075, loss_semantic_seg: 0.1375, s0.loss_cls: 0.0775, s0.acc: 96.8750, s0.loss_bbox: 0.0477, s0.loss_mask: 0.2213, s1.loss_cls: 0.0365, s1.acc: 97.1779, s1.loss_bbox: 0.0604, s1.loss_mask: 0.1064, s2.loss_cls: 0.0227, s2.acc: 96.7461, s2.loss_bbox: 0.0449, s2.loss_mask: 0.0522, loss: 0.8272, grad_norm: 5.4026
2022-05-05 22:01:49,297 - mmdet - INFO - Epoch [1][200/32058]	lr: 2.008e-03, eta: 4 days, 1:57:45, time: 1.827, data_time: 0.020, memory: 19223, loss_rpn_cls: 0.0106, loss_rpn_bbox: 0.0075, loss_semantic_seg: 0.1577, s0.loss_cls: 0.0601, s0.acc: 97.6348, s0.loss_bbox: 0.0419, s0.loss_mask: 0.2095, s1.loss_cls: 0.0268, s1.acc: 98.1103, s1.loss_bbox: 0.0538, s1.loss_mask: 0.1012, s2.loss_cls: 0.0168, s2.acc: 97.6709, s2.loss_bbox: 0.0391, s2.loss_mask: 0.0498, loss: 0.7749, grad_norm: 5.8148
2022-05-05 22:03:20,331 - mmdet - INFO - Epoch [1][250/32058]	lr: 2.508e-03, eta: 4 days, 1:46:47, time: 1.821, data_time: 0.018, memory: 19223, loss_rpn_cls: 0.0101, loss_rpn_bbox: 0.0066, loss_semantic_seg: 0.1495, s0.loss_cls: 0.0617, s0.acc: 97.5449, s0.loss_bbox: 0.0420, s0.loss_mask: 0.2133, s1.loss_cls: 0.0280, s1.acc: 97.8064, s1.loss_bbox: 0.0538, s1.loss_mask: 0.1042, s2.loss_cls: 0.0163, s2.acc: 97.5840, s2.loss_bbox: 0.0412, s2.loss_mask: 0.0516, loss: 0.7784, grad_norm: 5.4603
2022-05-05 22:04:52,171 - mmdet - INFO - Epoch [1][300/32058]	lr: 3.007e-03, eta: 4 days, 1:47:35, time: 1.837, data_time: 0.021, memory: 19223, loss_rpn_cls: 0.0096, loss_rpn_bbox: 0.0071, loss_semantic_seg: 0.1665, s0.loss_cls: 0.0697, s0.acc: 97.3125, s0.loss_bbox: 0.0433, s0.loss_mask: 0.2209, s1.loss_cls: 0.0291, s1.acc: 97.8826, s1.loss_bbox: 0.0556, s1.loss_mask: 0.1072, s2.loss_cls: 0.0159, s2.acc: 97.5659, s2.loss_bbox: 0.0403, s2.loss_mask: 0.0523, loss: 0.8173, grad_norm: 6.0915
2022-05-05 22:06:23,790 - mmdet - INFO - Epoch [1][350/32058]	lr: 3.507e-03, eta: 4 days, 1:45:42, time: 1.832, data_time: 0.020, memory: 19223, loss_rpn_cls: 0.0090, loss_rpn_bbox: 0.0099, loss_semantic_seg: 0.1601, s0.loss_cls: 0.0698, s0.acc: 97.2930, s0.loss_bbox: 0.0537, s0.loss_mask: 0.2278, s1.loss_cls: 0.0318, s1.acc: 97.6776, s1.loss_bbox: 0.0676, s1.loss_mask: 0.1100, s2.loss_cls: 0.0192, s2.acc: 96.9935, s2.loss_bbox: 0.0417, s2.loss_mask: 0.0523, loss: 0.8528, grad_norm: 7.9540
2022-05-05 22:07:55,377 - mmdet - INFO - Epoch [1][400/32058]	lr: 4.006e-03, eta: 4 days, 1:43:39, time: 1.832, data_time: 0.019, memory: 19223, loss_rpn_cls: 0.0100, loss_rpn_bbox: 0.0092, loss_semantic_seg: 0.1647, s0.loss_cls: 0.0802, s0.acc: 96.6973, s0.loss_bbox: 0.0648, s0.loss_mask: 0.2590, s1.loss_cls: 0.0388, s1.acc: 96.8583, s1.loss_bbox: 0.0762, s1.loss_mask: 0.1237, s2.loss_cls: 0.0224, s2.acc: 96.1883, s2.loss_bbox: 0.0504, s2.loss_mask: 0.0596, loss: 0.9591, grad_norm: 7.1457
2022-05-05 22:09:25,629 - mmdet - INFO - Epoch [1][450/32058]	lr: 4.506e-03, eta: 4 days, 1:32:13, time: 1.805, data_time: 0.017, memory: 19223, loss_rpn_cls: 0.0174, loss_rpn_bbox: 0.0129, loss_semantic_seg: 0.1556, s0.loss_cls: 0.0822, s0.acc: 96.9102, s0.loss_bbox: 0.0570, s0.loss_mask: 0.2372, s1.loss_cls: 0.0360, s1.acc: 97.3870, s1.loss_bbox: 0.0683, s1.loss_mask: 0.1150, s2.loss_cls: 0.0194, s2.acc: 97.1163, s2.loss_bbox: 0.0469, s2.loss_mask: 0.0561, loss: 0.9040, grad_norm: 7.4773
2022-05-05 22:10:56,776 - mmdet - INFO - Epoch [1][500/32058]	lr: 5.005e-03, eta: 4 days, 1:28:30, time: 1.823, data_time: 0.020, memory: 19223, loss_rpn_cls: 0.0099, loss_rpn_bbox: 0.0126, loss_semantic_seg: 0.1914, s0.loss_cls: 0.0751, s0.acc: 97.0176, s0.loss_bbox: 0.0545, s0.loss_mask: 0.2375, s1.loss_cls: 0.0334, s1.acc: 97.4336, s1.loss_bbox: 0.0678, s1.loss_mask: 0.1121, s2.loss_cls: 0.0186, s2.acc: 97.1467, s2.loss_bbox: 0.0468, s2.loss_mask: 0.0534, loss: 0.9133, grad_norm: 6.3244
2022-05-05 22:12:29,500 - mmdet - INFO - Epoch [1][550/32058]	lr: 5.505e-03, eta: 4 days, 1:34:21, time: 1.854, data_time: 0.021, memory: 19223, loss_rpn_cls: 0.0134, loss_rpn_bbox: 0.0132, loss_semantic_seg: 0.1895, s0.loss_cls: 0.1034, s0.acc: 95.7930, s0.loss_bbox: 0.0779, s0.loss_mask: 0.2746, s1.loss_cls: 0.0510, s1.acc: 95.8793, s1.loss_bbox: 0.0905, s1.loss_mask: 0.1328, s2.loss_cls: 0.0270, s2.acc: 95.6776, s2.loss_bbox: 0.0609, s2.loss_mask: 0.0649, loss: 1.0991, grad_norm: 7.7024
2022-05-05 22:13:59,662 - mmdet - INFO - Epoch [1][600/32058]	lr: 6.004e-03, eta: 4 days, 1:25:19, time: 1.803, data_time: 0.018, memory: 19223, loss_rpn_cls: 0.0155, loss_rpn_bbox: 0.0138, loss_semantic_seg: 0.1956, s0.loss_cls: 0.0804, s0.acc: 96.8066, s0.loss_bbox: 0.0563, s0.loss_mask: 0.2579, s1.loss_cls: 0.0386, s1.acc: 96.8748, s1.loss_bbox: 0.0723, s1.loss_mask: 0.1250, s2.loss_cls: 0.0216, s2.acc: 96.4640, s2.loss_bbox: 0.0509, s2.loss_mask: 0.0610, loss: 0.9887, grad_norm: 7.2477
2022-05-05 22:15:30,319 - mmdet - INFO - Epoch [1][650/32058]	lr: 6.504e-03, eta: 4 days, 1:19:53, time: 1.813, data_time: 0.018, memory: 19223, loss_rpn_cls: 0.0151, loss_rpn_bbox: 0.0146, loss_semantic_seg: 0.2097, s0.loss_cls: 0.0990, s0.acc: 96.0176, s0.loss_bbox: 0.0685, s0.loss_mask: 0.2600, s1.loss_cls: 0.0470, s1.acc: 96.1900, s1.loss_bbox: 0.0836, s1.loss_mask: 0.1260, s2.loss_cls: 0.0244, s2.acc: 95.9992, s2.loss_bbox: 0.0518, s2.loss_mask: 0.0600, loss: 1.0599, grad_norm: 6.4579
2022-05-05 22:17:01,930 - mmdet - INFO - Epoch [1][700/32058]	lr: 7.003e-03, eta: 4 days, 1:19:21, time: 1.832, data_time: 0.020, memory: 19223, loss_rpn_cls: 0.0158, loss_rpn_bbox: 0.0111, loss_semantic_seg: 0.2573, s0.loss_cls: 0.0887, s0.acc: 96.5098, s0.loss_bbox: 0.0705, s0.loss_mask: 0.2656, s1.loss_cls: 0.0422, s1.acc: 96.7067, s1.loss_bbox: 0.0854, s1.loss_mask: 0.1285, s2.loss_cls: 0.0239, s2.acc: 95.9719, s2.loss_bbox: 0.0542, s2.loss_mask: 0.0602, loss: 1.1033, grad_norm: 7.5202
2022-05-05 22:18:32,601 - mmdet - INFO - Epoch [1][750/32058]	lr: 7.503e-03, eta: 4 days, 1:14:41, time: 1.813, data_time: 0.020, memory: 19223, loss_rpn_cls: 0.0175, loss_rpn_bbox: 0.0135, loss_semantic_seg: 0.2083, s0.loss_cls: 0.0913, s0.acc: 96.2324, s0.loss_bbox: 0.0704, s0.loss_mask: 0.3046, s1.loss_cls: 0.0439, s1.acc: 96.5008, s1.loss_bbox: 0.0860, s1.loss_mask: 0.1450, s2.loss_cls: 0.0235, s2.acc: 96.0796, s2.loss_bbox: 0.0540, s2.loss_mask: 0.0701, loss: 1.1282, grad_norm: 7.3847
2022-05-05 22:20:03,585 - mmdet - INFO - Epoch [1][800/32058]	lr: 8.002e-03, eta: 4 days, 1:11:40, time: 1.820, data_time: 0.019, memory: 19223, loss_rpn_cls: 0.0246, loss_rpn_bbox: 0.0166, loss_semantic_seg: 0.2770, s0.loss_cls: 0.1029, s0.acc: 95.9219, s0.loss_bbox: 0.0755, s0.loss_mask: 0.2944, s1.loss_cls: 0.0484, s1.acc: 96.1679, s1.loss_bbox: 0.0871, s1.loss_mask: 0.1356, s2.loss_cls: 0.0251, s2.acc: 95.9667, s2.loss_bbox: 0.0544, s2.loss_mask: 0.0649, loss: 1.2065, grad_norm: 8.6848
2022-05-05 22:21:36,390 - mmdet - INFO - Epoch [1][850/32058]	lr: 8.502e-03, eta: 4 days, 1:15:40, time: 1.856, data_time: 0.021, memory: 19223, loss_rpn_cls: 0.0214, loss_rpn_bbox: 0.0177, loss_semantic_seg: 0.2804, s0.loss_cls: 0.1024, s0.acc: 96.0332, s0.loss_bbox: 0.0738, s0.loss_mask: 0.2882, s1.loss_cls: 0.0506, s1.acc: 96.0846, s1.loss_bbox: 0.0818, s1.loss_mask: 0.1356, s2.loss_cls: 0.0258, s2.acc: 95.8562, s2.loss_bbox: 0.0498, s2.loss_mask: 0.0649, loss: 1.1925, grad_norm: 7.1333
2022-05-05 22:23:07,413 - mmdet - INFO - Epoch [1][900/32058]	lr: 9.001e-03, eta: 4 days, 1:12:44, time: 1.820, data_time: 0.020, memory: 19223, loss_rpn_cls: 0.0170, loss_rpn_bbox: 0.0150, loss_semantic_seg: 0.3017, s0.loss_cls: 0.0841, s0.acc: 96.6113, s0.loss_bbox: 0.0666, s0.loss_mask: 0.2806, s1.loss_cls: 0.0400, s1.acc: 96.8257, s1.loss_bbox: 0.0770, s1.loss_mask: 0.1323, s2.loss_cls: 0.0215, s2.acc: 96.6010, s2.loss_bbox: 0.0499, s2.loss_mask: 0.0631, loss: 1.1489, grad_norm: 7.2640
2022-05-05 22:24:39,280 - mmdet - INFO - Epoch [1][950/32058]	lr: 9.501e-03, eta: 4 days, 1:12:47, time: 1.837, data_time: 0.019, memory: 19223, loss_rpn_cls: 0.0187, loss_rpn_bbox: 0.0205, loss_semantic_seg: 0.2918, s0.loss_cls: 0.1085, s0.acc: 95.6172, s0.loss_bbox: 0.0870, s0.loss_mask: 0.2936, s1.loss_cls: 0.0517, s1.acc: 95.7645, s1.loss_bbox: 0.0972, s1.loss_mask: 0.1390, s2.loss_cls: 0.0273, s2.acc: 95.5341, s2.loss_bbox: 0.0551, s2.loss_mask: 0.0662, loss: 1.2567, grad_norm: 7.6548
2022-05-05 22:26:10,242 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-05 22:26:10,242 - mmdet - INFO - Epoch [1][1000/32058]	lr: 1.000e-02, eta: 4 days, 1:09:47, time: 1.819, data_time: 0.021, memory: 19246, loss_rpn_cls: 0.0267, loss_rpn_bbox: 0.0189, loss_semantic_seg: 0.3303, s0.loss_cls: 0.1270, s0.acc: 94.9727, s0.loss_bbox: 0.0968, s0.loss_mask: 0.3176, s1.loss_cls: 0.0596, s1.acc: 95.2031, s1.loss_bbox: 0.1023, s1.loss_mask: 0.1503, s2.loss_cls: 0.0292, s2.acc: 95.2263, s2.loss_bbox: 0.0597, s2.loss_mask: 0.0723, loss: 1.3906, grad_norm: 7.4877
2022-05-05 22:27:41,542 - mmdet - INFO - Epoch [1][1050/32058]	lr: 1.050e-02, eta: 4 days, 1:07:57, time: 1.826, data_time: 0.019, memory: 19246, loss_rpn_cls: 0.0272, loss_rpn_bbox: 0.0166, loss_semantic_seg: 0.3346, s0.loss_cls: 0.1063, s0.acc: 95.8379, s0.loss_bbox: 0.0798, s0.loss_mask: 0.3104, s1.loss_cls: 0.0508, s1.acc: 96.0924, s1.loss_bbox: 0.0934, s1.loss_mask: 0.1492, s2.loss_cls: 0.0266, s2.acc: 95.9019, s2.loss_bbox: 0.0560, s2.loss_mask: 0.0720, loss: 1.3228, grad_norm: 7.2210
2022-05-05 22:29:10,958 - mmdet - INFO - Epoch [1][1100/32058]	lr: 1.100e-02, eta: 4 days, 1:00:41, time: 1.788, data_time: 0.019, memory: 19246, loss_rpn_cls: 0.0236, loss_rpn_bbox: 0.0176, loss_semantic_seg: 0.3477, s0.loss_cls: 0.0959, s0.acc: 96.1914, s0.loss_bbox: 0.0749, s0.loss_mask: 0.3124, s1.loss_cls: 0.0451, s1.acc: 96.3067, s1.loss_bbox: 0.0831, s1.loss_mask: 0.1452, s2.loss_cls: 0.0232, s2.acc: 96.2302, s2.loss_bbox: 0.0499, s2.loss_mask: 0.0719, loss: 1.2905, grad_norm: 6.4908
2022-05-05 22:30:41,601 - mmdet - INFO - Epoch [1][1150/32058]	lr: 1.150e-02, eta: 4 days, 0:57:20, time: 1.813, data_time: 0.022, memory: 19246, loss_rpn_cls: 0.0221, loss_rpn_bbox: 0.0228, loss_semantic_seg: 0.3665, s0.loss_cls: 0.1226, s0.acc: 95.0742, s0.loss_bbox: 0.0912, s0.loss_mask: 0.3204, s1.loss_cls: 0.0587, s1.acc: 95.1767, s1.loss_bbox: 0.1023, s1.loss_mask: 0.1556, s2.loss_cls: 0.0296, s2.acc: 94.9036, s2.loss_bbox: 0.0592, s2.loss_mask: 0.0744, loss: 1.4253, grad_norm: 7.3151
2022-05-05 22:32:12,401 - mmdet - INFO - Epoch [1][1200/32058]	lr: 1.200e-02, eta: 4 days, 0:54:32, time: 1.816, data_time: 0.019, memory: 19246, loss_rpn_cls: 0.0347, loss_rpn_bbox: 0.0181, loss_semantic_seg: 0.3938, s0.loss_cls: 0.1197, s0.acc: 95.2832, s0.loss_bbox: 0.0810, s0.loss_mask: 0.2875, s1.loss_cls: 0.0584, s1.acc: 95.3245, s1.loss_bbox: 0.0918, s1.loss_mask: 0.1354, s2.loss_cls: 0.0294, s2.acc: 95.1048, s2.loss_bbox: 0.0544, s2.loss_mask: 0.0646, loss: 1.3688, grad_norm: 7.8039
2022-05-05 22:33:42,281 - mmdet - INFO - Epoch [1][1250/32058]	lr: 1.250e-02, eta: 4 days, 0:49:30, time: 1.798, data_time: 0.017, memory: 19246, loss_rpn_cls: 0.0317, loss_rpn_bbox: 0.0182, loss_semantic_seg: 0.3914, s0.loss_cls: 0.1131, s0.acc: 95.6602, s0.loss_bbox: 0.0900, s0.loss_mask: 0.3234, s1.loss_cls: 0.0531, s1.acc: 96.0028, s1.loss_bbox: 0.0929, s1.loss_mask: 0.1476, s2.loss_cls: 0.0266, s2.acc: 95.9762, s2.loss_bbox: 0.0485, s2.loss_mask: 0.0695, loss: 1.4059, grad_norm: 6.2078
2022-05-05 22:35:13,414 - mmdet - INFO - Epoch [1][1300/32058]	lr: 1.300e-02, eta: 4 days, 0:47:49, time: 1.823, data_time: 0.019, memory: 19246, loss_rpn_cls: 0.0303, loss_rpn_bbox: 0.0179, loss_semantic_seg: 0.4565, s0.loss_cls: 0.1133, s0.acc: 95.7832, s0.loss_bbox: 0.0789, s0.loss_mask: 0.3011, s1.loss_cls: 0.0519, s1.acc: 96.0730, s1.loss_bbox: 0.0821, s1.loss_mask: 0.1402, s2.loss_cls: 0.0257, s2.acc: 95.9828, s2.loss_bbox: 0.0479, s2.loss_mask: 0.0675, loss: 1.4132, grad_norm: 7.3042
2022-05-05 22:36:45,406 - mmdet - INFO - Epoch [1][1350/32058]	lr: 1.350e-02, eta: 4 days, 0:48:10, time: 1.840, data_time: 0.019, memory: 19246, loss_rpn_cls: 0.0272, loss_rpn_bbox: 0.0198, loss_semantic_seg: 0.3831, s0.loss_cls: 0.1233, s0.acc: 95.1055, s0.loss_bbox: 0.1006, s0.loss_mask: 0.3339, s1.loss_cls: 0.0626, s1.acc: 94.8458, s1.loss_bbox: 0.1084, s1.loss_mask: 0.1560, s2.loss_cls: 0.0304, s2.acc: 94.9821, s2.loss_bbox: 0.0576, s2.loss_mask: 0.0744, loss: 1.4772, grad_norm: 6.5252
2022-05-05 22:38:17,488 - mmdet - INFO - Epoch [1][1400/32058]	lr: 1.400e-02, eta: 4 days, 0:48:35, time: 1.842, data_time: 0.018, memory: 19246, loss_rpn_cls: 0.0266, loss_rpn_bbox: 0.0203, loss_semantic_seg: 0.4200, s0.loss_cls: 0.1218, s0.acc: 95.5605, s0.loss_bbox: 0.0895, s0.loss_mask: 0.3369, s1.loss_cls: 0.0593, s1.acc: 95.6120, s1.loss_bbox: 0.0950, s1.loss_mask: 0.1609, s2.loss_cls: 0.0298, s2.acc: 95.6030, s2.loss_bbox: 0.0527, s2.loss_mask: 0.0763, loss: 1.4892, grad_norm: 6.5632
2022-05-05 22:39:49,408 - mmdet - INFO - Epoch [1][1450/32058]	lr: 1.450e-02, eta: 4 days, 0:48:31, time: 1.838, data_time: 0.019, memory: 19246, loss_rpn_cls: 0.0283, loss_rpn_bbox: 0.0215, loss_semantic_seg: 0.4534, s0.loss_cls: 0.1423, s0.acc: 94.4883, s0.loss_bbox: 0.1073, s0.loss_mask: 0.3475, s1.loss_cls: 0.0680, s1.acc: 94.8561, s1.loss_bbox: 0.1083, s1.loss_mask: 0.1638, s2.loss_cls: 0.0314, s2.acc: 95.2288, s2.loss_bbox: 0.0559, s2.loss_mask: 0.0789, loss: 1.6065, grad_norm: 6.9981
2022-05-05 22:41:21,780 - mmdet - INFO - Epoch [1][1500/32058]	lr: 1.500e-02, eta: 4 days, 0:49:18, time: 1.847, data_time: 0.020, memory: 19246, loss_rpn_cls: 0.0259, loss_rpn_bbox: 0.0253, loss_semantic_seg: 0.4398, s0.loss_cls: 0.1318, s0.acc: 94.8535, s0.loss_bbox: 0.0947, s0.loss_mask: 0.3614, s1.loss_cls: 0.0631, s1.acc: 94.9983, s1.loss_bbox: 0.1038, s1.loss_mask: 0.1720, s2.loss_cls: 0.0308, s2.acc: 95.2064, s2.loss_bbox: 0.0603, s2.loss_mask: 0.0842, loss: 1.5931, grad_norm: 6.8254
2022-05-05 22:42:52,436 - mmdet - INFO - Epoch [1][1550/32058]	lr: 1.549e-02, eta: 4 days, 0:46:25, time: 1.813, data_time: 0.018, memory: 19246, loss_rpn_cls: 0.0233, loss_rpn_bbox: 0.0196, loss_semantic_seg: 0.4073, s0.loss_cls: 0.1105, s0.acc: 95.8320, s0.loss_bbox: 0.0830, s0.loss_mask: 0.3146, s1.loss_cls: 0.0518, s1.acc: 95.9569, s1.loss_bbox: 0.0858, s1.loss_mask: 0.1470, s2.loss_cls: 0.0256, s2.acc: 95.8396, s2.loss_bbox: 0.0483, s2.loss_mask: 0.0700, loss: 1.3869, grad_norm: 5.7007
2022-05-05 22:44:22,618 - mmdet - INFO - Epoch [1][1600/32058]	lr: 1.599e-02, eta: 4 days, 0:42:41, time: 1.804, data_time: 0.019, memory: 19246, loss_rpn_cls: 0.0323, loss_rpn_bbox: 0.0209, loss_semantic_seg: 0.4108, s0.loss_cls: 0.1311, s0.acc: 95.0078, s0.loss_bbox: 0.0967, s0.loss_mask: 0.3431, s1.loss_cls: 0.0648, s1.acc: 94.9087, s1.loss_bbox: 0.0965, s1.loss_mask: 0.1594, s2.loss_cls: 0.0319, s2.acc: 94.7386, s2.loss_bbox: 0.0541, s2.loss_mask: 0.0764, loss: 1.5181, grad_norm: 5.9103
2022-05-05 22:45:53,406 - mmdet - INFO - Epoch [1][1650/32058]	lr: 1.649e-02, eta: 4 days, 0:40:15, time: 1.816, data_time: 0.021, memory: 19246, loss_rpn_cls: 0.0359, loss_rpn_bbox: 0.0195, loss_semantic_seg: 0.4618, s0.loss_cls: 0.1528, s0.acc: 94.3496, s0.loss_bbox: 0.1029, s0.loss_mask: 0.3405, s1.loss_cls: 0.0700, s1.acc: 94.8463, s1.loss_bbox: 0.0987, s1.loss_mask: 0.1601, s2.loss_cls: 0.0329, s2.acc: 94.8833, s2.loss_bbox: 0.0540, s2.loss_mask: 0.0752, loss: 1.6043, grad_norm: 5.8551
2022-05-05 22:47:24,184 - mmdet - INFO - Epoch [1][1700/32058]	lr: 1.699e-02, eta: 4 days, 0:37:51, time: 1.816, data_time: 0.019, memory: 19246, loss_rpn_cls: 0.0299, loss_rpn_bbox: 0.0212, loss_semantic_seg: 0.4198, s0.loss_cls: 0.1340, s0.acc: 95.1816, s0.loss_bbox: 0.0954, s0.loss_mask: 0.3263, s1.loss_cls: 0.0617, s1.acc: 95.4096, s1.loss_bbox: 0.1040, s1.loss_mask: 0.1561, s2.loss_cls: 0.0306, s2.acc: 95.3678, s2.loss_bbox: 0.0602, s2.loss_mask: 0.0766, loss: 1.5157, grad_norm: 5.9251
2022-05-05 22:48:54,636 - mmdet - INFO - Epoch [1][1750/32058]	lr: 1.749e-02, eta: 4 days, 0:34:54, time: 1.809, data_time: 0.018, memory: 19246, loss_rpn_cls: 0.0313, loss_rpn_bbox: 0.0208, loss_semantic_seg: 0.4074, s0.loss_cls: 0.1485, s0.acc: 94.2891, s0.loss_bbox: 0.1107, s0.loss_mask: 0.3059, s1.loss_cls: 0.0694, s1.acc: 94.6385, s1.loss_bbox: 0.1136, s1.loss_mask: 0.1485, s2.loss_cls: 0.0329, s2.acc: 94.7031, s2.loss_bbox: 0.0601, s2.loss_mask: 0.0717, loss: 1.5208, grad_norm: 5.7011
2022-05-05 22:50:24,587 - mmdet - INFO - Epoch [1][1800/32058]	lr: 1.799e-02, eta: 4 days, 0:31:10, time: 1.799, data_time: 0.019, memory: 19246, loss_rpn_cls: 0.0279, loss_rpn_bbox: 0.0203, loss_semantic_seg: 0.4394, s0.loss_cls: 0.1375, s0.acc: 94.7363, s0.loss_bbox: 0.1025, s0.loss_mask: 0.3221, s1.loss_cls: 0.0672, s1.acc: 94.6951, s1.loss_bbox: 0.1137, s1.loss_mask: 0.1531, s2.loss_cls: 0.0328, s2.acc: 94.6237, s2.loss_bbox: 0.0600, s2.loss_mask: 0.0734, loss: 1.5498, grad_norm: 5.4940
2022-05-05 22:51:55,118 - mmdet - INFO - Epoch [1][1850/32058]	lr: 1.849e-02, eta: 4 days, 0:28:32, time: 1.811, data_time: 0.016, memory: 19246, loss_rpn_cls: 0.0213, loss_rpn_bbox: 0.0176, loss_semantic_seg: 0.4070, s0.loss_cls: 0.1139, s0.acc: 95.8203, s0.loss_bbox: 0.0821, s0.loss_mask: 0.3267, s1.loss_cls: 0.0539, s1.acc: 96.0613, s1.loss_bbox: 0.0884, s1.loss_mask: 0.1545, s2.loss_cls: 0.0268, s2.acc: 95.8346, s2.loss_bbox: 0.0505, s2.loss_mask: 0.0732, loss: 1.4161, grad_norm: 5.6389
2022-05-05 22:53:25,613 - mmdet - INFO - Epoch [1][1900/32058]	lr: 1.899e-02, eta: 4 days, 0:25:54, time: 1.810, data_time: 0.021, memory: 19246, loss_rpn_cls: 0.0493, loss_rpn_bbox: 0.0266, loss_semantic_seg: 0.4828, s0.loss_cls: 0.1482, s0.acc: 94.6680, s0.loss_bbox: 0.1025, s0.loss_mask: 0.3130, s1.loss_cls: 0.0671, s1.acc: 95.0235, s1.loss_bbox: 0.1015, s1.loss_mask: 0.1490, s2.loss_cls: 0.0321, s2.acc: 94.9452, s2.loss_bbox: 0.0574, s2.loss_mask: 0.0730, loss: 1.6024, grad_norm: 5.8228
2022-05-05 22:54:43,784 - mmdet - INFO - Epoch [1][1950/32058]	lr: 1.949e-02, eta: 4 days, 0:03:17, time: 1.563, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 98.1567, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 98.2562, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 98.2733, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 22:55:56,906 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-05 22:55:56,907 - mmdet - INFO - Epoch [1][2000/32058]	lr: 1.999e-02, eta: 3 days, 23:33:42, time: 1.462, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 22:57:11,620 - mmdet - INFO - Epoch [1][2050/32058]	lr: 2.000e-02, eta: 3 days, 23:07:59, time: 1.494, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 22:58:26,289 - mmdet - INFO - Epoch [1][2100/32058]	lr: 2.000e-02, eta: 3 days, 22:43:21, time: 1.493, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 22:59:42,100 - mmdet - INFO - Epoch [1][2150/32058]	lr: 2.000e-02, eta: 3 days, 22:21:30, time: 1.516, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:00:57,645 - mmdet - INFO - Epoch [1][2200/32058]	lr: 2.000e-02, eta: 3 days, 22:00:12, time: 1.511, data_time: 0.024, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:02:12,627 - mmdet - INFO - Epoch [1][2250/32058]	lr: 2.000e-02, eta: 3 days, 21:39:00, time: 1.500, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:03:25,445 - mmdet - INFO - Epoch [1][2300/32058]	lr: 2.000e-02, eta: 3 days, 21:15:41, time: 1.456, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:04:40,436 - mmdet - INFO - Epoch [1][2350/32058]	lr: 2.000e-02, eta: 3 days, 20:56:14, time: 1.500, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:05:55,852 - mmdet - INFO - Epoch [1][2400/32058]	lr: 2.000e-02, eta: 3 days, 20:38:06, time: 1.508, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:07:08,899 - mmdet - INFO - Epoch [1][2450/32058]	lr: 2.000e-02, eta: 3 days, 20:17:36, time: 1.461, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:08:24,888 - mmdet - INFO - Epoch [1][2500/32058]	lr: 2.000e-02, eta: 3 days, 20:01:36, time: 1.520, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:09:40,606 - mmdet - INFO - Epoch [1][2550/32058]	lr: 2.000e-02, eta: 3 days, 19:45:50, time: 1.514, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:10:55,040 - mmdet - INFO - Epoch [1][2600/32058]	lr: 2.000e-02, eta: 3 days, 19:29:04, time: 1.489, data_time: 0.038, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:12:09,500 - mmdet - INFO - Epoch [1][2650/32058]	lr: 2.000e-02, eta: 3 days, 19:12:55, time: 1.489, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:13:25,033 - mmdet - INFO - Epoch [1][2700/32058]	lr: 2.000e-02, eta: 3 days, 18:58:34, time: 1.511, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:14:39,633 - mmdet - INFO - Epoch [1][2750/32058]	lr: 2.000e-02, eta: 3 days, 18:43:38, time: 1.492, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:15:55,457 - mmdet - INFO - Epoch [1][2800/32058]	lr: 2.000e-02, eta: 3 days, 18:30:34, time: 1.516, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:17:09,926 - mmdet - INFO - Epoch [1][2850/32058]	lr: 2.000e-02, eta: 3 days, 18:16:24, time: 1.489, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:18:26,036 - mmdet - INFO - Epoch [1][2900/32058]	lr: 2.000e-02, eta: 3 days, 18:04:29, time: 1.522, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:19:40,570 - mmdet - INFO - Epoch [1][2950/32058]	lr: 2.000e-02, eta: 3 days, 17:51:14, time: 1.491, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:20:55,842 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-05 23:20:55,842 - mmdet - INFO - Epoch [1][3000/32058]	lr: 2.000e-02, eta: 3 days, 17:39:10, time: 1.505, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:22:10,319 - mmdet - INFO - Epoch [1][3050/32058]	lr: 2.000e-02, eta: 3 days, 17:26:37, time: 1.490, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:23:23,340 - mmdet - INFO - Epoch [1][3100/32058]	lr: 2.000e-02, eta: 3 days, 17:12:58, time: 1.460, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:24:38,491 - mmdet - INFO - Epoch [1][3150/32058]	lr: 2.000e-02, eta: 3 days, 17:01:50, time: 1.503, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:25:52,246 - mmdet - INFO - Epoch [1][3200/32058]	lr: 2.000e-02, eta: 3 days, 16:49:38, time: 1.475, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:27:06,664 - mmdet - INFO - Epoch [1][3250/32058]	lr: 2.000e-02, eta: 3 days, 16:38:25, time: 1.488, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:28:21,993 - mmdet - INFO - Epoch [1][3300/32058]	lr: 2.000e-02, eta: 3 days, 16:28:23, time: 1.507, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:29:35,625 - mmdet - INFO - Epoch [1][3350/32058]	lr: 2.000e-02, eta: 3 days, 16:17:00, time: 1.473, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:30:50,295 - mmdet - INFO - Epoch [1][3400/32058]	lr: 2.000e-02, eta: 3 days, 16:06:53, time: 1.493, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:32:04,103 - mmdet - INFO - Epoch [1][3450/32058]	lr: 2.000e-02, eta: 3 days, 15:56:14, time: 1.476, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:33:17,551 - mmdet - INFO - Epoch [1][3500/32058]	lr: 2.000e-02, eta: 3 days, 15:45:32, time: 1.469, data_time: 0.016, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:34:33,641 - mmdet - INFO - Epoch [1][3550/32058]	lr: 2.000e-02, eta: 3 days, 15:37:26, time: 1.522, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:35:47,966 - mmdet - INFO - Epoch [1][3600/32058]	lr: 2.000e-02, eta: 3 days, 15:28:00, time: 1.487, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:37:01,609 - mmdet - INFO - Epoch [1][3650/32058]	lr: 2.000e-02, eta: 3 days, 15:18:11, time: 1.473, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:38:15,612 - mmdet - INFO - Epoch [1][3700/32058]	lr: 2.000e-02, eta: 3 days, 15:08:55, time: 1.480, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:39:29,148 - mmdet - INFO - Epoch [1][3750/32058]	lr: 2.000e-02, eta: 3 days, 14:59:28, time: 1.471, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:40:43,384 - mmdet - INFO - Epoch [1][3800/32058]	lr: 2.000e-02, eta: 3 days, 14:50:49, time: 1.485, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:41:57,842 - mmdet - INFO - Epoch [1][3850/32058]	lr: 2.000e-02, eta: 3 days, 14:42:32, time: 1.489, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:43:12,327 - mmdet - INFO - Epoch [1][3900/32058]	lr: 2.000e-02, eta: 3 days, 14:34:27, time: 1.490, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:44:27,699 - mmdet - INFO - Epoch [1][3950/32058]	lr: 2.000e-02, eta: 3 days, 14:27:16, time: 1.507, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:45:41,821 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-05 23:45:41,822 - mmdet - INFO - Epoch [1][4000/32058]	lr: 2.000e-02, eta: 3 days, 14:19:14, time: 1.482, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:46:56,489 - mmdet - INFO - Epoch [1][4050/32058]	lr: 2.000e-02, eta: 3 days, 14:11:47, time: 1.493, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:48:11,675 - mmdet - INFO - Epoch [1][4100/32058]	lr: 2.000e-02, eta: 3 days, 14:04:54, time: 1.504, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:49:25,816 - mmdet - INFO - Epoch [1][4150/32058]	lr: 2.000e-02, eta: 3 days, 13:57:21, time: 1.483, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:50:40,701 - mmdet - INFO - Epoch [1][4200/32058]	lr: 2.000e-02, eta: 3 days, 13:50:31, time: 1.498, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:51:55,688 - mmdet - INFO - Epoch [1][4250/32058]	lr: 2.000e-02, eta: 3 days, 13:43:53, time: 1.500, data_time: 0.024, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:53:09,548 - mmdet - INFO - Epoch [1][4300/32058]	lr: 2.000e-02, eta: 3 days, 13:36:33, time: 1.477, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:54:24,375 - mmdet - INFO - Epoch [1][4350/32058]	lr: 2.000e-02, eta: 3 days, 13:30:03, time: 1.497, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:55:38,037 - mmdet - INFO - Epoch [1][4400/32058]	lr: 2.000e-02, eta: 3 days, 13:22:51, time: 1.473, data_time: 0.016, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:56:53,318 - mmdet - INFO - Epoch [1][4450/32058]	lr: 2.000e-02, eta: 3 days, 13:16:55, time: 1.506, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:58:07,647 - mmdet - INFO - Epoch [1][4500/32058]	lr: 2.000e-02, eta: 3 days, 13:10:26, time: 1.487, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-05 23:59:21,399 - mmdet - INFO - Epoch [1][4550/32058]	lr: 2.000e-02, eta: 3 days, 13:03:40, time: 1.475, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:00:35,154 - mmdet - INFO - Epoch [1][4600/32058]	lr: 2.000e-02, eta: 3 days, 12:57:01, time: 1.475, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:01:49,594 - mmdet - INFO - Epoch [1][4650/32058]	lr: 2.000e-02, eta: 3 days, 12:50:57, time: 1.489, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:03:04,071 - mmdet - INFO - Epoch [1][4700/32058]	lr: 2.000e-02, eta: 3 days, 12:45:00, time: 1.490, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:04:18,810 - mmdet - INFO - Epoch [1][4750/32058]	lr: 2.000e-02, eta: 3 days, 12:39:20, time: 1.495, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:05:33,267 - mmdet - INFO - Epoch [1][4800/32058]	lr: 2.000e-02, eta: 3 days, 12:33:34, time: 1.489, data_time: 0.016, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:06:48,973 - mmdet - INFO - Epoch [1][4850/32058]	lr: 2.000e-02, eta: 3 days, 12:28:42, time: 1.514, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:08:04,122 - mmdet - INFO - Epoch [1][4900/32058]	lr: 2.000e-02, eta: 3 days, 12:23:33, time: 1.503, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:09:18,530 - mmdet - INFO - Epoch [1][4950/32058]	lr: 2.000e-02, eta: 3 days, 12:18:01, time: 1.488, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:10:32,978 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 00:10:32,979 - mmdet - INFO - Epoch [1][5000/32058]	lr: 2.000e-02, eta: 3 days, 12:12:36, time: 1.489, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:11:47,682 - mmdet - INFO - Epoch [1][5050/32058]	lr: 2.000e-02, eta: 3 days, 12:07:25, time: 1.494, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:13:01,596 - mmdet - INFO - Epoch [1][5100/32058]	lr: 2.000e-02, eta: 3 days, 12:01:49, time: 1.478, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:14:15,537 - mmdet - INFO - Epoch [1][5150/32058]	lr: 2.000e-02, eta: 3 days, 11:56:20, time: 1.479, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:15:28,988 - mmdet - INFO - Epoch [1][5200/32058]	lr: 2.000e-02, eta: 3 days, 11:50:38, time: 1.469, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:16:44,225 - mmdet - INFO - Epoch [1][5250/32058]	lr: 2.000e-02, eta: 3 days, 11:46:05, time: 1.505, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:17:59,212 - mmdet - INFO - Epoch [1][5300/32058]	lr: 2.000e-02, eta: 3 days, 11:41:26, time: 1.500, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:19:12,654 - mmdet - INFO - Epoch [1][5350/32058]	lr: 2.000e-02, eta: 3 days, 11:35:58, time: 1.469, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:20:27,329 - mmdet - INFO - Epoch [1][5400/32058]	lr: 2.000e-02, eta: 3 days, 11:31:17, time: 1.493, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:21:42,542 - mmdet - INFO - Epoch [1][5450/32058]	lr: 2.000e-02, eta: 3 days, 11:26:58, time: 1.504, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:22:57,326 - mmdet - INFO - Epoch [1][5500/32058]	lr: 2.000e-02, eta: 3 days, 11:22:28, time: 1.496, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:24:11,309 - mmdet - INFO - Epoch [1][5550/32058]	lr: 2.000e-02, eta: 3 days, 11:17:34, time: 1.480, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:25:26,155 - mmdet - INFO - Epoch [1][5600/32058]	lr: 2.000e-02, eta: 3 days, 11:13:13, time: 1.497, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:26:41,353 - mmdet - INFO - Epoch [1][5650/32058]	lr: 2.000e-02, eta: 3 days, 11:09:07, time: 1.504, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:27:55,917 - mmdet - INFO - Epoch [1][5700/32058]	lr: 2.000e-02, eta: 3 days, 11:04:44, time: 1.491, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:29:09,795 - mmdet - INFO - Epoch [1][5750/32058]	lr: 2.000e-02, eta: 3 days, 11:00:01, time: 1.478, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:30:24,063 - mmdet - INFO - Epoch [1][5800/32058]	lr: 2.000e-02, eta: 3 days, 10:55:34, time: 1.485, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:31:39,280 - mmdet - INFO - Epoch [1][5850/32058]	lr: 2.000e-02, eta: 3 days, 10:51:41, time: 1.504, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:32:54,891 - mmdet - INFO - Epoch [1][5900/32058]	lr: 2.000e-02, eta: 3 days, 10:48:03, time: 1.512, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:34:08,826 - mmdet - INFO - Epoch [1][5950/32058]	lr: 2.000e-02, eta: 3 days, 10:43:36, time: 1.479, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:35:23,961 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 00:35:23,961 - mmdet - INFO - Epoch [1][6000/32058]	lr: 2.000e-02, eta: 3 days, 10:39:48, time: 1.503, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:36:37,289 - mmdet - INFO - Epoch [1][6050/32058]	lr: 2.000e-02, eta: 3 days, 10:35:07, time: 1.467, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:37:52,123 - mmdet - INFO - Epoch [1][6100/32058]	lr: 2.000e-02, eta: 3 days, 10:31:16, time: 1.497, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:39:06,794 - mmdet - INFO - Epoch [1][6150/32058]	lr: 2.000e-02, eta: 3 days, 10:27:23, time: 1.493, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:40:20,834 - mmdet - INFO - Epoch [1][6200/32058]	lr: 2.000e-02, eta: 3 days, 10:23:13, time: 1.481, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:41:35,340 - mmdet - INFO - Epoch [1][6250/32058]	lr: 2.000e-02, eta: 3 days, 10:19:19, time: 1.490, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:42:49,133 - mmdet - INFO - Epoch [1][6300/32058]	lr: 2.000e-02, eta: 3 days, 10:15:07, time: 1.476, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:44:03,722 - mmdet - INFO - Epoch [1][6350/32058]	lr: 2.000e-02, eta: 3 days, 10:11:22, time: 1.492, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:45:19,614 - mmdet - INFO - Epoch [1][6400/32058]	lr: 2.000e-02, eta: 3 days, 10:08:16, time: 1.518, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:46:33,936 - mmdet - INFO - Epoch [1][6450/32058]	lr: 2.000e-02, eta: 3 days, 10:04:27, time: 1.486, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:47:48,020 - mmdet - INFO - Epoch [1][6500/32058]	lr: 2.000e-02, eta: 3 days, 10:00:34, time: 1.482, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:49:02,696 - mmdet - INFO - Epoch [1][6550/32058]	lr: 2.000e-02, eta: 3 days, 9:56:59, time: 1.494, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:50:16,366 - mmdet - INFO - Epoch [1][6600/32058]	lr: 2.000e-02, eta: 3 days, 9:52:59, time: 1.473, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:51:29,621 - mmdet - INFO - Epoch [1][6650/32058]	lr: 2.000e-02, eta: 3 days, 9:48:49, time: 1.465, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:52:45,092 - mmdet - INFO - Epoch [1][6700/32058]	lr: 2.000e-02, eta: 3 days, 9:45:44, time: 1.509, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:54:01,115 - mmdet - INFO - Epoch [1][6750/32058]	lr: 2.000e-02, eta: 3 days, 9:42:55, time: 1.520, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:55:16,508 - mmdet - INFO - Epoch [1][6800/32058]	lr: 2.000e-02, eta: 3 days, 9:39:51, time: 1.508, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:56:30,509 - mmdet - INFO - Epoch [1][6850/32058]	lr: 2.000e-02, eta: 3 days, 9:36:10, time: 1.480, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:57:45,256 - mmdet - INFO - Epoch [1][6900/32058]	lr: 2.000e-02, eta: 3 days, 9:32:52, time: 1.495, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 00:58:59,108 - mmdet - INFO - Epoch [1][6950/32058]	lr: 2.000e-02, eta: 3 days, 9:29:11, time: 1.477, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:00:15,050 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 01:00:15,050 - mmdet - INFO - Epoch [1][7000/32058]	lr: 2.000e-02, eta: 3 days, 9:26:28, time: 1.519, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:01:29,449 - mmdet - INFO - Epoch [1][7050/32058]	lr: 2.000e-02, eta: 3 days, 9:23:05, time: 1.488, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:02:43,072 - mmdet - INFO - Epoch [1][7100/32058]	lr: 2.000e-02, eta: 3 days, 9:19:25, time: 1.472, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:03:57,626 - mmdet - INFO - Epoch [1][7150/32058]	lr: 2.000e-02, eta: 3 days, 9:16:10, time: 1.491, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:05:12,051 - mmdet - INFO - Epoch [1][7200/32058]	lr: 2.000e-02, eta: 3 days, 9:12:53, time: 1.489, data_time: 0.016, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:06:26,784 - mmdet - INFO - Epoch [1][7250/32058]	lr: 2.000e-02, eta: 3 days, 9:09:47, time: 1.495, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:07:41,685 - mmdet - INFO - Epoch [1][7300/32058]	lr: 2.000e-02, eta: 3 days, 9:06:46, time: 1.498, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:08:56,187 - mmdet - INFO - Epoch [1][7350/32058]	lr: 2.000e-02, eta: 3 days, 9:03:36, time: 1.490, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:10:11,506 - mmdet - INFO - Epoch [1][7400/32058]	lr: 2.000e-02, eta: 3 days, 9:00:48, time: 1.506, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:11:26,800 - mmdet - INFO - Epoch [1][7450/32058]	lr: 2.000e-02, eta: 3 days, 8:58:01, time: 1.506, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:12:40,863 - mmdet - INFO - Epoch [1][7500/32058]	lr: 2.000e-02, eta: 3 days, 8:54:45, time: 1.481, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:13:54,935 - mmdet - INFO - Epoch [1][7550/32058]	lr: 2.000e-02, eta: 3 days, 8:51:31, time: 1.481, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:15:09,096 - mmdet - INFO - Epoch [1][7600/32058]	lr: 2.000e-02, eta: 3 days, 8:48:20, time: 1.483, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:16:24,348 - mmdet - INFO - Epoch [1][7650/32058]	lr: 2.000e-02, eta: 3 days, 8:45:38, time: 1.505, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:17:38,270 - mmdet - INFO - Epoch [1][7700/32058]	lr: 2.000e-02, eta: 3 days, 8:42:24, time: 1.478, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:18:53,087 - mmdet - INFO - Epoch [1][7750/32058]	lr: 2.000e-02, eta: 3 days, 8:39:34, time: 1.496, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:20:08,201 - mmdet - INFO - Epoch [1][7800/32058]	lr: 2.000e-02, eta: 3 days, 8:36:51, time: 1.502, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:21:23,221 - mmdet - INFO - Epoch [1][7850/32058]	lr: 2.000e-02, eta: 3 days, 8:34:08, time: 1.500, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:22:37,346 - mmdet - INFO - Epoch [1][7900/32058]	lr: 2.000e-02, eta: 3 days, 8:31:05, time: 1.482, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:23:51,278 - mmdet - INFO - Epoch [1][7950/32058]	lr: 2.000e-02, eta: 3 days, 8:27:58, time: 1.479, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:25:06,533 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 01:25:06,534 - mmdet - INFO - Epoch [1][8000/32058]	lr: 2.000e-02, eta: 3 days, 8:25:24, time: 1.505, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:26:21,661 - mmdet - INFO - Epoch [1][8050/32058]	lr: 2.000e-02, eta: 3 days, 8:22:48, time: 1.503, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:27:35,237 - mmdet - INFO - Epoch [1][8100/32058]	lr: 2.000e-02, eta: 3 days, 8:19:37, time: 1.471, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:28:51,093 - mmdet - INFO - Epoch [1][8150/32058]	lr: 2.000e-02, eta: 3 days, 8:17:19, time: 1.517, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:30:05,146 - mmdet - INFO - Epoch [1][8200/32058]	lr: 2.000e-02, eta: 3 days, 8:14:22, time: 1.481, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:31:19,949 - mmdet - INFO - Epoch [1][8250/32058]	lr: 2.000e-02, eta: 3 days, 8:11:43, time: 1.496, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:32:34,541 - mmdet - INFO - Epoch [1][8300/32058]	lr: 2.000e-02, eta: 3 days, 8:08:59, time: 1.492, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:33:49,063 - mmdet - INFO - Epoch [1][8350/32058]	lr: 2.000e-02, eta: 3 days, 8:06:16, time: 1.490, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:35:03,633 - mmdet - INFO - Epoch [1][8400/32058]	lr: 2.000e-02, eta: 3 days, 8:03:34, time: 1.491, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:36:18,194 - mmdet - INFO - Epoch [1][8450/32058]	lr: 2.000e-02, eta: 3 days, 8:00:54, time: 1.491, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:37:33,354 - mmdet - INFO - Epoch [1][8500/32058]	lr: 2.000e-02, eta: 3 days, 7:58:27, time: 1.503, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:38:48,499 - mmdet - INFO - Epoch [1][8550/32058]	lr: 2.000e-02, eta: 3 days, 7:56:01, time: 1.503, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:40:02,746 - mmdet - INFO - Epoch [1][8600/32058]	lr: 2.000e-02, eta: 3 days, 7:53:17, time: 1.485, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:41:16,752 - mmdet - INFO - Epoch [1][8650/32058]	lr: 2.000e-02, eta: 3 days, 7:50:28, time: 1.480, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:42:30,722 - mmdet - INFO - Epoch [1][8700/32058]	lr: 2.000e-02, eta: 3 days, 7:47:40, time: 1.479, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:43:44,524 - mmdet - INFO - Epoch [1][8750/32058]	lr: 2.000e-02, eta: 3 days, 7:44:49, time: 1.476, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:45:00,474 - mmdet - INFO - Epoch [1][8800/32058]	lr: 2.000e-02, eta: 3 days, 7:42:44, time: 1.519, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:46:15,402 - mmdet - INFO - Epoch [1][8850/32058]	lr: 2.000e-02, eta: 3 days, 7:40:19, time: 1.499, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:47:29,809 - mmdet - INFO - Epoch [1][8900/32058]	lr: 2.000e-02, eta: 3 days, 7:37:43, time: 1.488, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:48:44,384 - mmdet - INFO - Epoch [1][8950/32058]	lr: 2.000e-02, eta: 3 days, 7:35:12, time: 1.491, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:49:59,541 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 01:49:59,542 - mmdet - INFO - Epoch [1][9000/32058]	lr: 2.000e-02, eta: 3 days, 7:32:54, time: 1.503, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:51:14,382 - mmdet - INFO - Epoch [1][9050/32058]	lr: 2.000e-02, eta: 3 days, 7:30:30, time: 1.497, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:52:27,886 - mmdet - INFO - Epoch [1][9100/32058]	lr: 2.000e-02, eta: 3 days, 7:27:40, time: 1.470, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:53:41,918 - mmdet - INFO - Epoch [1][9150/32058]	lr: 2.000e-02, eta: 3 days, 7:25:01, time: 1.481, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:54:56,073 - mmdet - INFO - Epoch [1][9200/32058]	lr: 2.000e-02, eta: 3 days, 7:22:26, time: 1.483, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:56:10,609 - mmdet - INFO - Epoch [1][9250/32058]	lr: 2.000e-02, eta: 3 days, 7:19:59, time: 1.491, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:57:24,716 - mmdet - INFO - Epoch [1][9300/32058]	lr: 2.000e-02, eta: 3 days, 7:17:25, time: 1.482, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:58:38,765 - mmdet - INFO - Epoch [1][9350/32058]	lr: 2.000e-02, eta: 3 days, 7:14:50, time: 1.481, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 01:59:54,577 - mmdet - INFO - Epoch [1][9400/32058]	lr: 2.000e-02, eta: 3 days, 7:12:51, time: 1.516, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:01:08,861 - mmdet - INFO - Epoch [1][9450/32058]	lr: 2.000e-02, eta: 3 days, 7:10:22, time: 1.486, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:02:23,651 - mmdet - INFO - Epoch [1][9500/32058]	lr: 2.000e-02, eta: 3 days, 7:08:04, time: 1.496, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:03:37,114 - mmdet - INFO - Epoch [1][9550/32058]	lr: 2.000e-02, eta: 3 days, 7:05:21, time: 1.469, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:04:52,137 - mmdet - INFO - Epoch [1][9600/32058]	lr: 2.000e-02, eta: 3 days, 7:03:09, time: 1.500, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:06:05,594 - mmdet - INFO - Epoch [1][9650/32058]	lr: 2.000e-02, eta: 3 days, 7:00:27, time: 1.469, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:07:19,965 - mmdet - INFO - Epoch [1][9700/32058]	lr: 2.000e-02, eta: 3 days, 6:58:04, time: 1.487, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:08:33,802 - mmdet - INFO - Epoch [1][9750/32058]	lr: 2.000e-02, eta: 3 days, 6:55:32, time: 1.477, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:09:48,787 - mmdet - INFO - Epoch [1][9800/32058]	lr: 2.000e-02, eta: 3 days, 6:53:21, time: 1.500, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:11:02,858 - mmdet - INFO - Epoch [1][9850/32058]	lr: 2.000e-02, eta: 3 days, 6:50:55, time: 1.481, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:12:16,812 - mmdet - INFO - Epoch [1][9900/32058]	lr: 2.000e-02, eta: 3 days, 6:48:27, time: 1.479, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:13:30,772 - mmdet - INFO - Epoch [1][9950/32058]	lr: 2.000e-02, eta: 3 days, 6:45:59, time: 1.479, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:14:45,265 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 02:14:45,265 - mmdet - INFO - Epoch [1][10000/32058]	lr: 2.000e-02, eta: 3 days, 6:43:43, time: 1.490, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:15:59,708 - mmdet - INFO - Epoch [1][10050/32058]	lr: 2.000e-02, eta: 3 days, 6:41:26, time: 1.489, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:17:14,516 - mmdet - INFO - Epoch [1][10100/32058]	lr: 2.000e-02, eta: 3 days, 6:39:16, time: 1.496, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:18:29,160 - mmdet - INFO - Epoch [1][10150/32058]	lr: 2.000e-02, eta: 3 days, 6:37:03, time: 1.493, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:19:44,129 - mmdet - INFO - Epoch [1][10200/32058]	lr: 2.000e-02, eta: 3 days, 6:34:58, time: 1.499, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:21:00,182 - mmdet - INFO - Epoch [1][10250/32058]	lr: 2.000e-02, eta: 3 days, 6:33:11, time: 1.521, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:22:14,973 - mmdet - INFO - Epoch [1][10300/32058]	lr: 2.000e-02, eta: 3 days, 6:31:03, time: 1.496, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:23:28,790 - mmdet - INFO - Epoch [1][10350/32058]	lr: 2.000e-02, eta: 3 days, 6:28:38, time: 1.476, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:24:43,590 - mmdet - INFO - Epoch [1][10400/32058]	lr: 2.000e-02, eta: 3 days, 6:26:32, time: 1.496, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:25:58,601 - mmdet - INFO - Epoch [1][10450/32058]	lr: 2.000e-02, eta: 3 days, 6:24:29, time: 1.500, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:27:12,348 - mmdet - INFO - Epoch [1][10500/32058]	lr: 2.000e-02, eta: 3 days, 6:22:05, time: 1.475, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:28:27,157 - mmdet - INFO - Epoch [1][10550/32058]	lr: 2.000e-02, eta: 3 days, 6:20:00, time: 1.496, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:29:42,623 - mmdet - INFO - Epoch [1][10600/32058]	lr: 2.000e-02, eta: 3 days, 6:18:06, time: 1.509, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:30:57,299 - mmdet - INFO - Epoch [1][10650/32058]	lr: 2.000e-02, eta: 3 days, 6:16:00, time: 1.494, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:32:11,272 - mmdet - INFO - Epoch [1][10700/32058]	lr: 2.000e-02, eta: 3 days, 6:13:42, time: 1.479, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:33:26,700 - mmdet - INFO - Epoch [1][10750/32058]	lr: 2.000e-02, eta: 3 days, 6:11:49, time: 1.509, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:34:41,970 - mmdet - INFO - Epoch [1][10800/32058]	lr: 2.000e-02, eta: 3 days, 6:09:54, time: 1.505, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:35:56,022 - mmdet - INFO - Epoch [1][10850/32058]	lr: 2.000e-02, eta: 3 days, 6:07:38, time: 1.481, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:37:11,188 - mmdet - INFO - Epoch [1][10900/32058]	lr: 2.000e-02, eta: 3 days, 6:05:42, time: 1.503, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:38:25,067 - mmdet - INFO - Epoch [1][10950/32058]	lr: 2.000e-02, eta: 3 days, 6:03:25, time: 1.478, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:39:39,302 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 02:39:39,302 - mmdet - INFO - Epoch [1][11000/32058]	lr: 2.000e-02, eta: 3 days, 6:01:15, time: 1.485, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:40:53,619 - mmdet - INFO - Epoch [1][11050/32058]	lr: 2.000e-02, eta: 3 days, 5:59:06, time: 1.486, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:42:08,449 - mmdet - INFO - Epoch [1][11100/32058]	lr: 2.000e-02, eta: 3 days, 5:57:06, time: 1.497, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:43:23,000 - mmdet - INFO - Epoch [1][11150/32058]	lr: 2.000e-02, eta: 3 days, 5:55:02, time: 1.491, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:44:36,219 - mmdet - INFO - Epoch [1][11200/32058]	lr: 2.000e-02, eta: 3 days, 5:52:37, time: 1.464, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:45:51,113 - mmdet - INFO - Epoch [1][11250/32058]	lr: 2.000e-02, eta: 3 days, 5:50:40, time: 1.498, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:47:06,309 - mmdet - INFO - Epoch [1][11300/32058]	lr: 2.000e-02, eta: 3 days, 5:48:47, time: 1.504, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:48:21,865 - mmdet - INFO - Epoch [1][11350/32058]	lr: 2.000e-02, eta: 3 days, 5:47:01, time: 1.511, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:49:36,008 - mmdet - INFO - Epoch [1][11400/32058]	lr: 2.000e-02, eta: 3 days, 5:44:53, time: 1.483, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:50:51,020 - mmdet - INFO - Epoch [1][11450/32058]	lr: 2.000e-02, eta: 3 days, 5:42:59, time: 1.500, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:52:04,937 - mmdet - INFO - Epoch [1][11500/32058]	lr: 2.000e-02, eta: 3 days, 5:40:48, time: 1.478, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:53:19,205 - mmdet - INFO - Epoch [1][11550/32058]	lr: 2.000e-02, eta: 3 days, 5:38:43, time: 1.485, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:54:34,850 - mmdet - INFO - Epoch [1][11600/32058]	lr: 2.000e-02, eta: 3 days, 5:37:00, time: 1.513, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:55:49,789 - mmdet - INFO - Epoch [1][11650/32058]	lr: 2.000e-02, eta: 3 days, 5:35:06, time: 1.499, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:57:04,125 - mmdet - INFO - Epoch [1][11700/32058]	lr: 2.000e-02, eta: 3 days, 5:33:03, time: 1.487, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:58:20,044 - mmdet - INFO - Epoch [1][11750/32058]	lr: 2.000e-02, eta: 3 days, 5:31:25, time: 1.518, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 02:59:34,155 - mmdet - INFO - Epoch [1][11800/32058]	lr: 2.000e-02, eta: 3 days, 5:29:19, time: 1.482, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:00:48,878 - mmdet - INFO - Epoch [1][11850/32058]	lr: 2.000e-02, eta: 3 days, 5:27:24, time: 1.494, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:02:03,081 - mmdet - INFO - Epoch [1][11900/32058]	lr: 2.000e-02, eta: 3 days, 5:25:20, time: 1.484, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:03:17,914 - mmdet - INFO - Epoch [1][11950/32058]	lr: 2.000e-02, eta: 3 days, 5:23:27, time: 1.497, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:04:31,908 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 03:04:31,908 - mmdet - INFO - Epoch [1][12000/32058]	lr: 2.000e-02, eta: 3 days, 5:21:21, time: 1.480, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:05:46,536 - mmdet - INFO - Epoch [1][12050/32058]	lr: 2.000e-02, eta: 3 days, 5:19:25, time: 1.493, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:06:59,839 - mmdet - INFO - Epoch [1][12100/32058]	lr: 2.000e-02, eta: 3 days, 5:17:10, time: 1.466, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:08:13,909 - mmdet - INFO - Epoch [1][12150/32058]	lr: 2.000e-02, eta: 3 days, 5:15:07, time: 1.481, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:09:28,172 - mmdet - INFO - Epoch [1][12200/32058]	lr: 2.000e-02, eta: 3 days, 5:13:07, time: 1.485, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:10:40,269 - mmdet - INFO - Epoch [1][12250/32058]	lr: 2.000e-02, eta: 3 days, 5:10:35, time: 1.442, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:11:54,466 - mmdet - INFO - Epoch [1][12300/32058]	lr: 2.000e-02, eta: 3 days, 5:08:35, time: 1.484, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:13:08,418 - mmdet - INFO - Epoch [1][12350/32058]	lr: 2.000e-02, eta: 3 days, 5:06:32, time: 1.479, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:14:22,911 - mmdet - INFO - Epoch [1][12400/32058]	lr: 2.000e-02, eta: 3 days, 5:04:37, time: 1.490, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:15:37,495 - mmdet - INFO - Epoch [1][12450/32058]	lr: 2.000e-02, eta: 3 days, 5:02:43, time: 1.492, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:16:50,523 - mmdet - INFO - Epoch [1][12500/32058]	lr: 2.000e-02, eta: 3 days, 5:00:28, time: 1.461, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:18:04,634 - mmdet - INFO - Epoch [1][12550/32058]	lr: 2.000e-02, eta: 3 days, 4:58:28, time: 1.482, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:19:18,676 - mmdet - INFO - Epoch [1][12600/32058]	lr: 2.000e-02, eta: 3 days, 4:56:28, time: 1.481, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:20:33,877 - mmdet - INFO - Epoch [1][12650/32058]	lr: 2.000e-02, eta: 3 days, 4:54:45, time: 1.504, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:21:48,526 - mmdet - INFO - Epoch [1][12700/32058]	lr: 2.000e-02, eta: 3 days, 4:52:54, time: 1.493, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:23:04,353 - mmdet - INFO - Epoch [1][12750/32058]	lr: 2.000e-02, eta: 3 days, 4:51:20, time: 1.517, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:24:19,175 - mmdet - INFO - Epoch [1][12800/32058]	lr: 2.000e-02, eta: 3 days, 4:49:32, time: 1.496, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:25:34,346 - mmdet - INFO - Epoch [1][12850/32058]	lr: 2.000e-02, eta: 3 days, 4:47:49, time: 1.503, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:26:49,491 - mmdet - INFO - Epoch [1][12900/32058]	lr: 2.000e-02, eta: 3 days, 4:46:06, time: 1.503, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:28:03,811 - mmdet - INFO - Epoch [1][12950/32058]	lr: 2.000e-02, eta: 3 days, 4:44:12, time: 1.486, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:29:19,871 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 03:29:19,871 - mmdet - INFO - Epoch [1][13000/32058]	lr: 2.000e-02, eta: 3 days, 4:42:42, time: 1.521, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:30:34,897 - mmdet - INFO - Epoch [1][13050/32058]	lr: 2.000e-02, eta: 3 days, 4:40:58, time: 1.500, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:31:49,707 - mmdet - INFO - Epoch [1][13100/32058]	lr: 2.000e-02, eta: 3 days, 4:39:11, time: 1.496, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:33:03,861 - mmdet - INFO - Epoch [1][13150/32058]	lr: 2.000e-02, eta: 3 days, 4:37:16, time: 1.483, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:34:18,794 - mmdet - INFO - Epoch [1][13200/32058]	lr: 2.000e-02, eta: 3 days, 4:35:31, time: 1.499, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:35:33,844 - mmdet - INFO - Epoch [1][13250/32058]	lr: 2.000e-02, eta: 3 days, 4:33:48, time: 1.501, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:36:47,833 - mmdet - INFO - Epoch [1][13300/32058]	lr: 2.000e-02, eta: 3 days, 4:31:52, time: 1.480, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:38:02,882 - mmdet - INFO - Epoch [1][13350/32058]	lr: 2.000e-02, eta: 3 days, 4:30:09, time: 1.501, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:39:17,206 - mmdet - INFO - Epoch [1][13400/32058]	lr: 2.000e-02, eta: 3 days, 4:28:18, time: 1.486, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:40:31,719 - mmdet - INFO - Epoch [1][13450/32058]	lr: 2.000e-02, eta: 3 days, 4:26:29, time: 1.490, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:41:44,478 - mmdet - INFO - Epoch [1][13500/32058]	lr: 2.000e-02, eta: 3 days, 4:24:17, time: 1.455, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:42:58,754 - mmdet - INFO - Epoch [1][13550/32058]	lr: 2.000e-02, eta: 3 days, 4:22:25, time: 1.486, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:44:13,321 - mmdet - INFO - Epoch [1][13600/32058]	lr: 2.000e-02, eta: 3 days, 4:20:38, time: 1.491, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:45:28,349 - mmdet - INFO - Epoch [1][13650/32058]	lr: 2.000e-02, eta: 3 days, 4:18:57, time: 1.501, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:46:42,530 - mmdet - INFO - Epoch [1][13700/32058]	lr: 2.000e-02, eta: 3 days, 4:17:05, time: 1.484, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:47:57,187 - mmdet - INFO - Epoch [1][13750/32058]	lr: 2.000e-02, eta: 3 days, 4:15:19, time: 1.493, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:49:12,267 - mmdet - INFO - Epoch [1][13800/32058]	lr: 2.000e-02, eta: 3 days, 4:13:39, time: 1.502, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:50:27,376 - mmdet - INFO - Epoch [1][13850/32058]	lr: 2.000e-02, eta: 3 days, 4:12:00, time: 1.502, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:51:41,062 - mmdet - INFO - Epoch [1][13900/32058]	lr: 2.000e-02, eta: 3 days, 4:10:03, time: 1.474, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:52:53,778 - mmdet - INFO - Epoch [1][13950/32058]	lr: 2.000e-02, eta: 3 days, 4:07:53, time: 1.454, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:54:07,940 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 03:54:07,941 - mmdet - INFO - Epoch [1][14000/32058]	lr: 2.000e-02, eta: 3 days, 4:06:03, time: 1.483, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:55:22,159 - mmdet - INFO - Epoch [1][14050/32058]	lr: 2.000e-02, eta: 3 days, 4:04:13, time: 1.484, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:56:36,551 - mmdet - INFO - Epoch [1][14100/32058]	lr: 2.000e-02, eta: 3 days, 4:02:26, time: 1.488, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:57:51,002 - mmdet - INFO - Epoch [1][14150/32058]	lr: 2.000e-02, eta: 3 days, 4:00:40, time: 1.489, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 03:59:06,609 - mmdet - INFO - Epoch [1][14200/32058]	lr: 2.000e-02, eta: 3 days, 3:59:08, time: 1.512, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:00:20,401 - mmdet - INFO - Epoch [1][14250/32058]	lr: 2.000e-02, eta: 3 days, 3:57:14, time: 1.476, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:01:35,397 - mmdet - INFO - Epoch [1][14300/32058]	lr: 2.000e-02, eta: 3 days, 3:55:35, time: 1.500, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:02:50,372 - mmdet - INFO - Epoch [1][14350/32058]	lr: 2.000e-02, eta: 3 days, 3:53:56, time: 1.499, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:04:04,240 - mmdet - INFO - Epoch [1][14400/32058]	lr: 2.000e-02, eta: 3 days, 3:52:04, time: 1.477, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:05:16,999 - mmdet - INFO - Epoch [1][14450/32058]	lr: 2.000e-02, eta: 3 days, 3:49:58, time: 1.455, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:06:31,812 - mmdet - INFO - Epoch [1][14500/32058]	lr: 2.000e-02, eta: 3 days, 3:48:18, time: 1.496, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:07:46,444 - mmdet - INFO - Epoch [1][14550/32058]	lr: 2.000e-02, eta: 3 days, 3:46:36, time: 1.493, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:09:00,546 - mmdet - INFO - Epoch [1][14600/32058]	lr: 2.000e-02, eta: 3 days, 3:44:47, time: 1.482, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:10:15,681 - mmdet - INFO - Epoch [1][14650/32058]	lr: 2.000e-02, eta: 3 days, 3:43:11, time: 1.503, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:11:31,755 - mmdet - INFO - Epoch [1][14700/32058]	lr: 2.000e-02, eta: 3 days, 3:41:47, time: 1.521, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:12:45,759 - mmdet - INFO - Epoch [1][14750/32058]	lr: 2.000e-02, eta: 3 days, 3:39:58, time: 1.480, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:14:00,787 - mmdet - INFO - Epoch [1][14800/32058]	lr: 2.000e-02, eta: 3 days, 3:38:21, time: 1.501, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:15:15,458 - mmdet - INFO - Epoch [1][14850/32058]	lr: 2.000e-02, eta: 3 days, 3:36:41, time: 1.493, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:16:30,239 - mmdet - INFO - Epoch [1][14900/32058]	lr: 2.000e-02, eta: 3 days, 3:35:01, time: 1.496, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:17:43,283 - mmdet - INFO - Epoch [1][14950/32058]	lr: 2.000e-02, eta: 3 days, 3:33:02, time: 1.461, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:18:58,216 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 04:18:58,216 - mmdet - INFO - Epoch [1][15000/32058]	lr: 2.000e-02, eta: 3 days, 3:31:25, time: 1.499, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:20:12,961 - mmdet - INFO - Epoch [1][15050/32058]	lr: 2.000e-02, eta: 3 days, 3:29:46, time: 1.495, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:21:27,095 - mmdet - INFO - Epoch [1][15100/32058]	lr: 2.000e-02, eta: 3 days, 3:27:59, time: 1.483, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:22:41,243 - mmdet - INFO - Epoch [1][15150/32058]	lr: 2.000e-02, eta: 3 days, 3:26:14, time: 1.483, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:23:56,191 - mmdet - INFO - Epoch [1][15200/32058]	lr: 2.000e-02, eta: 3 days, 3:24:37, time: 1.499, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:25:11,367 - mmdet - INFO - Epoch [1][15250/32058]	lr: 2.000e-02, eta: 3 days, 3:23:04, time: 1.504, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:26:25,646 - mmdet - INFO - Epoch [1][15300/32058]	lr: 2.000e-02, eta: 3 days, 3:21:20, time: 1.486, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:27:39,720 - mmdet - INFO - Epoch [1][15350/32058]	lr: 2.000e-02, eta: 3 days, 3:19:34, time: 1.481, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:28:55,795 - mmdet - INFO - Epoch [1][15400/32058]	lr: 2.000e-02, eta: 3 days, 3:18:12, time: 1.522, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:30:10,588 - mmdet - INFO - Epoch [1][15450/32058]	lr: 2.000e-02, eta: 3 days, 3:16:34, time: 1.496, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:31:25,541 - mmdet - INFO - Epoch [1][15500/32058]	lr: 2.000e-02, eta: 3 days, 3:14:59, time: 1.499, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:32:40,954 - mmdet - INFO - Epoch [1][15550/32058]	lr: 2.000e-02, eta: 3 days, 3:13:29, time: 1.508, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:33:54,860 - mmdet - INFO - Epoch [1][15600/32058]	lr: 2.000e-02, eta: 3 days, 3:11:42, time: 1.478, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:35:09,837 - mmdet - INFO - Epoch [1][15650/32058]	lr: 2.000e-02, eta: 3 days, 3:10:07, time: 1.500, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:36:24,383 - mmdet - INFO - Epoch [1][15700/32058]	lr: 2.000e-02, eta: 3 days, 3:08:28, time: 1.491, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:37:38,870 - mmdet - INFO - Epoch [1][15750/32058]	lr: 2.000e-02, eta: 3 days, 3:06:48, time: 1.490, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:38:52,253 - mmdet - INFO - Epoch [1][15800/32058]	lr: 2.000e-02, eta: 3 days, 3:04:56, time: 1.468, data_time: 0.016, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:40:06,041 - mmdet - INFO - Epoch [1][15850/32058]	lr: 2.000e-02, eta: 3 days, 3:03:09, time: 1.476, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:41:21,716 - mmdet - INFO - Epoch [1][15900/32058]	lr: 2.000e-02, eta: 3 days, 3:01:42, time: 1.513, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:42:35,954 - mmdet - INFO - Epoch [1][15950/32058]	lr: 2.000e-02, eta: 3 days, 3:00:01, time: 1.485, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:43:50,361 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 04:43:50,361 - mmdet - INFO - Epoch [1][16000/32058]	lr: 2.000e-02, eta: 3 days, 2:58:21, time: 1.488, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:45:04,533 - mmdet - INFO - Epoch [1][16050/32058]	lr: 2.000e-02, eta: 3 days, 2:56:38, time: 1.483, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:46:18,124 - mmdet - INFO - Epoch [1][16100/32058]	lr: 2.000e-02, eta: 3 days, 2:54:50, time: 1.472, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:47:32,572 - mmdet - INFO - Epoch [1][16150/32058]	lr: 2.000e-02, eta: 3 days, 2:53:11, time: 1.489, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:48:47,176 - mmdet - INFO - Epoch [1][16200/32058]	lr: 2.000e-02, eta: 3 days, 2:51:33, time: 1.492, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:50:01,034 - mmdet - INFO - Epoch [1][16250/32058]	lr: 2.000e-02, eta: 3 days, 2:49:48, time: 1.477, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:51:15,879 - mmdet - INFO - Epoch [1][16300/32058]	lr: 2.000e-02, eta: 3 days, 2:48:14, time: 1.497, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:52:31,037 - mmdet - INFO - Epoch [1][16350/32058]	lr: 2.000e-02, eta: 3 days, 2:46:43, time: 1.503, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:53:44,569 - mmdet - INFO - Epoch [1][16400/32058]	lr: 2.000e-02, eta: 3 days, 2:44:55, time: 1.471, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:54:58,738 - mmdet - INFO - Epoch [1][16450/32058]	lr: 2.000e-02, eta: 3 days, 2:43:14, time: 1.483, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:56:12,476 - mmdet - INFO - Epoch [1][16500/32058]	lr: 2.000e-02, eta: 3 days, 2:41:29, time: 1.475, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:57:24,875 - mmdet - INFO - Epoch [1][16550/32058]	lr: 2.000e-02, eta: 3 days, 2:39:29, time: 1.448, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:58:39,745 - mmdet - INFO - Epoch [1][16600/32058]	lr: 2.000e-02, eta: 3 days, 2:37:56, time: 1.497, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 04:59:53,071 - mmdet - INFO - Epoch [1][16650/32058]	lr: 2.000e-02, eta: 3 days, 2:36:07, time: 1.467, data_time: 0.015, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:01:08,469 - mmdet - INFO - Epoch [1][16700/32058]	lr: 2.000e-02, eta: 3 days, 2:34:40, time: 1.508, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:02:22,201 - mmdet - INFO - Epoch [1][16750/32058]	lr: 2.000e-02, eta: 3 days, 2:32:55, time: 1.475, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:03:36,525 - mmdet - INFO - Epoch [1][16800/32058]	lr: 2.000e-02, eta: 3 days, 2:31:17, time: 1.486, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:04:50,520 - mmdet - INFO - Epoch [1][16850/32058]	lr: 2.000e-02, eta: 3 days, 2:29:35, time: 1.480, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:06:04,601 - mmdet - INFO - Epoch [1][16900/32058]	lr: 2.000e-02, eta: 3 days, 2:27:54, time: 1.482, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:07:19,713 - mmdet - INFO - Epoch [1][16950/32058]	lr: 2.000e-02, eta: 3 days, 2:26:25, time: 1.502, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:08:33,285 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 05:08:33,285 - mmdet - INFO - Epoch [1][17000/32058]	lr: 2.000e-02, eta: 3 days, 2:24:39, time: 1.471, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:09:47,964 - mmdet - INFO - Epoch [1][17050/32058]	lr: 2.000e-02, eta: 3 days, 2:23:05, time: 1.494, data_time: 0.016, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:11:03,195 - mmdet - INFO - Epoch [1][17100/32058]	lr: 2.000e-02, eta: 3 days, 2:21:37, time: 1.505, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:12:19,261 - mmdet - INFO - Epoch [1][17150/32058]	lr: 2.000e-02, eta: 3 days, 2:20:18, time: 1.521, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:13:33,285 - mmdet - INFO - Epoch [1][17200/32058]	lr: 2.000e-02, eta: 3 days, 2:18:37, time: 1.480, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:14:47,043 - mmdet - INFO - Epoch [1][17250/32058]	lr: 2.000e-02, eta: 3 days, 2:16:54, time: 1.475, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:16:02,297 - mmdet - INFO - Epoch [1][17300/32058]	lr: 2.000e-02, eta: 3 days, 2:15:27, time: 1.505, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:17:16,821 - mmdet - INFO - Epoch [1][17350/32058]	lr: 2.000e-02, eta: 3 days, 2:13:52, time: 1.490, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:18:31,612 - mmdet - INFO - Epoch [1][17400/32058]	lr: 2.000e-02, eta: 3 days, 2:12:20, time: 1.496, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:19:45,303 - mmdet - INFO - Epoch [1][17450/32058]	lr: 2.000e-02, eta: 3 days, 2:10:37, time: 1.474, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:20:59,316 - mmdet - INFO - Epoch [1][17500/32058]	lr: 2.000e-02, eta: 3 days, 2:08:57, time: 1.480, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:22:12,134 - mmdet - INFO - Epoch [1][17550/32058]	lr: 2.000e-02, eta: 3 days, 2:07:06, time: 1.456, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:23:25,961 - mmdet - INFO - Epoch [1][17600/32058]	lr: 2.000e-02, eta: 3 days, 2:05:25, time: 1.477, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:24:39,492 - mmdet - INFO - Epoch [1][17650/32058]	lr: 2.000e-02, eta: 3 days, 2:03:41, time: 1.471, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:25:53,635 - mmdet - INFO - Epoch [1][17700/32058]	lr: 2.000e-02, eta: 3 days, 2:02:03, time: 1.483, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:27:08,757 - mmdet - INFO - Epoch [1][17750/32058]	lr: 2.000e-02, eta: 3 days, 2:00:35, time: 1.502, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:28:24,503 - mmdet - INFO - Epoch [1][17800/32058]	lr: 2.000e-02, eta: 3 days, 1:59:14, time: 1.515, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:29:39,664 - mmdet - INFO - Epoch [1][17850/32058]	lr: 2.000e-02, eta: 3 days, 1:57:46, time: 1.503, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:30:52,434 - mmdet - INFO - Epoch [1][17900/32058]	lr: 2.000e-02, eta: 3 days, 1:55:56, time: 1.455, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:32:06,593 - mmdet - INFO - Epoch [1][17950/32058]	lr: 2.000e-02, eta: 3 days, 1:54:19, time: 1.483, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:33:20,772 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 05:33:20,772 - mmdet - INFO - Epoch [1][18000/32058]	lr: 2.000e-02, eta: 3 days, 1:52:42, time: 1.484, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:34:34,796 - mmdet - INFO - Epoch [1][18050/32058]	lr: 2.000e-02, eta: 3 days, 1:51:04, time: 1.480, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:35:48,543 - mmdet - INFO - Epoch [1][18100/32058]	lr: 2.000e-02, eta: 3 days, 1:49:23, time: 1.475, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:37:03,678 - mmdet - INFO - Epoch [1][18150/32058]	lr: 2.000e-02, eta: 3 days, 1:47:56, time: 1.503, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:38:18,911 - mmdet - INFO - Epoch [1][18200/32058]	lr: 2.000e-02, eta: 3 days, 1:46:30, time: 1.505, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:39:33,877 - mmdet - INFO - Epoch [1][18250/32058]	lr: 2.000e-02, eta: 3 days, 1:45:02, time: 1.499, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:40:48,266 - mmdet - INFO - Epoch [1][18300/32058]	lr: 2.000e-02, eta: 3 days, 1:43:28, time: 1.488, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:42:03,350 - mmdet - INFO - Epoch [1][18350/32058]	lr: 2.000e-02, eta: 3 days, 1:42:01, time: 1.502, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:43:18,315 - mmdet - INFO - Epoch [1][18400/32058]	lr: 2.000e-02, eta: 3 days, 1:40:32, time: 1.499, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:44:33,271 - mmdet - INFO - Epoch [1][18450/32058]	lr: 2.000e-02, eta: 3 days, 1:39:04, time: 1.499, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:45:47,588 - mmdet - INFO - Epoch [1][18500/32058]	lr: 2.000e-02, eta: 3 days, 1:37:30, time: 1.486, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:47:01,142 - mmdet - INFO - Epoch [1][18550/32058]	lr: 2.000e-02, eta: 3 days, 1:35:48, time: 1.471, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:48:16,896 - mmdet - INFO - Epoch [1][18600/32058]	lr: 2.000e-02, eta: 3 days, 1:34:28, time: 1.515, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:49:31,002 - mmdet - INFO - Epoch [1][18650/32058]	lr: 2.000e-02, eta: 3 days, 1:32:52, time: 1.482, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:50:45,644 - mmdet - INFO - Epoch [1][18700/32058]	lr: 2.000e-02, eta: 3 days, 1:31:21, time: 1.493, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:51:59,761 - mmdet - INFO - Epoch [1][18750/32058]	lr: 2.000e-02, eta: 3 days, 1:29:45, time: 1.482, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:53:14,877 - mmdet - INFO - Epoch [1][18800/32058]	lr: 2.000e-02, eta: 3 days, 1:28:19, time: 1.502, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:54:29,269 - mmdet - INFO - Epoch [1][18850/32058]	lr: 2.000e-02, eta: 3 days, 1:26:46, time: 1.488, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:55:43,367 - mmdet - INFO - Epoch [1][18900/32058]	lr: 2.000e-02, eta: 3 days, 1:25:11, time: 1.482, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:56:58,499 - mmdet - INFO - Epoch [1][18950/32058]	lr: 2.000e-02, eta: 3 days, 1:23:45, time: 1.503, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:58:12,417 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 05:58:12,417 - mmdet - INFO - Epoch [1][19000/32058]	lr: 2.000e-02, eta: 3 days, 1:22:08, time: 1.478, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 05:59:27,062 - mmdet - INFO - Epoch [1][19050/32058]	lr: 2.000e-02, eta: 3 days, 1:20:38, time: 1.493, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:00:40,514 - mmdet - INFO - Epoch [1][19100/32058]	lr: 2.000e-02, eta: 3 days, 1:18:57, time: 1.469, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:01:54,714 - mmdet - INFO - Epoch [1][19150/32058]	lr: 2.000e-02, eta: 3 days, 1:17:23, time: 1.484, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:03:10,896 - mmdet - INFO - Epoch [1][19200/32058]	lr: 2.000e-02, eta: 3 days, 1:16:07, time: 1.524, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:04:24,797 - mmdet - INFO - Epoch [1][19250/32058]	lr: 2.000e-02, eta: 3 days, 1:14:30, time: 1.478, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:05:38,639 - mmdet - INFO - Epoch [1][19300/32058]	lr: 2.000e-02, eta: 3 days, 1:12:53, time: 1.477, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:06:52,839 - mmdet - INFO - Epoch [1][19350/32058]	lr: 2.000e-02, eta: 3 days, 1:11:19, time: 1.484, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:08:07,917 - mmdet - INFO - Epoch [1][19400/32058]	lr: 2.000e-02, eta: 3 days, 1:09:54, time: 1.502, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:09:23,048 - mmdet - INFO - Epoch [1][19450/32058]	lr: 2.000e-02, eta: 3 days, 1:08:29, time: 1.503, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:10:36,229 - mmdet - INFO - Epoch [1][19500/32058]	lr: 2.000e-02, eta: 3 days, 1:06:46, time: 1.464, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:11:51,221 - mmdet - INFO - Epoch [1][19550/32058]	lr: 2.000e-02, eta: 3 days, 1:05:20, time: 1.500, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:13:05,519 - mmdet - INFO - Epoch [1][19600/32058]	lr: 2.000e-02, eta: 3 days, 1:03:48, time: 1.486, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:14:18,948 - mmdet - INFO - Epoch [1][19650/32058]	lr: 2.000e-02, eta: 3 days, 1:02:08, time: 1.469, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:15:34,480 - mmdet - INFO - Epoch [1][19700/32058]	lr: 2.000e-02, eta: 3 days, 1:00:46, time: 1.511, data_time: 0.024, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:16:49,310 - mmdet - INFO - Epoch [1][19750/32058]	lr: 2.000e-02, eta: 3 days, 0:59:19, time: 1.497, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:18:02,159 - mmdet - INFO - Epoch [1][19800/32058]	lr: 2.000e-02, eta: 3 days, 0:57:34, time: 1.457, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:19:16,755 - mmdet - INFO - Epoch [1][19850/32058]	lr: 2.000e-02, eta: 3 days, 0:56:05, time: 1.492, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:20:31,675 - mmdet - INFO - Epoch [1][19900/32058]	lr: 2.000e-02, eta: 3 days, 0:54:39, time: 1.498, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:21:46,018 - mmdet - INFO - Epoch [1][19950/32058]	lr: 2.000e-02, eta: 3 days, 0:53:07, time: 1.487, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:23:00,979 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 06:23:00,979 - mmdet - INFO - Epoch [1][20000/32058]	lr: 2.000e-02, eta: 3 days, 0:51:41, time: 1.499, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:24:14,857 - mmdet - INFO - Epoch [1][20050/32058]	lr: 2.000e-02, eta: 3 days, 0:50:06, time: 1.478, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:25:28,126 - mmdet - INFO - Epoch [1][20100/32058]	lr: 2.000e-02, eta: 3 days, 0:48:26, time: 1.465, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:26:42,419 - mmdet - INFO - Epoch [1][20150/32058]	lr: 2.000e-02, eta: 3 days, 0:46:55, time: 1.486, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:27:57,032 - mmdet - INFO - Epoch [1][20200/32058]	lr: 2.000e-02, eta: 3 days, 0:45:26, time: 1.492, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:29:11,528 - mmdet - INFO - Epoch [1][20250/32058]	lr: 2.000e-02, eta: 3 days, 0:43:56, time: 1.490, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:30:25,795 - mmdet - INFO - Epoch [1][20300/32058]	lr: 2.000e-02, eta: 3 days, 0:42:25, time: 1.485, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:31:40,731 - mmdet - INFO - Epoch [1][20350/32058]	lr: 2.000e-02, eta: 3 days, 0:40:59, time: 1.499, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:32:54,710 - mmdet - INFO - Epoch [1][20400/32058]	lr: 2.000e-02, eta: 3 days, 0:39:26, time: 1.480, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:34:09,322 - mmdet - INFO - Epoch [1][20450/32058]	lr: 2.000e-02, eta: 3 days, 0:37:58, time: 1.492, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:35:23,165 - mmdet - INFO - Epoch [1][20500/32058]	lr: 2.000e-02, eta: 3 days, 0:36:23, time: 1.477, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:36:37,730 - mmdet - INFO - Epoch [1][20550/32058]	lr: 2.000e-02, eta: 3 days, 0:34:55, time: 1.491, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:37:52,532 - mmdet - INFO - Epoch [1][20600/32058]	lr: 2.000e-02, eta: 3 days, 0:33:28, time: 1.496, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:39:07,528 - mmdet - INFO - Epoch [1][20650/32058]	lr: 2.000e-02, eta: 3 days, 0:32:03, time: 1.500, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:40:22,036 - mmdet - INFO - Epoch [1][20700/32058]	lr: 2.000e-02, eta: 3 days, 0:30:35, time: 1.490, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:41:36,423 - mmdet - INFO - Epoch [1][20750/32058]	lr: 2.000e-02, eta: 3 days, 0:29:05, time: 1.488, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:42:51,043 - mmdet - INFO - Epoch [1][20800/32058]	lr: 2.000e-02, eta: 3 days, 0:27:37, time: 1.492, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:44:05,872 - mmdet - INFO - Epoch [1][20850/32058]	lr: 2.000e-02, eta: 3 days, 0:26:11, time: 1.497, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:45:20,530 - mmdet - INFO - Epoch [1][20900/32058]	lr: 2.000e-02, eta: 3 days, 0:24:44, time: 1.493, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:46:35,166 - mmdet - INFO - Epoch [1][20950/32058]	lr: 2.000e-02, eta: 3 days, 0:23:17, time: 1.493, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:47:50,061 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 06:47:50,061 - mmdet - INFO - Epoch [1][21000/32058]	lr: 2.000e-02, eta: 3 days, 0:21:51, time: 1.498, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:49:04,214 - mmdet - INFO - Epoch [1][21050/32058]	lr: 2.000e-02, eta: 3 days, 0:20:20, time: 1.483, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:50:18,238 - mmdet - INFO - Epoch [1][21100/32058]	lr: 2.000e-02, eta: 3 days, 0:18:48, time: 1.480, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:51:33,095 - mmdet - INFO - Epoch [1][21150/32058]	lr: 2.000e-02, eta: 3 days, 0:17:23, time: 1.497, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:52:46,941 - mmdet - INFO - Epoch [1][21200/32058]	lr: 2.000e-02, eta: 3 days, 0:15:49, time: 1.477, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:54:01,971 - mmdet - INFO - Epoch [1][21250/32058]	lr: 2.000e-02, eta: 3 days, 0:14:25, time: 1.501, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:55:16,271 - mmdet - INFO - Epoch [1][21300/32058]	lr: 2.000e-02, eta: 3 days, 0:12:56, time: 1.486, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:56:29,562 - mmdet - INFO - Epoch [1][21350/32058]	lr: 2.000e-02, eta: 3 days, 0:11:18, time: 1.466, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:57:43,899 - mmdet - INFO - Epoch [1][21400/32058]	lr: 2.000e-02, eta: 3 days, 0:09:49, time: 1.487, data_time: 0.024, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 06:58:57,845 - mmdet - INFO - Epoch [1][21450/32058]	lr: 2.000e-02, eta: 3 days, 0:08:17, time: 1.479, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:00:11,930 - mmdet - INFO - Epoch [1][21500/32058]	lr: 2.000e-02, eta: 3 days, 0:06:46, time: 1.482, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:01:25,855 - mmdet - INFO - Epoch [1][21550/32058]	lr: 2.000e-02, eta: 3 days, 0:05:13, time: 1.479, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:02:39,290 - mmdet - INFO - Epoch [1][21600/32058]	lr: 2.000e-02, eta: 3 days, 0:03:37, time: 1.469, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:03:54,055 - mmdet - INFO - Epoch [1][21650/32058]	lr: 2.000e-02, eta: 3 days, 0:02:12, time: 1.495, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:05:08,636 - mmdet - INFO - Epoch [1][21700/32058]	lr: 2.000e-02, eta: 3 days, 0:00:45, time: 1.492, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:06:22,912 - mmdet - INFO - Epoch [1][21750/32058]	lr: 2.000e-02, eta: 2 days, 23:59:16, time: 1.486, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:07:37,762 - mmdet - INFO - Epoch [1][21800/32058]	lr: 2.000e-02, eta: 2 days, 23:57:51, time: 1.497, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:08:52,722 - mmdet - INFO - Epoch [1][21850/32058]	lr: 2.000e-02, eta: 2 days, 23:56:28, time: 1.499, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:10:07,106 - mmdet - INFO - Epoch [1][21900/32058]	lr: 2.000e-02, eta: 2 days, 23:55:00, time: 1.488, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:11:21,084 - mmdet - INFO - Epoch [1][21950/32058]	lr: 2.000e-02, eta: 2 days, 23:53:28, time: 1.480, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:12:35,144 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 07:12:35,144 - mmdet - INFO - Epoch [1][22000/32058]	lr: 2.000e-02, eta: 2 days, 23:51:58, time: 1.481, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:13:49,414 - mmdet - INFO - Epoch [1][22050/32058]	lr: 2.000e-02, eta: 2 days, 23:50:29, time: 1.485, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:15:02,743 - mmdet - INFO - Epoch [1][22100/32058]	lr: 2.000e-02, eta: 2 days, 23:48:53, time: 1.467, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:16:16,559 - mmdet - INFO - Epoch [1][22150/32058]	lr: 2.000e-02, eta: 2 days, 23:47:21, time: 1.476, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:17:30,173 - mmdet - INFO - Epoch [1][22200/32058]	lr: 2.000e-02, eta: 2 days, 23:45:47, time: 1.472, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:18:43,368 - mmdet - INFO - Epoch [1][22250/32058]	lr: 2.000e-02, eta: 2 days, 23:44:10, time: 1.464, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:19:57,282 - mmdet - INFO - Epoch [1][22300/32058]	lr: 2.000e-02, eta: 2 days, 23:42:39, time: 1.478, data_time: 0.015, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:21:11,900 - mmdet - INFO - Epoch [1][22350/32058]	lr: 2.000e-02, eta: 2 days, 23:41:14, time: 1.492, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:22:28,095 - mmdet - INFO - Epoch [1][22400/32058]	lr: 2.000e-02, eta: 2 days, 23:40:00, time: 1.524, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:23:42,004 - mmdet - INFO - Epoch [1][22450/32058]	lr: 2.000e-02, eta: 2 days, 23:38:29, time: 1.478, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:24:55,637 - mmdet - INFO - Epoch [1][22500/32058]	lr: 2.000e-02, eta: 2 days, 23:36:56, time: 1.473, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:26:09,920 - mmdet - INFO - Epoch [1][22550/32058]	lr: 2.000e-02, eta: 2 days, 23:35:28, time: 1.486, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:27:23,770 - mmdet - INFO - Epoch [1][22600/32058]	lr: 2.000e-02, eta: 2 days, 23:33:56, time: 1.477, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:28:37,649 - mmdet - INFO - Epoch [1][22650/32058]	lr: 2.000e-02, eta: 2 days, 23:32:26, time: 1.478, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:29:52,834 - mmdet - INFO - Epoch [1][22700/32058]	lr: 2.000e-02, eta: 2 days, 23:31:04, time: 1.504, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:31:06,672 - mmdet - INFO - Epoch [1][22750/32058]	lr: 2.000e-02, eta: 2 days, 23:29:33, time: 1.477, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:32:20,693 - mmdet - INFO - Epoch [1][22800/32058]	lr: 2.000e-02, eta: 2 days, 23:28:04, time: 1.480, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:33:35,584 - mmdet - INFO - Epoch [1][22850/32058]	lr: 2.000e-02, eta: 2 days, 23:26:40, time: 1.498, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:34:50,757 - mmdet - INFO - Epoch [1][22900/32058]	lr: 2.000e-02, eta: 2 days, 23:25:19, time: 1.503, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:36:06,010 - mmdet - INFO - Epoch [1][22950/32058]	lr: 2.000e-02, eta: 2 days, 23:23:59, time: 1.505, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:37:20,402 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 07:37:20,403 - mmdet - INFO - Epoch [1][23000/32058]	lr: 2.000e-02, eta: 2 days, 23:22:32, time: 1.488, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:38:34,394 - mmdet - INFO - Epoch [1][23050/32058]	lr: 2.000e-02, eta: 2 days, 23:21:03, time: 1.480, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:39:48,405 - mmdet - INFO - Epoch [1][23100/32058]	lr: 2.000e-02, eta: 2 days, 23:19:33, time: 1.480, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:41:01,602 - mmdet - INFO - Epoch [1][23150/32058]	lr: 2.000e-02, eta: 2 days, 23:17:58, time: 1.464, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:42:17,122 - mmdet - INFO - Epoch [1][23200/32058]	lr: 2.000e-02, eta: 2 days, 23:16:40, time: 1.510, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:43:30,953 - mmdet - INFO - Epoch [1][23250/32058]	lr: 2.000e-02, eta: 2 days, 23:15:09, time: 1.477, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:44:46,034 - mmdet - INFO - Epoch [1][23300/32058]	lr: 2.000e-02, eta: 2 days, 23:13:48, time: 1.502, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:46:00,914 - mmdet - INFO - Epoch [1][23350/32058]	lr: 2.000e-02, eta: 2 days, 23:12:25, time: 1.498, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:47:14,266 - mmdet - INFO - Epoch [1][23400/32058]	lr: 2.000e-02, eta: 2 days, 23:10:51, time: 1.467, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:48:28,457 - mmdet - INFO - Epoch [1][23450/32058]	lr: 2.000e-02, eta: 2 days, 23:09:23, time: 1.484, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:49:42,219 - mmdet - INFO - Epoch [1][23500/32058]	lr: 2.000e-02, eta: 2 days, 23:07:53, time: 1.475, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:50:56,028 - mmdet - INFO - Epoch [1][23550/32058]	lr: 2.000e-02, eta: 2 days, 23:06:22, time: 1.476, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:52:10,362 - mmdet - INFO - Epoch [1][23600/32058]	lr: 2.000e-02, eta: 2 days, 23:04:56, time: 1.487, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:53:24,613 - mmdet - INFO - Epoch [1][23650/32058]	lr: 2.000e-02, eta: 2 days, 23:03:29, time: 1.485, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:54:39,487 - mmdet - INFO - Epoch [1][23700/32058]	lr: 2.000e-02, eta: 2 days, 23:02:06, time: 1.497, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:55:54,683 - mmdet - INFO - Epoch [1][23750/32058]	lr: 2.000e-02, eta: 2 days, 23:00:46, time: 1.504, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:57:08,878 - mmdet - INFO - Epoch [1][23800/32058]	lr: 2.000e-02, eta: 2 days, 22:59:19, time: 1.484, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:58:23,866 - mmdet - INFO - Epoch [1][23850/32058]	lr: 2.000e-02, eta: 2 days, 22:57:57, time: 1.500, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 07:59:38,175 - mmdet - INFO - Epoch [1][23900/32058]	lr: 2.000e-02, eta: 2 days, 22:56:31, time: 1.486, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:00:53,142 - mmdet - INFO - Epoch [1][23950/32058]	lr: 2.000e-02, eta: 2 days, 22:55:09, time: 1.499, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:02:06,765 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 08:02:06,766 - mmdet - INFO - Epoch [1][24000/32058]	lr: 2.000e-02, eta: 2 days, 22:53:38, time: 1.472, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:03:20,335 - mmdet - INFO - Epoch [1][24050/32058]	lr: 2.000e-02, eta: 2 days, 22:52:06, time: 1.471, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:04:35,096 - mmdet - INFO - Epoch [1][24100/32058]	lr: 2.000e-02, eta: 2 days, 22:50:43, time: 1.495, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:05:49,260 - mmdet - INFO - Epoch [1][24150/32058]	lr: 2.000e-02, eta: 2 days, 22:49:16, time: 1.483, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:07:03,803 - mmdet - INFO - Epoch [1][24200/32058]	lr: 2.000e-02, eta: 2 days, 22:47:52, time: 1.491, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:08:17,740 - mmdet - INFO - Epoch [1][24250/32058]	lr: 2.000e-02, eta: 2 days, 22:46:23, time: 1.479, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:09:31,107 - mmdet - INFO - Epoch [1][24300/32058]	lr: 2.000e-02, eta: 2 days, 22:44:51, time: 1.467, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:10:45,724 - mmdet - INFO - Epoch [1][24350/32058]	lr: 2.000e-02, eta: 2 days, 22:43:27, time: 1.492, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:11:59,662 - mmdet - INFO - Epoch [1][24400/32058]	lr: 2.000e-02, eta: 2 days, 22:41:58, time: 1.479, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:13:12,767 - mmdet - INFO - Epoch [1][24450/32058]	lr: 2.000e-02, eta: 2 days, 22:40:24, time: 1.462, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:14:26,445 - mmdet - INFO - Epoch [1][24500/32058]	lr: 2.000e-02, eta: 2 days, 22:38:54, time: 1.474, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:15:40,354 - mmdet - INFO - Epoch [1][24550/32058]	lr: 2.000e-02, eta: 2 days, 22:37:26, time: 1.478, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:16:54,263 - mmdet - INFO - Epoch [1][24600/32058]	lr: 2.000e-02, eta: 2 days, 22:35:57, time: 1.478, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:18:08,122 - mmdet - INFO - Epoch [1][24650/32058]	lr: 2.000e-02, eta: 2 days, 22:34:29, time: 1.477, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:19:23,094 - mmdet - INFO - Epoch [1][24700/32058]	lr: 2.000e-02, eta: 2 days, 22:33:08, time: 1.499, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:20:36,569 - mmdet - INFO - Epoch [1][24750/32058]	lr: 2.000e-02, eta: 2 days, 22:31:37, time: 1.469, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:21:50,412 - mmdet - INFO - Epoch [1][24800/32058]	lr: 2.000e-02, eta: 2 days, 22:30:08, time: 1.477, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:23:03,986 - mmdet - INFO - Epoch [1][24850/32058]	lr: 2.000e-02, eta: 2 days, 22:28:38, time: 1.471, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:24:17,574 - mmdet - INFO - Epoch [1][24900/32058]	lr: 2.000e-02, eta: 2 days, 22:27:07, time: 1.472, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:25:33,088 - mmdet - INFO - Epoch [1][24950/32058]	lr: 2.000e-02, eta: 2 days, 22:25:50, time: 1.510, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:26:48,111 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 08:26:48,112 - mmdet - INFO - Epoch [1][25000/32058]	lr: 2.000e-02, eta: 2 days, 22:24:30, time: 1.500, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:28:03,572 - mmdet - INFO - Epoch [1][25050/32058]	lr: 2.000e-02, eta: 2 days, 22:23:12, time: 1.509, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:29:17,108 - mmdet - INFO - Epoch [1][25100/32058]	lr: 2.000e-02, eta: 2 days, 22:21:42, time: 1.471, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:30:32,058 - mmdet - INFO - Epoch [1][25150/32058]	lr: 2.000e-02, eta: 2 days, 22:20:21, time: 1.499, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:31:45,831 - mmdet - INFO - Epoch [1][25200/32058]	lr: 2.000e-02, eta: 2 days, 22:18:52, time: 1.475, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:33:00,226 - mmdet - INFO - Epoch [1][25250/32058]	lr: 2.000e-02, eta: 2 days, 22:17:28, time: 1.488, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:34:14,302 - mmdet - INFO - Epoch [1][25300/32058]	lr: 2.000e-02, eta: 2 days, 22:16:01, time: 1.482, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:35:29,066 - mmdet - INFO - Epoch [1][25350/32058]	lr: 2.000e-02, eta: 2 days, 22:14:39, time: 1.495, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:36:43,505 - mmdet - INFO - Epoch [1][25400/32058]	lr: 2.000e-02, eta: 2 days, 22:13:15, time: 1.489, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:37:57,241 - mmdet - INFO - Epoch [1][25450/32058]	lr: 2.000e-02, eta: 2 days, 22:11:46, time: 1.475, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:39:11,557 - mmdet - INFO - Epoch [1][25500/32058]	lr: 2.000e-02, eta: 2 days, 22:10:22, time: 1.486, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:40:26,290 - mmdet - INFO - Epoch [1][25550/32058]	lr: 2.000e-02, eta: 2 days, 22:09:00, time: 1.495, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:41:41,244 - mmdet - INFO - Epoch [1][25600/32058]	lr: 2.000e-02, eta: 2 days, 22:07:39, time: 1.499, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:42:55,415 - mmdet - INFO - Epoch [1][25650/32058]	lr: 2.000e-02, eta: 2 days, 22:06:13, time: 1.483, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:44:09,567 - mmdet - INFO - Epoch [1][25700/32058]	lr: 2.000e-02, eta: 2 days, 22:04:48, time: 1.483, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:45:23,313 - mmdet - INFO - Epoch [1][25750/32058]	lr: 2.000e-02, eta: 2 days, 22:03:19, time: 1.475, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:46:37,797 - mmdet - INFO - Epoch [1][25800/32058]	lr: 2.000e-02, eta: 2 days, 22:01:56, time: 1.490, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:47:51,314 - mmdet - INFO - Epoch [1][25850/32058]	lr: 2.000e-02, eta: 2 days, 22:00:26, time: 1.470, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:49:04,543 - mmdet - INFO - Epoch [1][25900/32058]	lr: 2.000e-02, eta: 2 days, 21:58:55, time: 1.465, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:50:20,029 - mmdet - INFO - Epoch [1][25950/32058]	lr: 2.000e-02, eta: 2 days, 21:57:38, time: 1.510, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:51:34,745 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 08:51:34,745 - mmdet - INFO - Epoch [1][26000/32058]	lr: 2.000e-02, eta: 2 days, 21:56:16, time: 1.494, data_time: 0.016, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:52:49,703 - mmdet - INFO - Epoch [1][26050/32058]	lr: 2.000e-02, eta: 2 days, 21:54:56, time: 1.499, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:54:05,146 - mmdet - INFO - Epoch [1][26100/32058]	lr: 2.000e-02, eta: 2 days, 21:53:39, time: 1.509, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:55:19,920 - mmdet - INFO - Epoch [1][26150/32058]	lr: 2.000e-02, eta: 2 days, 21:52:17, time: 1.495, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:56:34,963 - mmdet - INFO - Epoch [1][26200/32058]	lr: 2.000e-02, eta: 2 days, 21:50:57, time: 1.501, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:57:48,016 - mmdet - INFO - Epoch [1][26250/32058]	lr: 2.000e-02, eta: 2 days, 21:49:25, time: 1.461, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 08:59:01,774 - mmdet - INFO - Epoch [1][26300/32058]	lr: 2.000e-02, eta: 2 days, 21:47:57, time: 1.475, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:00:15,015 - mmdet - INFO - Epoch [1][26350/32058]	lr: 2.000e-02, eta: 2 days, 21:46:27, time: 1.465, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:01:30,256 - mmdet - INFO - Epoch [1][26400/32058]	lr: 2.000e-02, eta: 2 days, 21:45:08, time: 1.505, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:02:45,260 - mmdet - INFO - Epoch [1][26450/32058]	lr: 2.000e-02, eta: 2 days, 21:43:48, time: 1.500, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:04:01,068 - mmdet - INFO - Epoch [1][26500/32058]	lr: 2.000e-02, eta: 2 days, 21:42:34, time: 1.516, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:05:15,646 - mmdet - INFO - Epoch [1][26550/32058]	lr: 2.000e-02, eta: 2 days, 21:41:11, time: 1.492, data_time: 0.016, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:06:30,047 - mmdet - INFO - Epoch [1][26600/32058]	lr: 2.000e-02, eta: 2 days, 21:39:48, time: 1.488, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:07:44,268 - mmdet - INFO - Epoch [1][26650/32058]	lr: 2.000e-02, eta: 2 days, 21:38:23, time: 1.484, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:08:57,767 - mmdet - INFO - Epoch [1][26700/32058]	lr: 2.000e-02, eta: 2 days, 21:36:54, time: 1.470, data_time: 0.016, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:10:11,699 - mmdet - INFO - Epoch [1][26750/32058]	lr: 2.000e-02, eta: 2 days, 21:35:28, time: 1.479, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:11:25,838 - mmdet - INFO - Epoch [1][26800/32058]	lr: 2.000e-02, eta: 2 days, 21:34:03, time: 1.483, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:12:39,814 - mmdet - INFO - Epoch [1][26850/32058]	lr: 2.000e-02, eta: 2 days, 21:32:37, time: 1.480, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:13:54,409 - mmdet - INFO - Epoch [1][26900/32058]	lr: 2.000e-02, eta: 2 days, 21:31:15, time: 1.492, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:15:07,912 - mmdet - INFO - Epoch [1][26950/32058]	lr: 2.000e-02, eta: 2 days, 21:29:46, time: 1.470, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:16:21,764 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 09:16:21,764 - mmdet - INFO - Epoch [1][27000/32058]	lr: 2.000e-02, eta: 2 days, 21:28:20, time: 1.477, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:17:35,741 - mmdet - INFO - Epoch [1][27050/32058]	lr: 2.000e-02, eta: 2 days, 21:26:54, time: 1.480, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:18:49,514 - mmdet - INFO - Epoch [1][27100/32058]	lr: 2.000e-02, eta: 2 days, 21:25:27, time: 1.475, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:20:03,878 - mmdet - INFO - Epoch [1][27150/32058]	lr: 2.000e-02, eta: 2 days, 21:24:04, time: 1.487, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:21:17,862 - mmdet - INFO - Epoch [1][27200/32058]	lr: 2.000e-02, eta: 2 days, 21:22:38, time: 1.480, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:22:32,150 - mmdet - INFO - Epoch [1][27250/32058]	lr: 2.000e-02, eta: 2 days, 21:21:15, time: 1.486, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:23:47,962 - mmdet - INFO - Epoch [1][27300/32058]	lr: 2.000e-02, eta: 2 days, 21:20:00, time: 1.516, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:25:01,758 - mmdet - INFO - Epoch [1][27350/32058]	lr: 2.000e-02, eta: 2 days, 21:18:34, time: 1.476, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:26:15,554 - mmdet - INFO - Epoch [1][27400/32058]	lr: 2.000e-02, eta: 2 days, 21:17:07, time: 1.476, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:27:29,947 - mmdet - INFO - Epoch [1][27450/32058]	lr: 2.000e-02, eta: 2 days, 21:15:44, time: 1.488, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:28:43,770 - mmdet - INFO - Epoch [1][27500/32058]	lr: 2.000e-02, eta: 2 days, 21:14:18, time: 1.476, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:29:58,236 - mmdet - INFO - Epoch [1][27550/32058]	lr: 2.000e-02, eta: 2 days, 21:12:56, time: 1.489, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:31:10,370 - mmdet - INFO - Epoch [1][27600/32058]	lr: 2.000e-02, eta: 2 days, 21:11:19, time: 1.443, data_time: 0.016, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:32:24,990 - mmdet - INFO - Epoch [1][27650/32058]	lr: 2.000e-02, eta: 2 days, 21:09:58, time: 1.492, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:33:39,314 - mmdet - INFO - Epoch [1][27700/32058]	lr: 2.000e-02, eta: 2 days, 21:08:35, time: 1.486, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:34:53,715 - mmdet - INFO - Epoch [1][27750/32058]	lr: 2.000e-02, eta: 2 days, 21:07:12, time: 1.488, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:36:07,593 - mmdet - INFO - Epoch [1][27800/32058]	lr: 2.000e-02, eta: 2 days, 21:05:46, time: 1.478, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:37:21,554 - mmdet - INFO - Epoch [1][27850/32058]	lr: 2.000e-02, eta: 2 days, 21:04:21, time: 1.479, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:38:35,830 - mmdet - INFO - Epoch [1][27900/32058]	lr: 2.000e-02, eta: 2 days, 21:02:58, time: 1.486, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:39:50,446 - mmdet - INFO - Epoch [1][27950/32058]	lr: 2.000e-02, eta: 2 days, 21:01:37, time: 1.492, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:41:05,730 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 09:41:05,731 - mmdet - INFO - Epoch [1][28000/32058]	lr: 2.000e-02, eta: 2 days, 21:00:19, time: 1.506, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:42:21,125 - mmdet - INFO - Epoch [1][28050/32058]	lr: 2.000e-02, eta: 2 days, 20:59:03, time: 1.508, data_time: 0.024, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:43:34,704 - mmdet - INFO - Epoch [1][28100/32058]	lr: 2.000e-02, eta: 2 days, 20:57:35, time: 1.472, data_time: 0.016, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:44:48,680 - mmdet - INFO - Epoch [1][28150/32058]	lr: 2.000e-02, eta: 2 days, 20:56:11, time: 1.480, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:46:02,319 - mmdet - INFO - Epoch [1][28200/32058]	lr: 2.000e-02, eta: 2 days, 20:54:44, time: 1.473, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:47:15,862 - mmdet - INFO - Epoch [1][28250/32058]	lr: 2.000e-02, eta: 2 days, 20:53:16, time: 1.471, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:48:29,031 - mmdet - INFO - Epoch [1][28300/32058]	lr: 2.000e-02, eta: 2 days, 20:51:47, time: 1.463, data_time: 0.016, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:49:41,294 - mmdet - INFO - Epoch [1][28350/32058]	lr: 2.000e-02, eta: 2 days, 20:50:12, time: 1.445, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:50:55,875 - mmdet - INFO - Epoch [1][28400/32058]	lr: 2.000e-02, eta: 2 days, 20:48:51, time: 1.492, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:52:09,942 - mmdet - INFO - Epoch [1][28450/32058]	lr: 2.000e-02, eta: 2 days, 20:47:27, time: 1.481, data_time: 0.016, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:53:25,025 - mmdet - INFO - Epoch [1][28500/32058]	lr: 2.000e-02, eta: 2 days, 20:46:09, time: 1.502, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:54:39,652 - mmdet - INFO - Epoch [1][28550/32058]	lr: 2.000e-02, eta: 2 days, 20:44:48, time: 1.493, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:55:54,702 - mmdet - INFO - Epoch [1][28600/32058]	lr: 2.000e-02, eta: 2 days, 20:43:30, time: 1.501, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:57:08,900 - mmdet - INFO - Epoch [1][28650/32058]	lr: 2.000e-02, eta: 2 days, 20:42:06, time: 1.484, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:58:23,619 - mmdet - INFO - Epoch [1][28700/32058]	lr: 2.000e-02, eta: 2 days, 20:40:46, time: 1.494, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 09:59:38,578 - mmdet - INFO - Epoch [1][28750/32058]	lr: 2.000e-02, eta: 2 days, 20:39:27, time: 1.499, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:00:53,646 - mmdet - INFO - Epoch [1][28800/32058]	lr: 2.000e-02, eta: 2 days, 20:38:09, time: 1.501, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:02:06,816 - mmdet - INFO - Epoch [1][28850/32058]	lr: 2.000e-02, eta: 2 days, 20:36:40, time: 1.463, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:03:20,740 - mmdet - INFO - Epoch [1][28900/32058]	lr: 2.000e-02, eta: 2 days, 20:35:15, time: 1.478, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:04:34,413 - mmdet - INFO - Epoch [1][28950/32058]	lr: 2.000e-02, eta: 2 days, 20:33:49, time: 1.473, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:05:49,008 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 10:05:49,009 - mmdet - INFO - Epoch [1][29000/32058]	lr: 2.000e-02, eta: 2 days, 20:32:29, time: 1.492, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:07:04,515 - mmdet - INFO - Epoch [1][29050/32058]	lr: 2.000e-02, eta: 2 days, 20:31:13, time: 1.510, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:08:19,603 - mmdet - INFO - Epoch [1][29100/32058]	lr: 2.000e-02, eta: 2 days, 20:29:55, time: 1.502, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:09:33,629 - mmdet - INFO - Epoch [1][29150/32058]	lr: 2.000e-02, eta: 2 days, 20:28:31, time: 1.481, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:10:48,601 - mmdet - INFO - Epoch [1][29200/32058]	lr: 2.000e-02, eta: 2 days, 20:27:12, time: 1.499, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:12:02,229 - mmdet - INFO - Epoch [1][29250/32058]	lr: 2.000e-02, eta: 2 days, 20:25:46, time: 1.473, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:13:16,342 - mmdet - INFO - Epoch [1][29300/32058]	lr: 2.000e-02, eta: 2 days, 20:24:23, time: 1.482, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:14:31,771 - mmdet - INFO - Epoch [1][29350/32058]	lr: 2.000e-02, eta: 2 days, 20:23:07, time: 1.509, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:15:46,404 - mmdet - INFO - Epoch [1][29400/32058]	lr: 2.000e-02, eta: 2 days, 20:21:46, time: 1.493, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:17:00,443 - mmdet - INFO - Epoch [1][29450/32058]	lr: 2.000e-02, eta: 2 days, 20:20:23, time: 1.481, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:18:14,536 - mmdet - INFO - Epoch [1][29500/32058]	lr: 2.000e-02, eta: 2 days, 20:18:59, time: 1.482, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:19:28,743 - mmdet - INFO - Epoch [1][29550/32058]	lr: 2.000e-02, eta: 2 days, 20:17:37, time: 1.484, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:20:43,735 - mmdet - INFO - Epoch [1][29600/32058]	lr: 2.000e-02, eta: 2 days, 20:16:18, time: 1.500, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:21:57,785 - mmdet - INFO - Epoch [1][29650/32058]	lr: 2.000e-02, eta: 2 days, 20:14:55, time: 1.481, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:23:12,014 - mmdet - INFO - Epoch [1][29700/32058]	lr: 2.000e-02, eta: 2 days, 20:13:32, time: 1.485, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:24:26,042 - mmdet - INFO - Epoch [1][29750/32058]	lr: 2.000e-02, eta: 2 days, 20:12:09, time: 1.481, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:25:41,072 - mmdet - INFO - Epoch [1][29800/32058]	lr: 2.000e-02, eta: 2 days, 20:10:51, time: 1.501, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:26:55,290 - mmdet - INFO - Epoch [1][29850/32058]	lr: 2.000e-02, eta: 2 days, 20:09:28, time: 1.484, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:28:08,501 - mmdet - INFO - Epoch [1][29900/32058]	lr: 2.000e-02, eta: 2 days, 20:08:00, time: 1.464, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:29:22,661 - mmdet - INFO - Epoch [1][29950/32058]	lr: 2.000e-02, eta: 2 days, 20:06:37, time: 1.483, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:30:36,238 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 10:30:36,238 - mmdet - INFO - Epoch [1][30000/32058]	lr: 2.000e-02, eta: 2 days, 20:05:12, time: 1.472, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:31:50,093 - mmdet - INFO - Epoch [1][30050/32058]	lr: 2.000e-02, eta: 2 days, 20:03:47, time: 1.477, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:33:04,489 - mmdet - INFO - Epoch [1][30100/32058]	lr: 2.000e-02, eta: 2 days, 20:02:26, time: 1.488, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:34:18,231 - mmdet - INFO - Epoch [1][30150/32058]	lr: 2.000e-02, eta: 2 days, 20:01:01, time: 1.475, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:35:32,937 - mmdet - INFO - Epoch [1][30200/32058]	lr: 2.000e-02, eta: 2 days, 19:59:41, time: 1.494, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:36:46,831 - mmdet - INFO - Epoch [1][30250/32058]	lr: 2.000e-02, eta: 2 days, 19:58:17, time: 1.478, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:38:01,967 - mmdet - INFO - Epoch [1][30300/32058]	lr: 2.000e-02, eta: 2 days, 19:57:00, time: 1.503, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:39:17,462 - mmdet - INFO - Epoch [1][30350/32058]	lr: 2.000e-02, eta: 2 days, 19:55:45, time: 1.510, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:40:32,091 - mmdet - INFO - Epoch [1][30400/32058]	lr: 2.000e-02, eta: 2 days, 19:54:25, time: 1.493, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:41:48,108 - mmdet - INFO - Epoch [1][30450/32058]	lr: 2.000e-02, eta: 2 days, 19:53:12, time: 1.520, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:43:03,774 - mmdet - INFO - Epoch [1][30500/32058]	lr: 2.000e-02, eta: 2 days, 19:51:58, time: 1.513, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:44:17,995 - mmdet - INFO - Epoch [1][30550/32058]	lr: 2.000e-02, eta: 2 days, 19:50:36, time: 1.484, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:45:32,109 - mmdet - INFO - Epoch [1][30600/32058]	lr: 2.000e-02, eta: 2 days, 19:49:13, time: 1.482, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:46:46,662 - mmdet - INFO - Epoch [1][30650/32058]	lr: 2.000e-02, eta: 2 days, 19:47:53, time: 1.491, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:48:02,014 - mmdet - INFO - Epoch [1][30700/32058]	lr: 2.000e-02, eta: 2 days, 19:46:36, time: 1.507, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:49:16,377 - mmdet - INFO - Epoch [1][30750/32058]	lr: 2.000e-02, eta: 2 days, 19:45:15, time: 1.487, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:50:29,712 - mmdet - INFO - Epoch [1][30800/32058]	lr: 2.000e-02, eta: 2 days, 19:43:48, time: 1.467, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:51:44,474 - mmdet - INFO - Epoch [1][30850/32058]	lr: 2.000e-02, eta: 2 days, 19:42:29, time: 1.495, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:52:59,834 - mmdet - INFO - Epoch [1][30900/32058]	lr: 2.000e-02, eta: 2 days, 19:41:13, time: 1.507, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:54:14,154 - mmdet - INFO - Epoch [1][30950/32058]	lr: 2.000e-02, eta: 2 days, 19:39:52, time: 1.486, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:55:29,073 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 10:55:29,074 - mmdet - INFO - Epoch [1][31000/32058]	lr: 2.000e-02, eta: 2 days, 19:38:34, time: 1.498, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:56:43,535 - mmdet - INFO - Epoch [1][31050/32058]	lr: 2.000e-02, eta: 2 days, 19:37:13, time: 1.489, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:57:57,503 - mmdet - INFO - Epoch [1][31100/32058]	lr: 2.000e-02, eta: 2 days, 19:35:50, time: 1.479, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 10:59:11,321 - mmdet - INFO - Epoch [1][31150/32058]	lr: 2.000e-02, eta: 2 days, 19:34:26, time: 1.476, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:00:25,765 - mmdet - INFO - Epoch [1][31200/32058]	lr: 2.000e-02, eta: 2 days, 19:33:05, time: 1.489, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:01:39,411 - mmdet - INFO - Epoch [1][31250/32058]	lr: 2.000e-02, eta: 2 days, 19:31:40, time: 1.473, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:02:53,117 - mmdet - INFO - Epoch [1][31300/32058]	lr: 2.000e-02, eta: 2 days, 19:30:16, time: 1.474, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:04:06,816 - mmdet - INFO - Epoch [1][31350/32058]	lr: 2.000e-02, eta: 2 days, 19:28:51, time: 1.474, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:05:22,069 - mmdet - INFO - Epoch [1][31400/32058]	lr: 2.000e-02, eta: 2 days, 19:27:35, time: 1.505, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:06:35,197 - mmdet - INFO - Epoch [1][31450/32058]	lr: 2.000e-02, eta: 2 days, 19:26:08, time: 1.463, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:07:48,527 - mmdet - INFO - Epoch [1][31500/32058]	lr: 2.000e-02, eta: 2 days, 19:24:41, time: 1.467, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:09:02,293 - mmdet - INFO - Epoch [1][31550/32058]	lr: 2.000e-02, eta: 2 days, 19:23:17, time: 1.475, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:10:16,033 - mmdet - INFO - Epoch [1][31600/32058]	lr: 2.000e-02, eta: 2 days, 19:21:53, time: 1.475, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:11:29,757 - mmdet - INFO - Epoch [1][31650/32058]	lr: 2.000e-02, eta: 2 days, 19:20:29, time: 1.474, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:12:44,788 - mmdet - INFO - Epoch [1][31700/32058]	lr: 2.000e-02, eta: 2 days, 19:19:12, time: 1.501, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:13:57,582 - mmdet - INFO - Epoch [1][31750/32058]	lr: 2.000e-02, eta: 2 days, 19:17:43, time: 1.456, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:15:10,740 - mmdet - INFO - Epoch [1][31800/32058]	lr: 2.000e-02, eta: 2 days, 19:16:16, time: 1.463, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:16:24,179 - mmdet - INFO - Epoch [1][31850/32058]	lr: 2.000e-02, eta: 2 days, 19:14:51, time: 1.469, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:17:38,999 - mmdet - INFO - Epoch [1][31900/32058]	lr: 2.000e-02, eta: 2 days, 19:13:32, time: 1.496, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:18:54,108 - mmdet - INFO - Epoch [1][31950/32058]	lr: 2.000e-02, eta: 2 days, 19:12:15, time: 1.502, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:20:08,030 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 11:20:08,031 - mmdet - INFO - Epoch [1][32000/32058]	lr: 2.000e-02, eta: 2 days, 19:10:52, time: 1.478, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:21:23,101 - mmdet - INFO - Epoch [1][32050/32058]	lr: 2.000e-02, eta: 2 days, 19:09:35, time: 1.501, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:21:34,598 - mmdet - INFO - Saving checkpoint at 1 epochs
2022-05-06 11:30:50,382 - mmdet - INFO - Evaluating bbox...
2022-05-06 11:30:50,383 - mmdet - ERROR - The testing results of the whole dataset is empty.
2022-05-06 11:30:50,384 - mmdet - INFO - Exp name: detectors_instaboost.py
2022-05-06 11:30:50,385 - mmdet - INFO - Epoch(val) [1][2693]	
2022-05-06 11:32:06,296 - mmdet - INFO - Epoch [2][50/32058]	lr: 2.000e-02, eta: 2 days, 19:07:10, time: 1.518, data_time: 0.065, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:33:20,360 - mmdet - INFO - Epoch [2][100/32058]	lr: 2.000e-02, eta: 2 days, 19:05:48, time: 1.481, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:34:34,717 - mmdet - INFO - Epoch [2][150/32058]	lr: 2.000e-02, eta: 2 days, 19:04:27, time: 1.487, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:35:48,957 - mmdet - INFO - Epoch [2][200/32058]	lr: 2.000e-02, eta: 2 days, 19:03:06, time: 1.485, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:37:03,109 - mmdet - INFO - Epoch [2][250/32058]	lr: 2.000e-02, eta: 2 days, 19:01:45, time: 1.483, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:38:17,529 - mmdet - INFO - Epoch [2][300/32058]	lr: 2.000e-02, eta: 2 days, 19:00:25, time: 1.488, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:39:32,132 - mmdet - INFO - Epoch [2][350/32058]	lr: 2.000e-02, eta: 2 days, 18:59:05, time: 1.492, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:40:46,130 - mmdet - INFO - Epoch [2][400/32058]	lr: 2.000e-02, eta: 2 days, 18:57:43, time: 1.480, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:42:00,427 - mmdet - INFO - Epoch [2][450/32058]	lr: 2.000e-02, eta: 2 days, 18:56:22, time: 1.486, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:43:13,523 - mmdet - INFO - Epoch [2][500/32058]	lr: 2.000e-02, eta: 2 days, 18:54:56, time: 1.462, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:44:26,945 - mmdet - INFO - Epoch [2][550/32058]	lr: 2.000e-02, eta: 2 days, 18:53:31, time: 1.468, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:45:41,847 - mmdet - INFO - Epoch [2][600/32058]	lr: 2.000e-02, eta: 2 days, 18:52:13, time: 1.498, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:46:55,642 - mmdet - INFO - Epoch [2][650/32058]	lr: 2.000e-02, eta: 2 days, 18:50:50, time: 1.476, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:48:08,894 - mmdet - INFO - Epoch [2][700/32058]	lr: 2.000e-02, eta: 2 days, 18:49:24, time: 1.465, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:49:23,029 - mmdet - INFO - Epoch [2][750/32058]	lr: 2.000e-02, eta: 2 days, 18:48:03, time: 1.483, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:50:37,737 - mmdet - INFO - Epoch [2][800/32058]	lr: 2.000e-02, eta: 2 days, 18:46:44, time: 1.494, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:51:51,189 - mmdet - INFO - Epoch [2][850/32058]	lr: 2.000e-02, eta: 2 days, 18:45:20, time: 1.469, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:53:04,582 - mmdet - INFO - Epoch [2][900/32058]	lr: 2.000e-02, eta: 2 days, 18:43:55, time: 1.468, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:54:18,782 - mmdet - INFO - Epoch [2][950/32058]	lr: 2.000e-02, eta: 2 days, 18:42:34, time: 1.484, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:55:33,393 - mmdet - INFO - Epoch [2][1000/32058]	lr: 2.000e-02, eta: 2 days, 18:41:15, time: 1.492, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:56:47,786 - mmdet - INFO - Epoch [2][1050/32058]	lr: 2.000e-02, eta: 2 days, 18:39:55, time: 1.488, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:58:01,613 - mmdet - INFO - Epoch [2][1100/32058]	lr: 2.000e-02, eta: 2 days, 18:38:32, time: 1.477, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 11:59:15,952 - mmdet - INFO - Epoch [2][1150/32058]	lr: 2.000e-02, eta: 2 days, 18:37:12, time: 1.487, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:00:30,114 - mmdet - INFO - Epoch [2][1200/32058]	lr: 2.000e-02, eta: 2 days, 18:35:51, time: 1.483, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:01:45,621 - mmdet - INFO - Epoch [2][1250/32058]	lr: 2.000e-02, eta: 2 days, 18:34:36, time: 1.510, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:03:00,488 - mmdet - INFO - Epoch [2][1300/32058]	lr: 2.000e-02, eta: 2 days, 18:33:19, time: 1.497, data_time: 0.016, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:04:14,550 - mmdet - INFO - Epoch [2][1350/32058]	lr: 2.000e-02, eta: 2 days, 18:31:57, time: 1.481, data_time: 0.016, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:05:28,939 - mmdet - INFO - Epoch [2][1400/32058]	lr: 2.000e-02, eta: 2 days, 18:30:37, time: 1.488, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:06:42,660 - mmdet - INFO - Epoch [2][1450/32058]	lr: 2.000e-02, eta: 2 days, 18:29:14, time: 1.474, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:07:55,635 - mmdet - INFO - Epoch [2][1500/32058]	lr: 2.000e-02, eta: 2 days, 18:27:48, time: 1.459, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:09:10,021 - mmdet - INFO - Epoch [2][1550/32058]	lr: 2.000e-02, eta: 2 days, 18:26:28, time: 1.488, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:10:25,256 - mmdet - INFO - Epoch [2][1600/32058]	lr: 2.000e-02, eta: 2 days, 18:25:12, time: 1.505, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:11:38,893 - mmdet - INFO - Epoch [2][1650/32058]	lr: 2.000e-02, eta: 2 days, 18:23:49, time: 1.473, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:12:53,531 - mmdet - INFO - Epoch [2][1700/32058]	lr: 2.000e-02, eta: 2 days, 18:22:30, time: 1.493, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:14:08,057 - mmdet - INFO - Epoch [2][1750/32058]	lr: 2.000e-02, eta: 2 days, 18:21:11, time: 1.491, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:15:22,885 - mmdet - INFO - Epoch [2][1800/32058]	lr: 2.000e-02, eta: 2 days, 18:19:53, time: 1.497, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:16:37,879 - mmdet - INFO - Epoch [2][1850/32058]	lr: 2.000e-02, eta: 2 days, 18:18:36, time: 1.500, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:17:52,047 - mmdet - INFO - Epoch [2][1900/32058]	lr: 2.000e-02, eta: 2 days, 18:17:15, time: 1.483, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:19:05,407 - mmdet - INFO - Epoch [2][1950/32058]	lr: 2.000e-02, eta: 2 days, 18:15:51, time: 1.467, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:20:20,025 - mmdet - INFO - Epoch [2][2000/32058]	lr: 2.000e-02, eta: 2 days, 18:14:32, time: 1.492, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:21:34,444 - mmdet - INFO - Epoch [2][2050/32058]	lr: 2.000e-02, eta: 2 days, 18:13:13, time: 1.488, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:22:48,884 - mmdet - INFO - Epoch [2][2100/32058]	lr: 2.000e-02, eta: 2 days, 18:11:53, time: 1.489, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:24:03,051 - mmdet - INFO - Epoch [2][2150/32058]	lr: 2.000e-02, eta: 2 days, 18:10:33, time: 1.483, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:25:16,921 - mmdet - INFO - Epoch [2][2200/32058]	lr: 2.000e-02, eta: 2 days, 18:09:11, time: 1.477, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:26:31,246 - mmdet - INFO - Epoch [2][2250/32058]	lr: 2.000e-02, eta: 2 days, 18:07:51, time: 1.486, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:27:45,278 - mmdet - INFO - Epoch [2][2300/32058]	lr: 2.000e-02, eta: 2 days, 18:06:29, time: 1.481, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:28:59,051 - mmdet - INFO - Epoch [2][2350/32058]	lr: 2.000e-02, eta: 2 days, 18:05:07, time: 1.475, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:30:12,960 - mmdet - INFO - Epoch [2][2400/32058]	lr: 2.000e-02, eta: 2 days, 18:03:45, time: 1.478, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:31:27,296 - mmdet - INFO - Epoch [2][2450/32058]	lr: 2.000e-02, eta: 2 days, 18:02:26, time: 1.487, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:32:41,745 - mmdet - INFO - Epoch [2][2500/32058]	lr: 2.000e-02, eta: 2 days, 18:01:06, time: 1.489, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:33:56,405 - mmdet - INFO - Epoch [2][2550/32058]	lr: 2.000e-02, eta: 2 days, 17:59:48, time: 1.493, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:35:10,246 - mmdet - INFO - Epoch [2][2600/32058]	lr: 2.000e-02, eta: 2 days, 17:58:26, time: 1.477, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:36:24,956 - mmdet - INFO - Epoch [2][2650/32058]	lr: 2.000e-02, eta: 2 days, 17:57:08, time: 1.494, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:37:39,859 - mmdet - INFO - Epoch [2][2700/32058]	lr: 2.000e-02, eta: 2 days, 17:55:51, time: 1.498, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:38:54,334 - mmdet - INFO - Epoch [2][2750/32058]	lr: 2.000e-02, eta: 2 days, 17:54:32, time: 1.489, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:40:07,344 - mmdet - INFO - Epoch [2][2800/32058]	lr: 2.000e-02, eta: 2 days, 17:53:06, time: 1.460, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:41:21,834 - mmdet - INFO - Epoch [2][2850/32058]	lr: 2.000e-02, eta: 2 days, 17:51:47, time: 1.490, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:42:36,013 - mmdet - INFO - Epoch [2][2900/32058]	lr: 2.000e-02, eta: 2 days, 17:50:27, time: 1.484, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:43:50,513 - mmdet - INFO - Epoch [2][2950/32058]	lr: 2.000e-02, eta: 2 days, 17:49:08, time: 1.490, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:45:05,249 - mmdet - INFO - Epoch [2][3000/32058]	lr: 2.000e-02, eta: 2 days, 17:47:50, time: 1.495, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:46:18,491 - mmdet - INFO - Epoch [2][3050/32058]	lr: 2.000e-02, eta: 2 days, 17:46:26, time: 1.465, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:47:32,456 - mmdet - INFO - Epoch [2][3100/32058]	lr: 2.000e-02, eta: 2 days, 17:45:04, time: 1.479, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:48:47,132 - mmdet - INFO - Epoch [2][3150/32058]	lr: 2.000e-02, eta: 2 days, 17:43:46, time: 1.494, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:50:00,579 - mmdet - INFO - Epoch [2][3200/32058]	lr: 2.000e-02, eta: 2 days, 17:42:23, time: 1.469, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:51:14,503 - mmdet - INFO - Epoch [2][3250/32058]	lr: 2.000e-02, eta: 2 days, 17:41:01, time: 1.478, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:52:28,266 - mmdet - INFO - Epoch [2][3300/32058]	lr: 2.000e-02, eta: 2 days, 17:39:39, time: 1.475, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:53:42,651 - mmdet - INFO - Epoch [2][3350/32058]	lr: 2.000e-02, eta: 2 days, 17:38:20, time: 1.488, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:54:56,185 - mmdet - INFO - Epoch [2][3400/32058]	lr: 2.000e-02, eta: 2 days, 17:36:57, time: 1.471, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:56:10,920 - mmdet - INFO - Epoch [2][3450/32058]	lr: 2.000e-02, eta: 2 days, 17:35:39, time: 1.495, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:57:25,960 - mmdet - INFO - Epoch [2][3500/32058]	lr: 2.000e-02, eta: 2 days, 17:34:23, time: 1.501, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:58:40,951 - mmdet - INFO - Epoch [2][3550/32058]	lr: 2.000e-02, eta: 2 days, 17:33:06, time: 1.500, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 12:59:55,671 - mmdet - INFO - Epoch [2][3600/32058]	lr: 2.000e-02, eta: 2 days, 17:31:49, time: 1.494, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:01:09,214 - mmdet - INFO - Epoch [2][3650/32058]	lr: 2.000e-02, eta: 2 days, 17:30:26, time: 1.471, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:02:24,625 - mmdet - INFO - Epoch [2][3700/32058]	lr: 2.000e-02, eta: 2 days, 17:29:11, time: 1.508, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:03:38,119 - mmdet - INFO - Epoch [2][3750/32058]	lr: 2.000e-02, eta: 2 days, 17:27:48, time: 1.470, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:04:51,997 - mmdet - INFO - Epoch [2][3800/32058]	lr: 2.000e-02, eta: 2 days, 17:26:27, time: 1.478, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:06:07,039 - mmdet - INFO - Epoch [2][3850/32058]	lr: 2.000e-02, eta: 2 days, 17:25:10, time: 1.501, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:07:21,234 - mmdet - INFO - Epoch [2][3900/32058]	lr: 2.000e-02, eta: 2 days, 17:23:50, time: 1.484, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:08:34,917 - mmdet - INFO - Epoch [2][3950/32058]	lr: 2.000e-02, eta: 2 days, 17:22:28, time: 1.474, data_time: 0.016, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:09:47,612 - mmdet - INFO - Epoch [2][4000/32058]	lr: 2.000e-02, eta: 2 days, 17:21:02, time: 1.454, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:11:02,930 - mmdet - INFO - Epoch [2][4050/32058]	lr: 2.000e-02, eta: 2 days, 17:19:47, time: 1.506, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:12:18,057 - mmdet - INFO - Epoch [2][4100/32058]	lr: 2.000e-02, eta: 2 days, 17:18:31, time: 1.503, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:13:32,919 - mmdet - INFO - Epoch [2][4150/32058]	lr: 2.000e-02, eta: 2 days, 17:17:14, time: 1.497, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:14:46,261 - mmdet - INFO - Epoch [2][4200/32058]	lr: 2.000e-02, eta: 2 days, 17:15:50, time: 1.467, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:16:00,411 - mmdet - INFO - Epoch [2][4250/32058]	lr: 2.000e-02, eta: 2 days, 17:14:30, time: 1.483, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:17:14,039 - mmdet - INFO - Epoch [2][4300/32058]	lr: 2.000e-02, eta: 2 days, 17:13:08, time: 1.473, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:18:27,362 - mmdet - INFO - Epoch [2][4350/32058]	lr: 2.000e-02, eta: 2 days, 17:11:45, time: 1.466, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:19:40,272 - mmdet - INFO - Epoch [2][4400/32058]	lr: 2.000e-02, eta: 2 days, 17:10:19, time: 1.458, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:20:53,795 - mmdet - INFO - Epoch [2][4450/32058]	lr: 2.000e-02, eta: 2 days, 17:08:57, time: 1.470, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:22:07,777 - mmdet - INFO - Epoch [2][4500/32058]	lr: 2.000e-02, eta: 2 days, 17:07:36, time: 1.480, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:23:23,069 - mmdet - INFO - Epoch [2][4550/32058]	lr: 2.000e-02, eta: 2 days, 17:06:21, time: 1.506, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:24:37,984 - mmdet - INFO - Epoch [2][4600/32058]	lr: 2.000e-02, eta: 2 days, 17:05:04, time: 1.498, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:25:52,432 - mmdet - INFO - Epoch [2][4650/32058]	lr: 2.000e-02, eta: 2 days, 17:03:46, time: 1.489, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:27:07,955 - mmdet - INFO - Epoch [2][4700/32058]	lr: 2.000e-02, eta: 2 days, 17:02:32, time: 1.510, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:28:22,005 - mmdet - INFO - Epoch [2][4750/32058]	lr: 2.000e-02, eta: 2 days, 17:01:11, time: 1.481, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:29:35,245 - mmdet - INFO - Epoch [2][4800/32058]	lr: 2.000e-02, eta: 2 days, 16:59:48, time: 1.465, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:30:50,632 - mmdet - INFO - Epoch [2][4850/32058]	lr: 2.000e-02, eta: 2 days, 16:58:33, time: 1.508, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:32:05,133 - mmdet - INFO - Epoch [2][4900/32058]	lr: 2.000e-02, eta: 2 days, 16:57:15, time: 1.490, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:33:19,683 - mmdet - INFO - Epoch [2][4950/32058]	lr: 2.000e-02, eta: 2 days, 16:55:56, time: 1.491, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:34:33,838 - mmdet - INFO - Epoch [2][5000/32058]	lr: 2.000e-02, eta: 2 days, 16:54:37, time: 1.483, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:35:48,194 - mmdet - INFO - Epoch [2][5050/32058]	lr: 2.000e-02, eta: 2 days, 16:53:18, time: 1.487, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:37:03,643 - mmdet - INFO - Epoch [2][5100/32058]	lr: 2.000e-02, eta: 2 days, 16:52:03, time: 1.509, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:38:16,475 - mmdet - INFO - Epoch [2][5150/32058]	lr: 2.000e-02, eta: 2 days, 16:50:38, time: 1.457, data_time: 0.016, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:39:31,606 - mmdet - INFO - Epoch [2][5200/32058]	lr: 2.000e-02, eta: 2 days, 16:49:22, time: 1.503, data_time: 0.024, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:40:46,287 - mmdet - INFO - Epoch [2][5250/32058]	lr: 2.000e-02, eta: 2 days, 16:48:05, time: 1.494, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:42:00,440 - mmdet - INFO - Epoch [2][5300/32058]	lr: 2.000e-02, eta: 2 days, 16:46:45, time: 1.483, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:43:14,826 - mmdet - INFO - Epoch [2][5350/32058]	lr: 2.000e-02, eta: 2 days, 16:45:26, time: 1.488, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:44:29,615 - mmdet - INFO - Epoch [2][5400/32058]	lr: 2.000e-02, eta: 2 days, 16:44:09, time: 1.496, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:45:44,342 - mmdet - INFO - Epoch [2][5450/32058]	lr: 2.000e-02, eta: 2 days, 16:42:52, time: 1.495, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:46:58,607 - mmdet - INFO - Epoch [2][5500/32058]	lr: 2.000e-02, eta: 2 days, 16:41:33, time: 1.485, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:48:12,930 - mmdet - INFO - Epoch [2][5550/32058]	lr: 2.000e-02, eta: 2 days, 16:40:14, time: 1.486, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:49:28,816 - mmdet - INFO - Epoch [2][5600/32058]	lr: 2.000e-02, eta: 2 days, 16:39:01, time: 1.518, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:50:43,367 - mmdet - INFO - Epoch [2][5650/32058]	lr: 2.000e-02, eta: 2 days, 16:37:43, time: 1.491, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:51:59,193 - mmdet - INFO - Epoch [2][5700/32058]	lr: 2.000e-02, eta: 2 days, 16:36:31, time: 1.517, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:53:14,382 - mmdet - INFO - Epoch [2][5750/32058]	lr: 2.000e-02, eta: 2 days, 16:35:15, time: 1.504, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:54:29,666 - mmdet - INFO - Epoch [2][5800/32058]	lr: 2.000e-02, eta: 2 days, 16:34:00, time: 1.506, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:55:43,985 - mmdet - INFO - Epoch [2][5850/32058]	lr: 2.000e-02, eta: 2 days, 16:32:41, time: 1.486, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:57:00,392 - mmdet - INFO - Epoch [2][5900/32058]	lr: 2.000e-02, eta: 2 days, 16:31:31, time: 1.528, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:58:15,174 - mmdet - INFO - Epoch [2][5950/32058]	lr: 2.000e-02, eta: 2 days, 16:30:14, time: 1.496, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 13:59:29,777 - mmdet - INFO - Epoch [2][6000/32058]	lr: 2.000e-02, eta: 2 days, 16:28:56, time: 1.492, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:00:45,580 - mmdet - INFO - Epoch [2][6050/32058]	lr: 2.000e-02, eta: 2 days, 16:27:43, time: 1.516, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:02:00,726 - mmdet - INFO - Epoch [2][6100/32058]	lr: 2.000e-02, eta: 2 days, 16:26:27, time: 1.503, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:03:15,822 - mmdet - INFO - Epoch [2][6150/32058]	lr: 2.000e-02, eta: 2 days, 16:25:12, time: 1.502, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:04:30,844 - mmdet - INFO - Epoch [2][6200/32058]	lr: 2.000e-02, eta: 2 days, 16:23:56, time: 1.500, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:05:45,719 - mmdet - INFO - Epoch [2][6250/32058]	lr: 2.000e-02, eta: 2 days, 16:22:39, time: 1.498, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:06:59,968 - mmdet - INFO - Epoch [2][6300/32058]	lr: 2.000e-02, eta: 2 days, 16:21:20, time: 1.485, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:08:15,070 - mmdet - INFO - Epoch [2][6350/32058]	lr: 2.000e-02, eta: 2 days, 16:20:04, time: 1.502, data_time: 0.024, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:09:29,962 - mmdet - INFO - Epoch [2][6400/32058]	lr: 2.000e-02, eta: 2 days, 16:18:48, time: 1.498, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:10:43,672 - mmdet - INFO - Epoch [2][6450/32058]	lr: 2.000e-02, eta: 2 days, 16:17:26, time: 1.474, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:11:58,020 - mmdet - INFO - Epoch [2][6500/32058]	lr: 2.000e-02, eta: 2 days, 16:16:08, time: 1.487, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:13:12,982 - mmdet - INFO - Epoch [2][6550/32058]	lr: 2.000e-02, eta: 2 days, 16:14:51, time: 1.499, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:14:26,816 - mmdet - INFO - Epoch [2][6600/32058]	lr: 2.000e-02, eta: 2 days, 16:13:31, time: 1.477, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:15:42,273 - mmdet - INFO - Epoch [2][6650/32058]	lr: 2.000e-02, eta: 2 days, 16:12:16, time: 1.509, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:17:02,531 - mmdet - INFO - Epoch [2][6700/32058]	lr: 2.000e-02, eta: 2 days, 16:11:21, time: 1.605, data_time: 0.128, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:18:16,978 - mmdet - INFO - Epoch [2][6750/32058]	lr: 2.000e-02, eta: 2 days, 16:10:03, time: 1.489, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:19:32,781 - mmdet - INFO - Epoch [2][6800/32058]	lr: 2.000e-02, eta: 2 days, 16:08:50, time: 1.516, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:20:46,978 - mmdet - INFO - Epoch [2][6850/32058]	lr: 2.000e-02, eta: 2 days, 16:07:31, time: 1.484, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:22:02,853 - mmdet - INFO - Epoch [2][6900/32058]	lr: 2.000e-02, eta: 2 days, 16:06:18, time: 1.517, data_time: 0.025, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:23:18,023 - mmdet - INFO - Epoch [2][6950/32058]	lr: 2.000e-02, eta: 2 days, 16:05:02, time: 1.503, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:24:33,406 - mmdet - INFO - Epoch [2][7000/32058]	lr: 2.000e-02, eta: 2 days, 16:03:48, time: 1.508, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:25:48,240 - mmdet - INFO - Epoch [2][7050/32058]	lr: 2.000e-02, eta: 2 days, 16:02:31, time: 1.497, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:27:02,513 - mmdet - INFO - Epoch [2][7100/32058]	lr: 2.000e-02, eta: 2 days, 16:01:12, time: 1.485, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:28:16,519 - mmdet - INFO - Epoch [2][7150/32058]	lr: 2.000e-02, eta: 2 days, 15:59:52, time: 1.480, data_time: 0.019, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:29:31,262 - mmdet - INFO - Epoch [2][7200/32058]	lr: 2.000e-02, eta: 2 days, 15:58:35, time: 1.495, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:30:46,948 - mmdet - INFO - Epoch [2][7250/32058]	lr: 2.000e-02, eta: 2 days, 15:57:22, time: 1.514, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:32:01,327 - mmdet - INFO - Epoch [2][7300/32058]	lr: 2.000e-02, eta: 2 days, 15:56:03, time: 1.488, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:33:15,177 - mmdet - INFO - Epoch [2][7350/32058]	lr: 2.000e-02, eta: 2 days, 15:54:43, time: 1.477, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:34:29,381 - mmdet - INFO - Epoch [2][7400/32058]	lr: 2.000e-02, eta: 2 days, 15:53:23, time: 1.484, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:35:44,302 - mmdet - INFO - Epoch [2][7450/32058]	lr: 2.000e-02, eta: 2 days, 15:52:07, time: 1.498, data_time: 0.017, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:36:58,866 - mmdet - INFO - Epoch [2][7500/32058]	lr: 2.000e-02, eta: 2 days, 15:50:49, time: 1.491, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:38:14,045 - mmdet - INFO - Epoch [2][7550/32058]	lr: 2.000e-02, eta: 2 days, 15:49:34, time: 1.504, data_time: 0.021, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:39:29,177 - mmdet - INFO - Epoch [2][7600/32058]	lr: 2.000e-02, eta: 2 days, 15:48:18, time: 1.503, data_time: 0.023, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:40:43,848 - mmdet - INFO - Epoch [2][7650/32058]	lr: 2.000e-02, eta: 2 days, 15:47:01, time: 1.493, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:41:59,455 - mmdet - INFO - Epoch [2][7700/32058]	lr: 2.000e-02, eta: 2 days, 15:45:47, time: 1.512, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:43:14,400 - mmdet - INFO - Epoch [2][7750/32058]	lr: 2.000e-02, eta: 2 days, 15:44:31, time: 1.499, data_time: 0.022, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:44:30,319 - mmdet - INFO - Epoch [2][7800/32058]	lr: 2.000e-02, eta: 2 days, 15:43:18, time: 1.518, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:45:45,421 - mmdet - INFO - Epoch [2][7850/32058]	lr: 2.000e-02, eta: 2 days, 15:42:03, time: 1.502, data_time: 0.020, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:47:00,483 - mmdet - INFO - Epoch [2][7900/32058]	lr: 2.000e-02, eta: 2 days, 15:40:47, time: 1.501, data_time: 0.018, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
2022-05-06 14:48:16,204 - mmdet - INFO - Epoch [2][7950/32058]	lr: 2.000e-02, eta: 2 days, 15:39:34, time: 1.514, data_time: 0.051, memory: 19246, loss_rpn_cls: nan, loss_rpn_bbox: nan, loss_semantic_seg: nan, s0.loss_cls: nan, s0.acc: 100.0000, s0.loss_bbox: nan, s0.loss_mask: nan, s1.loss_cls: nan, s1.acc: 100.0000, s1.loss_bbox: nan, s1.loss_mask: nan, s2.loss_cls: nan, s2.acc: 100.0000, s2.loss_bbox: nan, s2.loss_mask: nan, loss: nan, grad_norm: nan
