{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASETS\n",
    "# DOWNLOAD COCO\n",
    "!bash scripts/coco.sh\n",
    "\n",
    "# INDIVIDUAL FRAMES MUST BE STORED IN ./dataset/frames/train/\n",
    "# game frames stored in trainA and movie frames stored in trainB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN INSTANCE SEGMENTATION MODEL\n",
    "\n",
    "from mmcv import Config\n",
    "from mmdet.apis import train_detector\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.utils import update_data_root\n",
    "\n",
    "cfg = Config.fromfile(\"./detectoRS/configs/custom/detectors_instaboost.py\")\n",
    "\n",
    "update_data_root(cfg)\n",
    "model = build_detector(cfg.model)\n",
    "\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "model.CLASSES = cfg.CLASSES\n",
    "train_detector(\n",
    "        model,\n",
    "        datasets,\n",
    "        cfg,\n",
    "        distributed=False,\n",
    "        validate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST INSTANCE SEGMENTATION MODEL\n",
    "\n",
    "from mmcv import Config\n",
    "from mmdet.apis import train_detector,  single_gpu_test\n",
    "from mmdet.datasets import build_dataloader, build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.utils import update_data_root\n",
    "from mmcv.runner import load_checkpoint\n",
    "from mmcv.parallel import MMDataParallel\n",
    "\n",
    "cfg = Config.fromfile(\"./detectoRS/configs/custom/detectors_instaboost.py\")\n",
    "\n",
    "# update data root according to MMDET_DATASETS\n",
    "update_data_root(cfg)\n",
    "\n",
    "# build the dataloader\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "    dataset,\n",
    "    shuffle=False,\n",
    "    samples_per_gpu=1,\n",
    "    workers_per_gpu=1\n",
    ")\n",
    "\n",
    "# build the model and load checkpoint\n",
    "cfg.model.train_cfg = None\n",
    "\n",
    "model = build_detector(cfg.model, test_cfg=cfg.get('test_cfg'))\n",
    "checkpoint = load_checkpoint(model, './detectoRS/checkpoints/detectors_finetuned.pth', map_location='cpu')\n",
    "    \n",
    "model.CLASSES = cfg.CLASSES\n",
    "\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader, None, None, 0.3)\n",
    "\n",
    "dataset.format_results(outputs, **{'jsonfile_prefix': '../dataset/annotation/test'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN CLASSIFICATION MODEL\n",
    "\n",
    "from mmcv import Config\n",
    "from mmcls.apis import train_model\n",
    "from mmcls.datasets import build_dataset\n",
    "from mmcls.models import build_classifier\n",
    "\n",
    "cfg = Config.fromfile('./swin_transformer/configs/custom/swin_tiny.py')\n",
    "  \n",
    "model = build_classifier(cfg.model)\n",
    "model.init_weights()\n",
    "\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "train_model(\n",
    "    model,\n",
    "    datasets,\n",
    "    cfg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST CLASSIFICATION MODEL\n",
    "\n",
    "import mmcv\n",
    "import numpy as np\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmcv.runner import load_checkpoint\n",
    "\n",
    "from mmcls.apis import single_gpu_test\n",
    "from mmcls.datasets import build_dataloader, build_dataset\n",
    "from mmcls.models import build_classifier\n",
    "\n",
    "cfg = mmcv.Config.fromfile('./swin_transformer/configs/custom/swin_tiny.py')\n",
    "\n",
    "dataset = build_dataset(cfg.data.test, default_args=dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "    dataset,\n",
    "    shuffle=False,\n",
    "    samples_per_gpu=1,\n",
    "    workers_per_gpu=1\n",
    ")\n",
    "\n",
    "model = build_classifier(cfg.model)\n",
    "checkpoint = load_checkpoint(model, './swin_transformer/checkpoints/swin_finetuned.pth', map_location='cpu')\n",
    "\n",
    "if 'CLASSES' in checkpoint.get('meta', {}):\n",
    "    CLASSES = checkpoint['meta']['CLASSES']\n",
    "\n",
    "outputs = single_gpu_test(model, data_loader, None, None)\n",
    "\n",
    "results = {}\n",
    "scores = np.vstack(outputs)\n",
    "pred_score = np.max(scores, axis=1)\n",
    "pred_label = np.argmax(scores, axis=1)\n",
    "pred_class = [CLASSES[lb] for lb in pred_label]\n",
    "res_items = {\n",
    "    'class_scores': scores,\n",
    "    'pred_score': pred_score,\n",
    "    'pred_label': pred_label,\n",
    "    'pred_class': pred_class\n",
    "}\n",
    "results.update(res_items)\n",
    "        \n",
    "mmcv.dump(results, \"./classification_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TRANSLATION MODEL\n",
    "\n",
    "# AtoB or BtoA\n",
    "direction = \"AtoB\"\n",
    "\n",
    "# 2.2) mask or no-mask\n",
    "mask = \"no-mask\"\n",
    "\n",
    "# 2.3) sample or no-sample\n",
    "sample = \"sample\"\n",
    "\n",
    "# num epochs\n",
    "epochs = 50\n",
    "\n",
    "!bash cut/train.sh {direction} {mask} {sample} {epochs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST TRANSLATION MODEL\n",
    "\n",
    "# AtoB or BtoA\n",
    "direction = \"AtoB\"\n",
    "\n",
    "# 2.2) mask or no-mask\n",
    "mask = \"no-mask\"\n",
    "\n",
    "# 2.3) sample or no-sample\n",
    "sample = \"sample\"\n",
    "\n",
    "!bash cut/test.sh {direction} {mask} {sample}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE FID SCORE\n",
    "\n",
    "# AtoB or BtoA\n",
    "direction = \"AtoB\"\n",
    "\n",
    "# 2.2) mask or no-mask\n",
    "mask = \"no-mask\"\n",
    "\n",
    "# 2.3) sample or no-sample\n",
    "sample = \"sample\"\n",
    "\n",
    "!bash cut/fid.sh "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e7bebb7c2a30dc1dd13f02ef965cce5c6376c7878fdfb39dfc17a775719c289"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
