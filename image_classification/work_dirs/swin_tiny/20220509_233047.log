2022-05-09 23:30:47,276 - mmcls - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.11 (default, Jul  3 2021, 17:53:42) [GCC 7.5.0]
CUDA available: True
GPU 0: NVIDIA TITAN RTX
CUDA_HOME: /apps/cuda/cuda-11.0-cudnn8.0
NVCC: Not Available
GCC: x86_64-linux-gnu-gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
PyTorch: 1.7.1+cu110
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.8.2+cu110
OpenCV: 4.5.5
MMCV: 1.5.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.0
MMClassification: 0.23.0+54b7d54
------------------------------------------------------------

2022-05-09 23:30:47,277 - mmcls - INFO - Distributed training: False
2022-05-09 23:30:47,724 - mmcls - INFO - Config:
model = dict(
    type='ImageClassifier',
    backbone=dict(
        type='SwinTransformer', arch='tiny', img_size=224, drop_path_rate=0.2),
    neck=dict(type='GlobalAveragePooling'),
    head=dict(
        type='LinearClsHead',
        num_classes=5,
        in_channels=768,
        init_cfg=None,
        loss=dict(
            type='LabelSmoothLoss', label_smooth_val=0.1, mode='original'),
        cal_acc=False),
    init_cfg=[
        dict(type='TruncNormal', layer='Linear', std=0.02, bias=0.0),
        dict(type='Constant', layer='LayerNorm', val=1.0, bias=0.0)
    ],
    train_cfg=dict(augments=[
        dict(type='BatchMixup', alpha=0.8, num_classes=5, prob=0.5),
        dict(type='BatchCutMix', alpha=1.0, num_classes=5, prob=0.5)
    ]))
rand_increasing_policies = [
    dict(type='AutoContrast'),
    dict(type='Equalize'),
    dict(type='Invert'),
    dict(type='Rotate', magnitude_key='angle', magnitude_range=(0, 30)),
    dict(type='Posterize', magnitude_key='bits', magnitude_range=(4, 0)),
    dict(type='Solarize', magnitude_key='thr', magnitude_range=(256, 0)),
    dict(
        type='SolarizeAdd',
        magnitude_key='magnitude',
        magnitude_range=(0, 110)),
    dict(
        type='ColorTransform',
        magnitude_key='magnitude',
        magnitude_range=(0, 0.9)),
    dict(type='Contrast', magnitude_key='magnitude', magnitude_range=(0, 0.9)),
    dict(
        type='Brightness', magnitude_key='magnitude',
        magnitude_range=(0, 0.9)),
    dict(
        type='Sharpness', magnitude_key='magnitude', magnitude_range=(0, 0.9)),
    dict(
        type='Shear',
        magnitude_key='magnitude',
        magnitude_range=(0, 0.3),
        direction='horizontal'),
    dict(
        type='Shear',
        magnitude_key='magnitude',
        magnitude_range=(0, 0.3),
        direction='vertical'),
    dict(
        type='Translate',
        magnitude_key='magnitude',
        magnitude_range=(0, 0.45),
        direction='horizontal'),
    dict(
        type='Translate',
        magnitude_key='magnitude',
        magnitude_range=(0, 0.45),
        direction='vertical')
]
dataset_type = 'ImageNet'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='RandomResizedCrop',
        size=224,
        backend='pillow',
        interpolation='bicubic'),
    dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
    dict(
        type='RandAugment',
        policies=[
            dict(type='AutoContrast'),
            dict(type='Equalize'),
            dict(type='Invert'),
            dict(
                type='Rotate', magnitude_key='angle', magnitude_range=(0, 30)),
            dict(
                type='Posterize', magnitude_key='bits',
                magnitude_range=(4, 0)),
            dict(
                type='Solarize', magnitude_key='thr',
                magnitude_range=(256, 0)),
            dict(
                type='SolarizeAdd',
                magnitude_key='magnitude',
                magnitude_range=(0, 110)),
            dict(
                type='ColorTransform',
                magnitude_key='magnitude',
                magnitude_range=(0, 0.9)),
            dict(
                type='Contrast',
                magnitude_key='magnitude',
                magnitude_range=(0, 0.9)),
            dict(
                type='Brightness',
                magnitude_key='magnitude',
                magnitude_range=(0, 0.9)),
            dict(
                type='Sharpness',
                magnitude_key='magnitude',
                magnitude_range=(0, 0.9)),
            dict(
                type='Shear',
                magnitude_key='magnitude',
                magnitude_range=(0, 0.3),
                direction='horizontal'),
            dict(
                type='Shear',
                magnitude_key='magnitude',
                magnitude_range=(0, 0.3),
                direction='vertical'),
            dict(
                type='Translate',
                magnitude_key='magnitude',
                magnitude_range=(0, 0.45),
                direction='horizontal'),
            dict(
                type='Translate',
                magnitude_key='magnitude',
                magnitude_range=(0, 0.45),
                direction='vertical')
        ],
        num_policies=2,
        total_level=10,
        magnitude_level=9,
        magnitude_std=0.5,
        hparams=dict(pad_val=[104, 116, 124], interpolation='bicubic')),
    dict(
        type='RandomErasing',
        erase_prob=0.25,
        mode='rand',
        min_area_ratio=0.02,
        max_area_ratio=0.3333333333333333,
        fill_color=[103.53, 116.28, 123.675],
        fill_std=[57.375, 57.12, 58.395]),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='ImageToTensor', keys=['img']),
    dict(type='ToTensor', keys=['gt_label']),
    dict(type='Collect', keys=['img', 'gt_label'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='Resize',
        size=(256, -1),
        backend='pillow',
        interpolation='bicubic'),
    dict(type='CenterCrop', crop_size=224),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='ImageToTensor', keys=['img']),
    dict(type='Collect', keys=['img'])
]
data = dict(
    samples_per_gpu=64,
    workers_per_gpu=8,
    train=dict(
        type='ImageNet',
        data_prefix='../dataset/patches/classified/train/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='RandomResizedCrop',
                size=224,
                backend='pillow',
                interpolation='bicubic'),
            dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
            dict(
                type='RandAugment',
                policies=[
                    dict(type='AutoContrast'),
                    dict(type='Equalize'),
                    dict(type='Invert'),
                    dict(
                        type='Rotate',
                        magnitude_key='angle',
                        magnitude_range=(0, 30)),
                    dict(
                        type='Posterize',
                        magnitude_key='bits',
                        magnitude_range=(4, 0)),
                    dict(
                        type='Solarize',
                        magnitude_key='thr',
                        magnitude_range=(256, 0)),
                    dict(
                        type='SolarizeAdd',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 110)),
                    dict(
                        type='ColorTransform',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.9)),
                    dict(
                        type='Contrast',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.9)),
                    dict(
                        type='Brightness',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.9)),
                    dict(
                        type='Sharpness',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.9)),
                    dict(
                        type='Shear',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.3),
                        direction='horizontal'),
                    dict(
                        type='Shear',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.3),
                        direction='vertical'),
                    dict(
                        type='Translate',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.45),
                        direction='horizontal'),
                    dict(
                        type='Translate',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.45),
                        direction='vertical')
                ],
                num_policies=2,
                total_level=10,
                magnitude_level=9,
                magnitude_std=0.5,
                hparams=dict(pad_val=[104, 116, 124],
                             interpolation='bicubic')),
            dict(
                type='RandomErasing',
                erase_prob=0.25,
                mode='rand',
                min_area_ratio=0.02,
                max_area_ratio=0.3333333333333333,
                fill_color=[103.53, 116.28, 123.675],
                fill_std=[57.375, 57.12, 58.395]),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='ToTensor', keys=['gt_label']),
            dict(type='Collect', keys=['img', 'gt_label'])
        ],
        classes='../dataset/annotation/classes.txt'),
    val=dict(
        type='ImageNet',
        data_prefix='../dataset/patches/classified/val/',
        ann_file='../dataset/annotation/val.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='Resize',
                size=(256, -1),
                backend='pillow',
                interpolation='bicubic'),
            dict(type='CenterCrop', crop_size=224),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ],
        classes='../dataset/annotation/classes.txt'),
    test=dict(
        type='ImageNet',
        data_prefix='../dataset/patches/classified/val/',
        ann_file='../dataset/annotation/classes/val.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='Resize',
                size=(256, -1),
                backend='pillow',
                interpolation='bicubic'),
            dict(type='CenterCrop', crop_size=224),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ],
        classes='../dataset/annotation/classes.txt'))
evaluation = dict(interval=5, metric='accuracy')
paramwise_cfg = dict(
    norm_decay_mult=0.0,
    bias_decay_mult=0.0,
    custom_keys=dict({
        '.absolute_pos_embed': dict(decay_mult=0.0),
        '.relative_position_bias_table': dict(decay_mult=0.0)
    }))
optimizer = dict(
    type='AdamW',
    lr=0.001,
    weight_decay=0.05,
    eps=1e-08,
    betas=(0.9, 0.999),
    paramwise_cfg=dict(
        norm_decay_mult=0.0,
        bias_decay_mult=0.0,
        custom_keys=dict({
            '.absolute_pos_embed': dict(decay_mult=0.0),
            '.relative_position_bias_table': dict(decay_mult=0.0)
        })))
optimizer_config = dict(grad_clip=dict(max_norm=5.0))
lr_config = dict(
    policy='CosineAnnealing',
    by_epoch=False,
    min_lr_ratio=0.01,
    warmup='linear',
    warmup_ratio=0.001,
    warmup_iters=20,
    warmup_by_epoch=True)
runner = dict(type='EpochBasedRunner', max_epochs=300)
checkpoint_config = dict(interval=1)
log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = './checkpoints/swin_small_224_b16x64_300e_imagenet_20210615_110219-7f9d988b.pth'
resume_from = None
workflow = [('train', 1)]
work_dir = './work_dirs/swin_tiny'
gpu_ids = [0]

2022-05-09 23:30:47,724 - mmcls - INFO - Set random seed to 1313777485, deterministic: False
2022-05-09 23:30:47,996 - mmcls - INFO - initialize ImageClassifier with init_cfg [{'type': 'TruncNormal', 'layer': 'Linear', 'std': 0.02, 'bias': 0.0}, {'type': 'Constant', 'layer': 'LayerNorm', 'val': 1.0, 'bias': 0.0}]
Name of parameter - Initialization information

backbone.patch_embed.projection.weight - torch.Size([96, 3, 4, 4]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.patch_embed.projection.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.patch_embed.norm.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.patch_embed.norm.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.0.blocks.0.norm1.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.0.blocks.0.norm1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
Initialized by user-defined `init_weights` in WindowMSA  

backbone.stages.0.blocks.0.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.blocks.0.attn.w_msa.qkv.bias - torch.Size([288]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.blocks.0.attn.w_msa.proj.weight - torch.Size([96, 96]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.blocks.0.attn.w_msa.proj.bias - torch.Size([96]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.blocks.0.norm2.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.0.blocks.0.norm2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.0.blocks.0.ffn.layers.0.0.weight - torch.Size([384, 96]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.blocks.0.ffn.layers.0.0.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.blocks.0.ffn.layers.1.weight - torch.Size([96, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.blocks.0.ffn.layers.1.bias - torch.Size([96]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.blocks.1.norm1.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.0.blocks.1.norm1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
Initialized by user-defined `init_weights` in WindowMSA  

backbone.stages.0.blocks.1.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.blocks.1.attn.w_msa.qkv.bias - torch.Size([288]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.blocks.1.attn.w_msa.proj.weight - torch.Size([96, 96]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.blocks.1.attn.w_msa.proj.bias - torch.Size([96]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.blocks.1.norm2.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.0.blocks.1.norm2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.0.blocks.1.ffn.layers.0.0.weight - torch.Size([384, 96]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.blocks.1.ffn.layers.0.0.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.blocks.1.ffn.layers.1.weight - torch.Size([96, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.blocks.1.ffn.layers.1.bias - torch.Size([96]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.downsample.norm.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.0.downsample.norm.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.0.downsample.reduction.weight - torch.Size([192, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.blocks.0.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.1.blocks.0.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
Initialized by user-defined `init_weights` in WindowMSA  

backbone.stages.1.blocks.0.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.blocks.0.attn.w_msa.qkv.bias - torch.Size([576]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.blocks.0.attn.w_msa.proj.weight - torch.Size([192, 192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.blocks.0.attn.w_msa.proj.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.blocks.0.norm2.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.1.blocks.0.norm2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.1.blocks.0.ffn.layers.0.0.weight - torch.Size([768, 192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.blocks.0.ffn.layers.0.0.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.blocks.0.ffn.layers.1.weight - torch.Size([192, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.blocks.0.ffn.layers.1.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.blocks.1.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.1.blocks.1.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
Initialized by user-defined `init_weights` in WindowMSA  

backbone.stages.1.blocks.1.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.blocks.1.attn.w_msa.qkv.bias - torch.Size([576]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.blocks.1.attn.w_msa.proj.weight - torch.Size([192, 192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.blocks.1.attn.w_msa.proj.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.blocks.1.norm2.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.1.blocks.1.norm2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.1.blocks.1.ffn.layers.0.0.weight - torch.Size([768, 192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.blocks.1.ffn.layers.0.0.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.blocks.1.ffn.layers.1.weight - torch.Size([192, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.blocks.1.ffn.layers.1.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.downsample.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.1.downsample.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.1.downsample.reduction.weight - torch.Size([384, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.0.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.0.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in WindowMSA  

backbone.stages.2.blocks.0.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.0.attn.w_msa.qkv.bias - torch.Size([1152]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.0.attn.w_msa.proj.weight - torch.Size([384, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.0.attn.w_msa.proj.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.0.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.0.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.0.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.0.ffn.layers.0.0.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.0.ffn.layers.1.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.0.ffn.layers.1.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.1.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.1.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in WindowMSA  

backbone.stages.2.blocks.1.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.1.attn.w_msa.qkv.bias - torch.Size([1152]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.1.attn.w_msa.proj.weight - torch.Size([384, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.1.attn.w_msa.proj.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.1.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.1.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.1.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.1.ffn.layers.0.0.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.1.ffn.layers.1.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.1.ffn.layers.1.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.2.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.2.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in WindowMSA  

backbone.stages.2.blocks.2.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.2.attn.w_msa.qkv.bias - torch.Size([1152]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.2.attn.w_msa.proj.weight - torch.Size([384, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.2.attn.w_msa.proj.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.2.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.2.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.2.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.2.ffn.layers.0.0.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.2.ffn.layers.1.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.2.ffn.layers.1.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.3.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.3.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in WindowMSA  

backbone.stages.2.blocks.3.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.3.attn.w_msa.qkv.bias - torch.Size([1152]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.3.attn.w_msa.proj.weight - torch.Size([384, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.3.attn.w_msa.proj.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.3.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.3.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.3.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.3.ffn.layers.0.0.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.3.ffn.layers.1.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.3.ffn.layers.1.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.4.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.4.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in WindowMSA  

backbone.stages.2.blocks.4.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.4.attn.w_msa.qkv.bias - torch.Size([1152]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.4.attn.w_msa.proj.weight - torch.Size([384, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.4.attn.w_msa.proj.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.4.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.4.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.4.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.4.ffn.layers.0.0.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.4.ffn.layers.1.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.4.ffn.layers.1.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.5.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.5.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in WindowMSA  

backbone.stages.2.blocks.5.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.5.attn.w_msa.qkv.bias - torch.Size([1152]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.5.attn.w_msa.proj.weight - torch.Size([384, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.5.attn.w_msa.proj.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.5.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.5.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.blocks.5.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.5.ffn.layers.0.0.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.5.ffn.layers.1.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.blocks.5.ffn.layers.1.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.downsample.norm.weight - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.downsample.norm.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.2.downsample.reduction.weight - torch.Size([768, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.blocks.0.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.3.blocks.0.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
Initialized by user-defined `init_weights` in WindowMSA  

backbone.stages.3.blocks.0.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.blocks.0.attn.w_msa.qkv.bias - torch.Size([2304]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.blocks.0.attn.w_msa.proj.weight - torch.Size([768, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.blocks.0.attn.w_msa.proj.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.blocks.0.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.3.blocks.0.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.3.blocks.0.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.blocks.0.ffn.layers.0.0.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.blocks.0.ffn.layers.1.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.blocks.0.ffn.layers.1.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.blocks.1.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.3.blocks.1.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
Initialized by user-defined `init_weights` in WindowMSA  

backbone.stages.3.blocks.1.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.blocks.1.attn.w_msa.qkv.bias - torch.Size([2304]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.blocks.1.attn.w_msa.proj.weight - torch.Size([768, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.blocks.1.attn.w_msa.proj.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.blocks.1.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.3.blocks.1.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.stages.3.blocks.1.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.blocks.1.ffn.layers.0.0.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.blocks.1.ffn.layers.1.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.blocks.1.ffn.layers.1.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.norm3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.norm3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

head.fc.weight - torch.Size([5, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

head.fc.bias - torch.Size([5]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 
2022-05-09 23:30:53,753 - mmcls - INFO - load checkpoint from local path: ./checkpoints/swin_small_224_b16x64_300e_imagenet_20210615_110219-7f9d988b.pth
2022-05-09 23:30:55,311 - mmcls - WARNING - The model and loaded state dict do not match exactly

size mismatch for head.fc.weight: copying a param with shape torch.Size([1000, 768]) from checkpoint, the shape in current model is torch.Size([5, 768]).
size mismatch for head.fc.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([5]).
unexpected key in source state_dict: backbone.stages.2.blocks.6.norm1.weight, backbone.stages.2.blocks.6.norm1.bias, backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.6.attn.w_msa.relative_position_index, backbone.stages.2.blocks.6.attn.w_msa.qkv.weight, backbone.stages.2.blocks.6.attn.w_msa.qkv.bias, backbone.stages.2.blocks.6.attn.w_msa.proj.weight, backbone.stages.2.blocks.6.attn.w_msa.proj.bias, backbone.stages.2.blocks.6.norm2.weight, backbone.stages.2.blocks.6.norm2.bias, backbone.stages.2.blocks.6.ffn.layers.0.0.weight, backbone.stages.2.blocks.6.ffn.layers.0.0.bias, backbone.stages.2.blocks.6.ffn.layers.1.weight, backbone.stages.2.blocks.6.ffn.layers.1.bias, backbone.stages.2.blocks.7.norm1.weight, backbone.stages.2.blocks.7.norm1.bias, backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.7.attn.w_msa.relative_position_index, backbone.stages.2.blocks.7.attn.w_msa.qkv.weight, backbone.stages.2.blocks.7.attn.w_msa.qkv.bias, backbone.stages.2.blocks.7.attn.w_msa.proj.weight, backbone.stages.2.blocks.7.attn.w_msa.proj.bias, backbone.stages.2.blocks.7.norm2.weight, backbone.stages.2.blocks.7.norm2.bias, backbone.stages.2.blocks.7.ffn.layers.0.0.weight, backbone.stages.2.blocks.7.ffn.layers.0.0.bias, backbone.stages.2.blocks.7.ffn.layers.1.weight, backbone.stages.2.blocks.7.ffn.layers.1.bias, backbone.stages.2.blocks.8.norm1.weight, backbone.stages.2.blocks.8.norm1.bias, backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.8.attn.w_msa.relative_position_index, backbone.stages.2.blocks.8.attn.w_msa.qkv.weight, backbone.stages.2.blocks.8.attn.w_msa.qkv.bias, backbone.stages.2.blocks.8.attn.w_msa.proj.weight, backbone.stages.2.blocks.8.attn.w_msa.proj.bias, backbone.stages.2.blocks.8.norm2.weight, backbone.stages.2.blocks.8.norm2.bias, backbone.stages.2.blocks.8.ffn.layers.0.0.weight, backbone.stages.2.blocks.8.ffn.layers.0.0.bias, backbone.stages.2.blocks.8.ffn.layers.1.weight, backbone.stages.2.blocks.8.ffn.layers.1.bias, backbone.stages.2.blocks.9.norm1.weight, backbone.stages.2.blocks.9.norm1.bias, backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.9.attn.w_msa.relative_position_index, backbone.stages.2.blocks.9.attn.w_msa.qkv.weight, backbone.stages.2.blocks.9.attn.w_msa.qkv.bias, backbone.stages.2.blocks.9.attn.w_msa.proj.weight, backbone.stages.2.blocks.9.attn.w_msa.proj.bias, backbone.stages.2.blocks.9.norm2.weight, backbone.stages.2.blocks.9.norm2.bias, backbone.stages.2.blocks.9.ffn.layers.0.0.weight, backbone.stages.2.blocks.9.ffn.layers.0.0.bias, backbone.stages.2.blocks.9.ffn.layers.1.weight, backbone.stages.2.blocks.9.ffn.layers.1.bias, backbone.stages.2.blocks.10.norm1.weight, backbone.stages.2.blocks.10.norm1.bias, backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.10.attn.w_msa.relative_position_index, backbone.stages.2.blocks.10.attn.w_msa.qkv.weight, backbone.stages.2.blocks.10.attn.w_msa.qkv.bias, backbone.stages.2.blocks.10.attn.w_msa.proj.weight, backbone.stages.2.blocks.10.attn.w_msa.proj.bias, backbone.stages.2.blocks.10.norm2.weight, backbone.stages.2.blocks.10.norm2.bias, backbone.stages.2.blocks.10.ffn.layers.0.0.weight, backbone.stages.2.blocks.10.ffn.layers.0.0.bias, backbone.stages.2.blocks.10.ffn.layers.1.weight, backbone.stages.2.blocks.10.ffn.layers.1.bias, backbone.stages.2.blocks.11.norm1.weight, backbone.stages.2.blocks.11.norm1.bias, backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.11.attn.w_msa.relative_position_index, backbone.stages.2.blocks.11.attn.w_msa.qkv.weight, backbone.stages.2.blocks.11.attn.w_msa.qkv.bias, backbone.stages.2.blocks.11.attn.w_msa.proj.weight, backbone.stages.2.blocks.11.attn.w_msa.proj.bias, backbone.stages.2.blocks.11.norm2.weight, backbone.stages.2.blocks.11.norm2.bias, backbone.stages.2.blocks.11.ffn.layers.0.0.weight, backbone.stages.2.blocks.11.ffn.layers.0.0.bias, backbone.stages.2.blocks.11.ffn.layers.1.weight, backbone.stages.2.blocks.11.ffn.layers.1.bias, backbone.stages.2.blocks.12.norm1.weight, backbone.stages.2.blocks.12.norm1.bias, backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.12.attn.w_msa.relative_position_index, backbone.stages.2.blocks.12.attn.w_msa.qkv.weight, backbone.stages.2.blocks.12.attn.w_msa.qkv.bias, backbone.stages.2.blocks.12.attn.w_msa.proj.weight, backbone.stages.2.blocks.12.attn.w_msa.proj.bias, backbone.stages.2.blocks.12.norm2.weight, backbone.stages.2.blocks.12.norm2.bias, backbone.stages.2.blocks.12.ffn.layers.0.0.weight, backbone.stages.2.blocks.12.ffn.layers.0.0.bias, backbone.stages.2.blocks.12.ffn.layers.1.weight, backbone.stages.2.blocks.12.ffn.layers.1.bias, backbone.stages.2.blocks.13.norm1.weight, backbone.stages.2.blocks.13.norm1.bias, backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.13.attn.w_msa.relative_position_index, backbone.stages.2.blocks.13.attn.w_msa.qkv.weight, backbone.stages.2.blocks.13.attn.w_msa.qkv.bias, backbone.stages.2.blocks.13.attn.w_msa.proj.weight, backbone.stages.2.blocks.13.attn.w_msa.proj.bias, backbone.stages.2.blocks.13.norm2.weight, backbone.stages.2.blocks.13.norm2.bias, backbone.stages.2.blocks.13.ffn.layers.0.0.weight, backbone.stages.2.blocks.13.ffn.layers.0.0.bias, backbone.stages.2.blocks.13.ffn.layers.1.weight, backbone.stages.2.blocks.13.ffn.layers.1.bias, backbone.stages.2.blocks.14.norm1.weight, backbone.stages.2.blocks.14.norm1.bias, backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.14.attn.w_msa.relative_position_index, backbone.stages.2.blocks.14.attn.w_msa.qkv.weight, backbone.stages.2.blocks.14.attn.w_msa.qkv.bias, backbone.stages.2.blocks.14.attn.w_msa.proj.weight, backbone.stages.2.blocks.14.attn.w_msa.proj.bias, backbone.stages.2.blocks.14.norm2.weight, backbone.stages.2.blocks.14.norm2.bias, backbone.stages.2.blocks.14.ffn.layers.0.0.weight, backbone.stages.2.blocks.14.ffn.layers.0.0.bias, backbone.stages.2.blocks.14.ffn.layers.1.weight, backbone.stages.2.blocks.14.ffn.layers.1.bias, backbone.stages.2.blocks.15.norm1.weight, backbone.stages.2.blocks.15.norm1.bias, backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.15.attn.w_msa.relative_position_index, backbone.stages.2.blocks.15.attn.w_msa.qkv.weight, backbone.stages.2.blocks.15.attn.w_msa.qkv.bias, backbone.stages.2.blocks.15.attn.w_msa.proj.weight, backbone.stages.2.blocks.15.attn.w_msa.proj.bias, backbone.stages.2.blocks.15.norm2.weight, backbone.stages.2.blocks.15.norm2.bias, backbone.stages.2.blocks.15.ffn.layers.0.0.weight, backbone.stages.2.blocks.15.ffn.layers.0.0.bias, backbone.stages.2.blocks.15.ffn.layers.1.weight, backbone.stages.2.blocks.15.ffn.layers.1.bias, backbone.stages.2.blocks.16.norm1.weight, backbone.stages.2.blocks.16.norm1.bias, backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.16.attn.w_msa.relative_position_index, backbone.stages.2.blocks.16.attn.w_msa.qkv.weight, backbone.stages.2.blocks.16.attn.w_msa.qkv.bias, backbone.stages.2.blocks.16.attn.w_msa.proj.weight, backbone.stages.2.blocks.16.attn.w_msa.proj.bias, backbone.stages.2.blocks.16.norm2.weight, backbone.stages.2.blocks.16.norm2.bias, backbone.stages.2.blocks.16.ffn.layers.0.0.weight, backbone.stages.2.blocks.16.ffn.layers.0.0.bias, backbone.stages.2.blocks.16.ffn.layers.1.weight, backbone.stages.2.blocks.16.ffn.layers.1.bias, backbone.stages.2.blocks.17.norm1.weight, backbone.stages.2.blocks.17.norm1.bias, backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.17.attn.w_msa.relative_position_index, backbone.stages.2.blocks.17.attn.w_msa.qkv.weight, backbone.stages.2.blocks.17.attn.w_msa.qkv.bias, backbone.stages.2.blocks.17.attn.w_msa.proj.weight, backbone.stages.2.blocks.17.attn.w_msa.proj.bias, backbone.stages.2.blocks.17.norm2.weight, backbone.stages.2.blocks.17.norm2.bias, backbone.stages.2.blocks.17.ffn.layers.0.0.weight, backbone.stages.2.blocks.17.ffn.layers.0.0.bias, backbone.stages.2.blocks.17.ffn.layers.1.weight, backbone.stages.2.blocks.17.ffn.layers.1.bias

2022-05-09 23:30:55,318 - mmcls - INFO - Start running, host: nfhr27@gpu8, work_dir: /home2/nfhr27/ADAM/comp_vis/image_classification/work_dirs/swin_tiny
2022-05-09 23:30:55,319 - mmcls - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2022-05-09 23:30:55,319 - mmcls - INFO - workflow: [('train', 1)], max: 300 epochs
2022-05-09 23:30:55,319 - mmcls - INFO - Checkpoints will be saved to /home2/nfhr27/ADAM/comp_vis/image_classification/work_dirs/swin_tiny by HardDiskBackend.
2022-05-09 23:31:13,803 - mmcls - INFO - Saving checkpoint at 1 epochs
2022-05-09 23:31:51,347 - mmcls - INFO - Saving checkpoint at 2 epochs
2022-05-09 23:32:27,137 - mmcls - INFO - Saving checkpoint at 3 epochs
2022-05-09 23:32:47,812 - mmcls - INFO - Saving checkpoint at 4 epochs
2022-05-09 23:33:08,144 - mmcls - INFO - Saving checkpoint at 5 epochs
2022-05-09 23:33:20,644 - mmcls - INFO - Epoch(val) [5][4]	accuracy_top-1: 65.2000, accuracy_top-5: 100.0000
2022-05-09 23:33:39,706 - mmcls - INFO - Saving checkpoint at 6 epochs
2022-05-09 23:33:59,813 - mmcls - INFO - Saving checkpoint at 7 epochs
2022-05-09 23:34:39,963 - mmcls - INFO - Saving checkpoint at 8 epochs
2022-05-09 23:35:04,442 - mmcls - INFO - Saving checkpoint at 9 epochs
2022-05-09 23:35:24,769 - mmcls - INFO - Saving checkpoint at 10 epochs
2022-05-09 23:35:41,595 - mmcls - INFO - Epoch(val) [10][4]	accuracy_top-1: 72.0000, accuracy_top-5: 100.0000
2022-05-09 23:36:00,098 - mmcls - INFO - Saving checkpoint at 11 epochs
2022-05-09 23:36:29,337 - mmcls - INFO - Saving checkpoint at 12 epochs
2022-05-09 23:37:00,409 - mmcls - INFO - Saving checkpoint at 13 epochs
2022-05-09 23:37:30,529 - mmcls - INFO - Saving checkpoint at 14 epochs
2022-05-09 23:37:50,802 - mmcls - INFO - Saving checkpoint at 15 epochs
2022-05-09 23:37:55,795 - mmcls - INFO - Epoch(val) [15][4]	accuracy_top-1: 69.2000, accuracy_top-5: 100.0000
2022-05-09 23:38:15,333 - mmcls - INFO - Saving checkpoint at 16 epochs
2022-05-09 23:38:52,440 - mmcls - INFO - Saving checkpoint at 17 epochs
2022-05-09 23:39:34,644 - mmcls - INFO - Saving checkpoint at 18 epochs
2022-05-09 23:40:20,208 - mmcls - INFO - Saving checkpoint at 19 epochs
2022-05-09 23:40:40,562 - mmcls - INFO - Saving checkpoint at 20 epochs
2022-05-09 23:40:53,781 - mmcls - INFO - Epoch(val) [20][4]	accuracy_top-1: 72.0000, accuracy_top-5: 100.0000
2022-05-09 23:41:12,891 - mmcls - INFO - Saving checkpoint at 21 epochs
2022-05-09 23:41:43,961 - mmcls - INFO - Saving checkpoint at 22 epochs
2022-05-09 23:42:22,533 - mmcls - INFO - Saving checkpoint at 23 epochs
2022-05-09 23:42:43,051 - mmcls - INFO - Saving checkpoint at 24 epochs
2022-05-09 23:43:03,155 - mmcls - INFO - Saving checkpoint at 25 epochs
2022-05-09 23:43:08,048 - mmcls - INFO - Epoch(val) [25][4]	accuracy_top-1: 71.6000, accuracy_top-5: 100.0000
2022-05-09 23:43:27,195 - mmcls - INFO - Saving checkpoint at 26 epochs
2022-05-09 23:43:49,235 - mmcls - INFO - Saving checkpoint at 27 epochs
2022-05-09 23:44:21,433 - mmcls - INFO - Saving checkpoint at 28 epochs
2022-05-09 23:44:47,966 - mmcls - INFO - Saving checkpoint at 29 epochs
2022-05-09 23:45:20,151 - mmcls - INFO - Saving checkpoint at 30 epochs
2022-05-09 23:45:28,520 - mmcls - INFO - Epoch(val) [30][4]	accuracy_top-1: 70.0000, accuracy_top-5: 100.0000
2022-05-09 23:45:47,302 - mmcls - INFO - Saving checkpoint at 31 epochs
2022-05-09 23:46:11,810 - mmcls - INFO - Saving checkpoint at 32 epochs
2022-05-09 23:46:41,119 - mmcls - INFO - Saving checkpoint at 33 epochs
2022-05-09 23:47:01,402 - mmcls - INFO - Saving checkpoint at 34 epochs
2022-05-09 23:47:21,232 - mmcls - INFO - Saving checkpoint at 35 epochs
2022-05-09 23:47:32,968 - mmcls - INFO - Epoch(val) [35][4]	accuracy_top-1: 74.0000, accuracy_top-5: 100.0000
2022-05-09 23:47:51,406 - mmcls - INFO - Saving checkpoint at 36 epochs
2022-05-09 23:48:25,522 - mmcls - INFO - Saving checkpoint at 37 epochs
2022-05-09 23:49:02,586 - mmcls - INFO - Saving checkpoint at 38 epochs
2022-05-09 23:49:30,009 - mmcls - INFO - Saving checkpoint at 39 epochs
2022-05-09 23:49:52,473 - mmcls - INFO - Saving checkpoint at 40 epochs
2022-05-09 23:49:57,322 - mmcls - INFO - Epoch(val) [40][4]	accuracy_top-1: 74.0000, accuracy_top-5: 100.0000
2022-05-09 23:50:16,185 - mmcls - INFO - Saving checkpoint at 41 epochs
2022-05-09 23:50:35,699 - mmcls - INFO - Saving checkpoint at 42 epochs
2022-05-09 23:50:55,415 - mmcls - INFO - Saving checkpoint at 43 epochs
2022-05-09 23:51:27,149 - mmcls - INFO - Saving checkpoint at 44 epochs
2022-05-09 23:51:54,412 - mmcls - INFO - Saving checkpoint at 45 epochs
2022-05-09 23:52:00,377 - mmcls - INFO - Epoch(val) [45][4]	accuracy_top-1: 71.6000, accuracy_top-5: 100.0000
2022-05-09 23:52:18,709 - mmcls - INFO - Saving checkpoint at 46 epochs
2022-05-09 23:52:39,018 - mmcls - INFO - Saving checkpoint at 47 epochs
2022-05-09 23:52:59,001 - mmcls - INFO - Saving checkpoint at 48 epochs
2022-05-09 23:53:18,502 - mmcls - INFO - Saving checkpoint at 49 epochs
2022-05-09 23:53:40,743 - mmcls - INFO - Saving checkpoint at 50 epochs
2022-05-09 23:53:48,369 - mmcls - INFO - Epoch(val) [50][4]	accuracy_top-1: 73.6000, accuracy_top-5: 100.0000
2022-05-09 23:54:07,429 - mmcls - INFO - Saving checkpoint at 51 epochs
2022-05-09 23:54:47,833 - mmcls - INFO - Saving checkpoint at 52 epochs
2022-05-09 23:55:12,955 - mmcls - INFO - Saving checkpoint at 53 epochs
2022-05-09 23:55:32,807 - mmcls - INFO - Saving checkpoint at 54 epochs
2022-05-09 23:55:55,259 - mmcls - INFO - Saving checkpoint at 55 epochs
2022-05-09 23:56:05,691 - mmcls - INFO - Epoch(val) [55][4]	accuracy_top-1: 76.8000, accuracy_top-5: 100.0000
2022-05-09 23:56:25,021 - mmcls - INFO - Saving checkpoint at 56 epochs
2022-05-09 23:56:57,850 - mmcls - INFO - Saving checkpoint at 57 epochs
2022-05-09 23:57:32,770 - mmcls - INFO - Saving checkpoint at 58 epochs
2022-05-09 23:57:53,302 - mmcls - INFO - Saving checkpoint at 59 epochs
2022-05-09 23:58:18,694 - mmcls - INFO - Saving checkpoint at 60 epochs
2022-05-09 23:58:38,227 - mmcls - INFO - Epoch(val) [60][4]	accuracy_top-1: 75.2000, accuracy_top-5: 100.0000
2022-05-09 23:58:57,385 - mmcls - INFO - Saving checkpoint at 61 epochs
2022-05-09 23:59:37,013 - mmcls - INFO - Saving checkpoint at 62 epochs
2022-05-09 23:59:58,417 - mmcls - INFO - Saving checkpoint at 63 epochs
2022-05-10 00:00:19,179 - mmcls - INFO - Saving checkpoint at 64 epochs
2022-05-10 00:00:39,721 - mmcls - INFO - Saving checkpoint at 65 epochs
2022-05-10 00:00:58,248 - mmcls - INFO - Epoch(val) [65][4]	accuracy_top-1: 76.4000, accuracy_top-5: 100.0000
2022-05-10 00:01:17,448 - mmcls - INFO - Saving checkpoint at 66 epochs
2022-05-10 00:02:01,829 - mmcls - INFO - Saving checkpoint at 67 epochs
2022-05-10 00:02:44,616 - mmcls - INFO - Saving checkpoint at 68 epochs
2022-05-10 00:03:07,412 - mmcls - INFO - Saving checkpoint at 69 epochs
2022-05-10 00:03:27,683 - mmcls - INFO - Saving checkpoint at 70 epochs
2022-05-10 00:03:32,606 - mmcls - INFO - Epoch(val) [70][4]	accuracy_top-1: 75.2000, accuracy_top-5: 100.0000
2022-05-10 00:03:51,408 - mmcls - INFO - Saving checkpoint at 71 epochs
2022-05-10 00:04:13,601 - mmcls - INFO - Saving checkpoint at 72 epochs
2022-05-10 00:04:40,169 - mmcls - INFO - Saving checkpoint at 73 epochs
2022-05-10 00:05:17,699 - mmcls - INFO - Saving checkpoint at 74 epochs
2022-05-10 00:05:58,593 - mmcls - INFO - Saving checkpoint at 75 epochs
2022-05-10 00:06:03,963 - mmcls - INFO - Epoch(val) [75][4]	accuracy_top-1: 73.6000, accuracy_top-5: 100.0000
2022-05-10 00:06:23,760 - mmcls - INFO - Saving checkpoint at 76 epochs
2022-05-10 00:06:47,800 - mmcls - INFO - Saving checkpoint at 77 epochs
2022-05-10 00:07:12,417 - mmcls - INFO - Saving checkpoint at 78 epochs
2022-05-10 00:07:42,002 - mmcls - INFO - Saving checkpoint at 79 epochs
2022-05-10 00:08:16,910 - mmcls - INFO - Saving checkpoint at 80 epochs
2022-05-10 00:08:22,019 - mmcls - INFO - Epoch(val) [80][4]	accuracy_top-1: 76.8000, accuracy_top-5: 100.0000
2022-05-10 00:08:40,972 - mmcls - INFO - Saving checkpoint at 81 epochs
2022-05-10 00:09:01,025 - mmcls - INFO - Saving checkpoint at 82 epochs
2022-05-10 00:09:21,112 - mmcls - INFO - Saving checkpoint at 83 epochs
2022-05-10 00:09:41,793 - mmcls - INFO - Saving checkpoint at 84 epochs
2022-05-10 00:10:47,379 - mmcls - INFO - Saving checkpoint at 85 epochs
2022-05-10 00:10:52,535 - mmcls - INFO - Epoch(val) [85][4]	accuracy_top-1: 75.2000, accuracy_top-5: 100.0000
2022-05-10 00:11:11,001 - mmcls - INFO - Saving checkpoint at 86 epochs
2022-05-10 00:11:31,065 - mmcls - INFO - Saving checkpoint at 87 epochs
2022-05-10 00:11:58,882 - mmcls - INFO - Saving checkpoint at 88 epochs
2022-05-10 00:12:26,136 - mmcls - INFO - Saving checkpoint at 89 epochs
2022-05-10 00:13:03,092 - mmcls - INFO - Saving checkpoint at 90 epochs
2022-05-10 00:13:16,101 - mmcls - INFO - Epoch(val) [90][4]	accuracy_top-1: 76.4000, accuracy_top-5: 100.0000
2022-05-10 00:13:34,666 - mmcls - INFO - Saving checkpoint at 91 epochs
2022-05-10 00:13:55,549 - mmcls - INFO - Saving checkpoint at 92 epochs
2022-05-10 00:14:39,473 - mmcls - INFO - Saving checkpoint at 93 epochs
2022-05-10 00:15:08,554 - mmcls - INFO - Saving checkpoint at 94 epochs
2022-05-10 00:15:32,954 - mmcls - INFO - Saving checkpoint at 95 epochs
2022-05-10 00:15:37,891 - mmcls - INFO - Epoch(val) [95][4]	accuracy_top-1: 77.6000, accuracy_top-5: 100.0000
2022-05-10 00:15:57,416 - mmcls - INFO - Saving checkpoint at 96 epochs
2022-05-10 00:16:16,561 - mmcls - INFO - Saving checkpoint at 97 epochs
2022-05-10 00:16:47,399 - mmcls - INFO - Saving checkpoint at 98 epochs
2022-05-10 00:17:28,430 - mmcls - INFO - Saving checkpoint at 99 epochs
2022-05-10 00:18:10,730 - mmcls - INFO - Saving checkpoint at 100 epochs
2022-05-10 00:18:20,914 - mmcls - INFO - Epoch(val) [100][4]	accuracy_top-1: 78.8000, accuracy_top-5: 100.0000
2022-05-10 00:18:39,407 - mmcls - INFO - Saving checkpoint at 101 epochs
2022-05-10 00:19:00,051 - mmcls - INFO - Saving checkpoint at 102 epochs
2022-05-10 00:19:20,815 - mmcls - INFO - Saving checkpoint at 103 epochs
2022-05-10 00:20:12,529 - mmcls - INFO - Saving checkpoint at 104 epochs
2022-05-10 00:20:46,319 - mmcls - INFO - Saving checkpoint at 105 epochs
2022-05-10 00:20:51,214 - mmcls - INFO - Epoch(val) [105][4]	accuracy_top-1: 78.8000, accuracy_top-5: 100.0000
2022-05-10 00:21:09,634 - mmcls - INFO - Saving checkpoint at 106 epochs
2022-05-10 00:21:29,259 - mmcls - INFO - Saving checkpoint at 107 epochs
2022-05-10 00:21:48,613 - mmcls - INFO - Saving checkpoint at 108 epochs
2022-05-10 00:22:08,209 - mmcls - INFO - Saving checkpoint at 109 epochs
2022-05-10 00:22:35,672 - mmcls - INFO - Saving checkpoint at 110 epochs
2022-05-10 00:23:13,497 - mmcls - INFO - Epoch(val) [110][4]	accuracy_top-1: 78.4000, accuracy_top-5: 100.0000
2022-05-10 00:23:32,155 - mmcls - INFO - Saving checkpoint at 111 epochs
2022-05-10 00:23:52,757 - mmcls - INFO - Saving checkpoint at 112 epochs
2022-05-10 00:24:12,884 - mmcls - INFO - Saving checkpoint at 113 epochs
2022-05-10 00:24:48,120 - mmcls - INFO - Saving checkpoint at 114 epochs
2022-05-10 00:25:19,376 - mmcls - INFO - Saving checkpoint at 115 epochs
2022-05-10 00:25:24,381 - mmcls - INFO - Epoch(val) [115][4]	accuracy_top-1: 78.4000, accuracy_top-5: 100.0000
2022-05-10 00:25:43,211 - mmcls - INFO - Saving checkpoint at 116 epochs
2022-05-10 00:26:25,893 - mmcls - INFO - Saving checkpoint at 117 epochs
2022-05-10 00:28:11,834 - mmcls - INFO - Saving checkpoint at 118 epochs
2022-05-10 00:28:31,944 - mmcls - INFO - Saving checkpoint at 119 epochs
2022-05-10 00:28:51,971 - mmcls - INFO - Saving checkpoint at 120 epochs
2022-05-10 00:28:56,837 - mmcls - INFO - Epoch(val) [120][4]	accuracy_top-1: 78.4000, accuracy_top-5: 100.0000
2022-05-10 00:29:16,410 - mmcls - INFO - Saving checkpoint at 121 epochs
2022-05-10 00:29:43,457 - mmcls - INFO - Saving checkpoint at 122 epochs
2022-05-10 00:30:36,751 - mmcls - INFO - Saving checkpoint at 123 epochs
2022-05-10 00:31:01,485 - mmcls - INFO - Saving checkpoint at 124 epochs
2022-05-10 00:31:21,611 - mmcls - INFO - Saving checkpoint at 125 epochs
2022-05-10 00:31:26,423 - mmcls - INFO - Epoch(val) [125][4]	accuracy_top-1: 80.8000, accuracy_top-5: 100.0000
2022-05-10 00:31:45,928 - mmcls - INFO - Saving checkpoint at 126 epochs
2022-05-10 00:32:26,634 - mmcls - INFO - Saving checkpoint at 127 epochs
2022-05-10 00:33:34,607 - mmcls - INFO - Saving checkpoint at 128 epochs
2022-05-10 00:33:55,203 - mmcls - INFO - Saving checkpoint at 129 epochs
2022-05-10 00:34:15,257 - mmcls - INFO - Saving checkpoint at 130 epochs
2022-05-10 00:34:33,535 - mmcls - INFO - Epoch(val) [130][4]	accuracy_top-1: 78.0000, accuracy_top-5: 100.0000
2022-05-10 00:34:52,410 - mmcls - INFO - Saving checkpoint at 131 epochs
2022-05-10 00:35:17,578 - mmcls - INFO - Saving checkpoint at 132 epochs
2022-05-10 00:35:48,484 - mmcls - INFO - Saving checkpoint at 133 epochs
2022-05-10 00:36:08,413 - mmcls - INFO - Saving checkpoint at 134 epochs
2022-05-10 00:36:28,014 - mmcls - INFO - Saving checkpoint at 135 epochs
2022-05-10 00:36:50,708 - mmcls - INFO - Epoch(val) [135][4]	accuracy_top-1: 79.2000, accuracy_top-5: 100.0000
2022-05-10 00:37:09,463 - mmcls - INFO - Saving checkpoint at 136 epochs
2022-05-10 00:37:41,961 - mmcls - INFO - Saving checkpoint at 137 epochs
2022-05-10 00:38:09,648 - mmcls - INFO - Saving checkpoint at 138 epochs
2022-05-10 00:38:28,968 - mmcls - INFO - Saving checkpoint at 139 epochs
2022-05-10 00:38:48,229 - mmcls - INFO - Saving checkpoint at 140 epochs
2022-05-10 00:38:53,187 - mmcls - INFO - Epoch(val) [140][4]	accuracy_top-1: 78.8000, accuracy_top-5: 100.0000
2022-05-10 00:39:11,640 - mmcls - INFO - Saving checkpoint at 141 epochs
2022-05-10 00:39:44,059 - mmcls - INFO - Saving checkpoint at 142 epochs
2022-05-10 00:40:13,691 - mmcls - INFO - Saving checkpoint at 143 epochs
2022-05-10 00:40:37,198 - mmcls - INFO - Saving checkpoint at 144 epochs
2022-05-10 00:40:56,953 - mmcls - INFO - Saving checkpoint at 145 epochs
2022-05-10 00:41:01,878 - mmcls - INFO - Epoch(val) [145][4]	accuracy_top-1: 80.4000, accuracy_top-5: 100.0000
2022-05-10 00:41:20,142 - mmcls - INFO - Saving checkpoint at 146 epochs
2022-05-10 00:41:44,951 - mmcls - INFO - Saving checkpoint at 147 epochs
2022-05-10 00:42:20,173 - mmcls - INFO - Saving checkpoint at 148 epochs
2022-05-10 00:42:54,359 - mmcls - INFO - Saving checkpoint at 149 epochs
2022-05-10 00:43:14,350 - mmcls - INFO - Saving checkpoint at 150 epochs
2022-05-10 00:43:19,245 - mmcls - INFO - Epoch(val) [150][4]	accuracy_top-1: 78.8000, accuracy_top-5: 100.0000
2022-05-10 00:43:38,382 - mmcls - INFO - Saving checkpoint at 151 epochs
2022-05-10 00:44:06,848 - mmcls - INFO - Saving checkpoint at 152 epochs
2022-05-10 00:44:31,608 - mmcls - INFO - Saving checkpoint at 153 epochs
2022-05-10 00:45:04,047 - mmcls - INFO - Saving checkpoint at 154 epochs
2022-05-10 00:45:23,660 - mmcls - INFO - Saving checkpoint at 155 epochs
2022-05-10 00:45:28,800 - mmcls - INFO - Epoch(val) [155][4]	accuracy_top-1: 81.2000, accuracy_top-5: 100.0000
2022-05-10 00:45:47,329 - mmcls - INFO - Saving checkpoint at 156 epochs
2022-05-10 00:46:15,951 - mmcls - INFO - Saving checkpoint at 157 epochs
2022-05-10 00:46:46,520 - mmcls - INFO - Saving checkpoint at 158 epochs
2022-05-10 00:47:14,635 - mmcls - INFO - Saving checkpoint at 159 epochs
2022-05-10 00:47:38,354 - mmcls - INFO - Saving checkpoint at 160 epochs
2022-05-10 00:47:43,237 - mmcls - INFO - Epoch(val) [160][4]	accuracy_top-1: 83.6000, accuracy_top-5: 100.0000
2022-05-10 00:48:03,005 - mmcls - INFO - Saving checkpoint at 161 epochs
2022-05-10 00:48:22,774 - mmcls - INFO - Saving checkpoint at 162 epochs
2022-05-10 00:48:53,839 - mmcls - INFO - Saving checkpoint at 163 epochs
2022-05-10 00:49:22,374 - mmcls - INFO - Saving checkpoint at 164 epochs
2022-05-10 00:49:56,281 - mmcls - INFO - Saving checkpoint at 165 epochs
2022-05-10 00:50:01,176 - mmcls - INFO - Epoch(val) [165][4]	accuracy_top-1: 81.2000, accuracy_top-5: 100.0000
2022-05-10 00:50:19,882 - mmcls - INFO - Saving checkpoint at 166 epochs
2022-05-10 00:50:40,248 - mmcls - INFO - Saving checkpoint at 167 epochs
2022-05-10 00:50:59,939 - mmcls - INFO - Saving checkpoint at 168 epochs
2022-05-10 00:51:20,410 - mmcls - INFO - Saving checkpoint at 169 epochs
2022-05-10 00:51:55,401 - mmcls - INFO - Saving checkpoint at 170 epochs
2022-05-10 00:52:11,280 - mmcls - INFO - Epoch(val) [170][4]	accuracy_top-1: 80.8000, accuracy_top-5: 100.0000
2022-05-10 00:52:29,853 - mmcls - INFO - Saving checkpoint at 171 epochs
2022-05-10 00:52:52,767 - mmcls - INFO - Saving checkpoint at 172 epochs
2022-05-10 00:53:12,001 - mmcls - INFO - Saving checkpoint at 173 epochs
2022-05-10 00:53:32,817 - mmcls - INFO - Saving checkpoint at 174 epochs
2022-05-10 00:53:52,594 - mmcls - INFO - Saving checkpoint at 175 epochs
2022-05-10 00:53:59,248 - mmcls - INFO - Epoch(val) [175][4]	accuracy_top-1: 80.4000, accuracy_top-5: 100.0000
2022-05-10 00:54:18,559 - mmcls - INFO - Saving checkpoint at 176 epochs
2022-05-10 00:55:01,779 - mmcls - INFO - Saving checkpoint at 177 epochs
2022-05-10 00:55:33,641 - mmcls - INFO - Saving checkpoint at 178 epochs
2022-05-10 00:56:04,598 - mmcls - INFO - Saving checkpoint at 179 epochs
2022-05-10 00:56:23,820 - mmcls - INFO - Saving checkpoint at 180 epochs
2022-05-10 00:56:28,700 - mmcls - INFO - Epoch(val) [180][4]	accuracy_top-1: 79.2000, accuracy_top-5: 100.0000
2022-05-10 00:56:48,299 - mmcls - INFO - Saving checkpoint at 181 epochs
2022-05-10 00:57:15,355 - mmcls - INFO - Saving checkpoint at 182 epochs
2022-05-10 00:57:49,735 - mmcls - INFO - Saving checkpoint at 183 epochs
2022-05-10 00:58:10,505 - mmcls - INFO - Saving checkpoint at 184 epochs
2022-05-10 00:58:31,287 - mmcls - INFO - Saving checkpoint at 185 epochs
2022-05-10 00:58:51,793 - mmcls - INFO - Epoch(val) [185][4]	accuracy_top-1: 83.2000, accuracy_top-5: 100.0000
2022-05-10 00:59:10,898 - mmcls - INFO - Saving checkpoint at 186 epochs
2022-05-10 00:59:40,895 - mmcls - INFO - Saving checkpoint at 187 epochs
2022-05-10 01:00:09,645 - mmcls - INFO - Saving checkpoint at 188 epochs
2022-05-10 01:00:29,526 - mmcls - INFO - Saving checkpoint at 189 epochs
2022-05-10 01:00:49,797 - mmcls - INFO - Saving checkpoint at 190 epochs
2022-05-10 01:00:54,846 - mmcls - INFO - Epoch(val) [190][4]	accuracy_top-1: 82.8000, accuracy_top-5: 100.0000
2022-05-10 01:01:14,329 - mmcls - INFO - Saving checkpoint at 191 epochs
2022-05-10 01:01:44,758 - mmcls - INFO - Saving checkpoint at 192 epochs
2022-05-10 01:02:17,350 - mmcls - INFO - Saving checkpoint at 193 epochs
2022-05-10 01:02:47,831 - mmcls - INFO - Saving checkpoint at 194 epochs
2022-05-10 01:03:07,414 - mmcls - INFO - Saving checkpoint at 195 epochs
2022-05-10 01:03:12,394 - mmcls - INFO - Epoch(val) [195][4]	accuracy_top-1: 82.8000, accuracy_top-5: 100.0000
2022-05-10 01:03:30,587 - mmcls - INFO - Saving checkpoint at 196 epochs
2022-05-10 01:03:50,732 - mmcls - INFO - Saving checkpoint at 197 epochs
2022-05-10 01:04:11,208 - mmcls - INFO - Saving checkpoint at 198 epochs
2022-05-10 01:04:36,967 - mmcls - INFO - Saving checkpoint at 199 epochs
2022-05-10 01:05:22,172 - mmcls - INFO - Saving checkpoint at 200 epochs
2022-05-10 01:05:50,131 - mmcls - INFO - Epoch(val) [200][4]	accuracy_top-1: 83.2000, accuracy_top-5: 100.0000
2022-05-10 01:06:09,087 - mmcls - INFO - Saving checkpoint at 201 epochs
2022-05-10 01:06:29,185 - mmcls - INFO - Saving checkpoint at 202 epochs
2022-05-10 01:06:48,399 - mmcls - INFO - Saving checkpoint at 203 epochs
2022-05-10 01:07:08,560 - mmcls - INFO - Saving checkpoint at 204 epochs
2022-05-10 01:07:28,494 - mmcls - INFO - Saving checkpoint at 205 epochs
2022-05-10 01:07:55,701 - mmcls - INFO - Epoch(val) [205][4]	accuracy_top-1: 82.4000, accuracy_top-5: 100.0000
2022-05-10 01:08:15,301 - mmcls - INFO - Saving checkpoint at 206 epochs
2022-05-10 01:08:40,850 - mmcls - INFO - Saving checkpoint at 207 epochs
2022-05-10 01:09:01,262 - mmcls - INFO - Saving checkpoint at 208 epochs
2022-05-10 01:09:20,647 - mmcls - INFO - Saving checkpoint at 209 epochs
2022-05-10 01:09:40,303 - mmcls - INFO - Saving checkpoint at 210 epochs
2022-05-10 01:09:51,091 - mmcls - INFO - Epoch(val) [210][4]	accuracy_top-1: 82.8000, accuracy_top-5: 100.0000
2022-05-10 01:10:10,390 - mmcls - INFO - Saving checkpoint at 211 epochs
2022-05-10 01:11:36,429 - mmcls - INFO - Saving checkpoint at 212 epochs
2022-05-10 01:12:00,068 - mmcls - INFO - Saving checkpoint at 213 epochs
2022-05-10 01:12:20,110 - mmcls - INFO - Saving checkpoint at 214 epochs
2022-05-10 01:12:40,243 - mmcls - INFO - Saving checkpoint at 215 epochs
2022-05-10 01:12:48,433 - mmcls - INFO - Epoch(val) [215][4]	accuracy_top-1: 84.0000, accuracy_top-5: 100.0000
2022-05-10 01:13:06,517 - mmcls - INFO - Saving checkpoint at 216 epochs
2022-05-10 01:13:28,913 - mmcls - INFO - Saving checkpoint at 217 epochs
2022-05-10 01:14:02,347 - mmcls - INFO - Saving checkpoint at 218 epochs
2022-05-10 01:14:23,164 - mmcls - INFO - Saving checkpoint at 219 epochs
2022-05-10 01:14:44,389 - mmcls - INFO - Saving checkpoint at 220 epochs
2022-05-10 01:14:53,906 - mmcls - INFO - Epoch(val) [220][4]	accuracy_top-1: 82.8000, accuracy_top-5: 100.0000
2022-05-10 01:15:12,645 - mmcls - INFO - Saving checkpoint at 221 epochs
2022-05-10 01:15:37,428 - mmcls - INFO - Saving checkpoint at 222 epochs
2022-05-10 01:16:02,041 - mmcls - INFO - Saving checkpoint at 223 epochs
2022-05-10 01:16:24,861 - mmcls - INFO - Saving checkpoint at 224 epochs
2022-05-10 01:16:44,829 - mmcls - INFO - Saving checkpoint at 225 epochs
2022-05-10 01:16:58,138 - mmcls - INFO - Epoch(val) [225][4]	accuracy_top-1: 81.6000, accuracy_top-5: 100.0000
2022-05-10 01:17:17,506 - mmcls - INFO - Saving checkpoint at 226 epochs
2022-05-10 01:17:51,100 - mmcls - INFO - Saving checkpoint at 227 epochs
2022-05-10 01:18:14,030 - mmcls - INFO - Saving checkpoint at 228 epochs
2022-05-10 01:18:45,282 - mmcls - INFO - Saving checkpoint at 229 epochs
2022-05-10 01:19:04,540 - mmcls - INFO - Saving checkpoint at 230 epochs
2022-05-10 01:19:14,702 - mmcls - INFO - Epoch(val) [230][4]	accuracy_top-1: 84.0000, accuracy_top-5: 100.0000
2022-05-10 01:19:34,020 - mmcls - INFO - Saving checkpoint at 231 epochs
2022-05-10 01:19:55,026 - mmcls - INFO - Saving checkpoint at 232 epochs
2022-05-10 01:20:15,627 - mmcls - INFO - Saving checkpoint at 233 epochs
2022-05-10 01:20:50,842 - mmcls - INFO - Saving checkpoint at 234 epochs
2022-05-10 01:21:16,996 - mmcls - INFO - Saving checkpoint at 235 epochs
2022-05-10 01:21:23,262 - mmcls - INFO - Epoch(val) [235][4]	accuracy_top-1: 84.4000, accuracy_top-5: 100.0000
2022-05-10 01:21:41,855 - mmcls - INFO - Saving checkpoint at 236 epochs
2022-05-10 01:22:02,149 - mmcls - INFO - Saving checkpoint at 237 epochs
2022-05-10 01:22:35,529 - mmcls - INFO - Saving checkpoint at 238 epochs
2022-05-10 01:23:01,716 - mmcls - INFO - Saving checkpoint at 239 epochs
2022-05-10 01:23:34,621 - mmcls - INFO - Saving checkpoint at 240 epochs
2022-05-10 01:23:46,785 - mmcls - INFO - Epoch(val) [240][4]	accuracy_top-1: 84.0000, accuracy_top-5: 100.0000
2022-05-10 01:24:05,774 - mmcls - INFO - Saving checkpoint at 241 epochs
2022-05-10 01:24:25,849 - mmcls - INFO - Saving checkpoint at 242 epochs
2022-05-10 01:24:45,907 - mmcls - INFO - Saving checkpoint at 243 epochs
2022-05-10 01:25:10,578 - mmcls - INFO - Saving checkpoint at 244 epochs
2022-05-10 01:25:35,886 - mmcls - INFO - Saving checkpoint at 245 epochs
2022-05-10 01:25:48,642 - mmcls - INFO - Epoch(val) [245][4]	accuracy_top-1: 84.4000, accuracy_top-5: 100.0000
2022-05-10 01:26:07,468 - mmcls - INFO - Saving checkpoint at 246 epochs
2022-05-10 01:26:40,458 - mmcls - INFO - Saving checkpoint at 247 epochs
2022-05-10 01:27:00,117 - mmcls - INFO - Saving checkpoint at 248 epochs
2022-05-10 01:27:20,769 - mmcls - INFO - Saving checkpoint at 249 epochs
2022-05-10 01:27:50,834 - mmcls - INFO - Saving checkpoint at 250 epochs
2022-05-10 01:28:04,663 - mmcls - INFO - Epoch(val) [250][4]	accuracy_top-1: 84.4000, accuracy_top-5: 100.0000
2022-05-10 01:28:23,947 - mmcls - INFO - Saving checkpoint at 251 epochs
2022-05-10 01:28:46,921 - mmcls - INFO - Saving checkpoint at 252 epochs
2022-05-10 01:29:06,514 - mmcls - INFO - Saving checkpoint at 253 epochs
2022-05-10 01:29:26,109 - mmcls - INFO - Saving checkpoint at 254 epochs
2022-05-10 01:29:51,804 - mmcls - INFO - Saving checkpoint at 255 epochs
2022-05-10 01:30:08,181 - mmcls - INFO - Epoch(val) [255][4]	accuracy_top-1: 85.2000, accuracy_top-5: 100.0000
2022-05-10 01:30:27,192 - mmcls - INFO - Saving checkpoint at 256 epochs
2022-05-10 01:31:14,445 - mmcls - INFO - Saving checkpoint at 257 epochs
2022-05-10 01:31:50,185 - mmcls - INFO - Saving checkpoint at 258 epochs
2022-05-10 01:32:10,331 - mmcls - INFO - Saving checkpoint at 259 epochs
2022-05-10 01:32:29,759 - mmcls - INFO - Saving checkpoint at 260 epochs
2022-05-10 01:32:34,731 - mmcls - INFO - Epoch(val) [260][4]	accuracy_top-1: 86.0000, accuracy_top-5: 100.0000
2022-05-10 01:32:53,833 - mmcls - INFO - Saving checkpoint at 261 epochs
2022-05-10 01:33:21,759 - mmcls - INFO - Saving checkpoint at 262 epochs
2022-05-10 01:34:01,329 - mmcls - INFO - Saving checkpoint at 263 epochs
2022-05-10 01:34:21,645 - mmcls - INFO - Saving checkpoint at 264 epochs
2022-05-10 01:34:44,728 - mmcls - INFO - Saving checkpoint at 265 epochs
2022-05-10 01:34:49,726 - mmcls - INFO - Epoch(val) [265][4]	accuracy_top-1: 86.0000, accuracy_top-5: 100.0000
2022-05-10 01:35:08,266 - mmcls - INFO - Saving checkpoint at 266 epochs
2022-05-10 01:35:27,987 - mmcls - INFO - Saving checkpoint at 267 epochs
2022-05-10 01:35:48,191 - mmcls - INFO - Saving checkpoint at 268 epochs
2022-05-10 01:36:21,733 - mmcls - INFO - Saving checkpoint at 269 epochs
2022-05-10 01:37:04,651 - mmcls - INFO - Saving checkpoint at 270 epochs
2022-05-10 01:37:21,671 - mmcls - INFO - Epoch(val) [270][4]	accuracy_top-1: 86.0000, accuracy_top-5: 100.0000
2022-05-10 01:37:40,914 - mmcls - INFO - Saving checkpoint at 271 epochs
2022-05-10 01:38:06,584 - mmcls - INFO - Saving checkpoint at 272 epochs
2022-05-10 01:38:26,694 - mmcls - INFO - Saving checkpoint at 273 epochs
2022-05-10 01:38:46,547 - mmcls - INFO - Saving checkpoint at 274 epochs
2022-05-10 01:39:14,997 - mmcls - INFO - Saving checkpoint at 275 epochs
2022-05-10 01:39:31,762 - mmcls - INFO - Epoch(val) [275][4]	accuracy_top-1: 87.6000, accuracy_top-5: 100.0000
2022-05-10 01:39:50,845 - mmcls - INFO - Saving checkpoint at 276 epochs
2022-05-10 01:40:20,427 - mmcls - INFO - Saving checkpoint at 277 epochs
2022-05-10 01:40:44,604 - mmcls - INFO - Saving checkpoint at 278 epochs
2022-05-10 01:41:04,690 - mmcls - INFO - Saving checkpoint at 279 epochs
2022-05-10 01:41:25,274 - mmcls - INFO - Saving checkpoint at 280 epochs
2022-05-10 01:41:30,186 - mmcls - INFO - Epoch(val) [280][4]	accuracy_top-1: 86.4000, accuracy_top-5: 100.0000
2022-05-10 01:41:50,041 - mmcls - INFO - Saving checkpoint at 281 epochs
2022-05-10 01:42:20,164 - mmcls - INFO - Saving checkpoint at 282 epochs
2022-05-10 01:42:47,779 - mmcls - INFO - Saving checkpoint at 283 epochs
2022-05-10 01:43:24,597 - mmcls - INFO - Saving checkpoint at 284 epochs
2022-05-10 01:43:49,537 - mmcls - INFO - Saving checkpoint at 285 epochs
2022-05-10 01:43:54,466 - mmcls - INFO - Epoch(val) [285][4]	accuracy_top-1: 86.8000, accuracy_top-5: 100.0000
2022-05-10 01:44:13,368 - mmcls - INFO - Saving checkpoint at 286 epochs
2022-05-10 01:44:32,607 - mmcls - INFO - Saving checkpoint at 287 epochs
2022-05-10 01:44:52,992 - mmcls - INFO - Saving checkpoint at 288 epochs
2022-05-10 01:45:15,574 - mmcls - INFO - Saving checkpoint at 289 epochs
2022-05-10 01:45:43,466 - mmcls - INFO - Saving checkpoint at 290 epochs
2022-05-10 01:46:01,796 - mmcls - INFO - Epoch(val) [290][4]	accuracy_top-1: 86.8000, accuracy_top-5: 100.0000
2022-05-10 01:46:20,047 - mmcls - INFO - Saving checkpoint at 291 epochs
2022-05-10 01:46:41,422 - mmcls - INFO - Saving checkpoint at 292 epochs
2022-05-10 01:47:01,387 - mmcls - INFO - Saving checkpoint at 293 epochs
2022-05-10 01:47:21,511 - mmcls - INFO - Saving checkpoint at 294 epochs
2022-05-10 01:47:42,883 - mmcls - INFO - Saving checkpoint at 295 epochs
2022-05-10 01:47:55,599 - mmcls - INFO - Epoch(val) [295][4]	accuracy_top-1: 86.0000, accuracy_top-5: 100.0000
2022-05-10 01:48:14,694 - mmcls - INFO - Saving checkpoint at 296 epochs
2022-05-10 01:48:39,764 - mmcls - INFO - Saving checkpoint at 297 epochs
2022-05-10 01:49:01,243 - mmcls - INFO - Saving checkpoint at 298 epochs
2022-05-10 01:49:41,418 - mmcls - INFO - Saving checkpoint at 299 epochs
2022-05-10 01:50:13,155 - mmcls - INFO - Saving checkpoint at 300 epochs
2022-05-10 01:50:25,555 - mmcls - INFO - Epoch(val) [300][4]	accuracy_top-1: 86.4000, accuracy_top-5: 100.0000
